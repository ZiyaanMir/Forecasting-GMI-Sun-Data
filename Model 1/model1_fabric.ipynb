{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "import torchsummary\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import sys\n",
    "sys.path.append('../DataLoader')\n",
    "\n",
    "from dataloader import SunImageDataset\n",
    "\n",
    "\n",
    "from lightning.fabric import Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "fabric = Fabric(accelerator='cuda', devices=1, precision=\"bf16-mixed\")\n",
    "fabric.launch()\n",
    "print(fabric.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 224*224\n",
    "hidden_size = 166\n",
    "num_epochs = 20\n",
    "batch_size = 2\n",
    "learning_rate = 0.001\n",
    "# dropout = 0.6990787087509548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SunImageDataset(csv_file=\"D:\\\\dataset.csv\", offset=0, transform=transforms.ToTensor())\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Without Validation Set\n",
    "trainset, testset = torch.utils.data.Subset(dataset, range(train_size)), torch.utils.data.Subset(dataset, range(train_size, len(dataset)))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "\n",
    "trainloader = fabric.setup_dataloaders(trainloader)\n",
    "\n",
    "# # With Validation Set\n",
    "# # Split dataset into training and test sets\n",
    "# train_indices, test_indices = train_test_split(range(len(dataset)), test_size=0.2, shuffle=False)\n",
    "\n",
    "# # Further split training set into training and validation sets\n",
    "# train_indices, val_indices = train_test_split(train_indices, test_size=0.25, shuffle=False)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# trainset = torch.utils.data.Subset(dataset, train_indices)\n",
    "# valset = torch.utils.data.Subset(dataset, val_indices)\n",
    "# testset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "# valloader = torch.utils.data.DataLoader(dataset=valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# # Get a batch of training data\n",
    "# dataiter = iter(trainloader)\n",
    "# images, labels = next(dataiter)\n",
    "# images = torch.stack(images)\n",
    "# print(images.shape)\n",
    "# print(labels.shape)\n",
    "\n",
    "# print(images)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_FabricModule(\n",
       "  (_forward_module): GmiSwinTransformer(\n",
       "    (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pretrained_model): SwinTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (layers): Sequential(\n",
       "        (0): SwinTransformerStage(\n",
       "          (downsample): Identity()\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): Identity()\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): Identity()\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.004)\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.004)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerStage(\n",
       "          (downsample): PatchMerging(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.009)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.009)\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.013)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.013)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerStage(\n",
       "          (downsample): PatchMerging(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.017)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.017)\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.022)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.022)\n",
       "            )\n",
       "            (2): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.026)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.026)\n",
       "            )\n",
       "            (3): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.030)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.030)\n",
       "            )\n",
       "            (4): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.035)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.035)\n",
       "            )\n",
       "            (5): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.039)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.039)\n",
       "            )\n",
       "            (6): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.043)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.043)\n",
       "            )\n",
       "            (7): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.048)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.048)\n",
       "            )\n",
       "            (8): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.052)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.052)\n",
       "            )\n",
       "            (9): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.057)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.057)\n",
       "            )\n",
       "            (10): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.061)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.061)\n",
       "            )\n",
       "            (11): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.065)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.065)\n",
       "            )\n",
       "            (12): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.070)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.070)\n",
       "            )\n",
       "            (13): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.074)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.074)\n",
       "            )\n",
       "            (14): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.078)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.078)\n",
       "            )\n",
       "            (15): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.083)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.083)\n",
       "            )\n",
       "            (16): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.087)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.087)\n",
       "            )\n",
       "            (17): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.091)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.091)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerStage(\n",
       "          (downsample): PatchMerging(\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.096)\n",
       "              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.096)\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.100)\n",
       "              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.100)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): ClassifierHead(\n",
       "        (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (fc): Linear(in_features=1024, out_features=166, bias=True)\n",
       "        (flatten): Identity()\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.01)\n",
       "      (1): Linear(in_features=1660, out_features=166, bias=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=166, out_features=1, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (_original_module): GmiSwinTransformer(\n",
       "    (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pretrained_model): SwinTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (layers): Sequential(\n",
       "        (0): SwinTransformerStage(\n",
       "          (downsample): Identity()\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): Identity()\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): Identity()\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.004)\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.004)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerStage(\n",
       "          (downsample): PatchMerging(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.009)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.009)\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.013)\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.013)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerStage(\n",
       "          (downsample): PatchMerging(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.017)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.017)\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.022)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.022)\n",
       "            )\n",
       "            (2): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.026)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.026)\n",
       "            )\n",
       "            (3): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.030)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.030)\n",
       "            )\n",
       "            (4): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.035)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.035)\n",
       "            )\n",
       "            (5): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.039)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.039)\n",
       "            )\n",
       "            (6): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.043)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.043)\n",
       "            )\n",
       "            (7): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.048)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.048)\n",
       "            )\n",
       "            (8): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.052)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.052)\n",
       "            )\n",
       "            (9): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.057)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.057)\n",
       "            )\n",
       "            (10): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.061)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.061)\n",
       "            )\n",
       "            (11): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.065)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.065)\n",
       "            )\n",
       "            (12): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.070)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.070)\n",
       "            )\n",
       "            (13): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.074)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.074)\n",
       "            )\n",
       "            (14): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.078)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.078)\n",
       "            )\n",
       "            (15): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.083)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.083)\n",
       "            )\n",
       "            (16): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.087)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.087)\n",
       "            )\n",
       "            (17): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.091)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.091)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerStage(\n",
       "          (downsample): PatchMerging(\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.096)\n",
       "              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.096)\n",
       "            )\n",
       "            (1): SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path1): DropPath(drop_prob=0.100)\n",
       "              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path2): DropPath(drop_prob=0.100)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): ClassifierHead(\n",
       "        (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (fc): Linear(in_features=1024, out_features=166, bias=True)\n",
       "        (flatten): Identity()\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.01)\n",
       "      (1): Linear(in_features=1660, out_features=166, bias=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=166, out_features=1, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class GmiSwinTransformer(nn.Module):\n",
    "    def __init__(self, hidden_size: int):\n",
    "        super(GmiSwinTransformer, self).__init__()\n",
    "        \n",
    "        # Batch normalization for 3 channels\n",
    "        self.bn = nn.BatchNorm2d(3)\n",
    "        \n",
    "        # Initialize Swin Transformer\n",
    "        self.pretrained_model = timm.create_model(\n",
    "            'swin_base_patch4_window7_224',\n",
    "            pretrained=True,\n",
    "            num_classes=hidden_size\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size*10, hidden_size),\n",
    "            nn.Dropout(p=0.5),  # Added dropout probability\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, images) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Batch should be in format:\n",
    "        {\n",
    "            'images': torch.FloatTensor((10, 1, 224, 224))\n",
    "        }\n",
    "        \"\"\"\n",
    "        # # Print input shape for debugging\n",
    "        # # print(\"Input shape:\", images.shape)\n",
    "        # image_features = torch.zeros(images.shape[0],images.shape[1], hidden_size).to(device)\n",
    "        # for i in range(images.shape[0]):\n",
    "        #     image = images[i, :, :, :]\n",
    "        #     # Pretrained swin transformer accepts three channel images\n",
    "        #     three_channel = torch.stack([image,image,image], dim=1).squeeze(2)\n",
    "        #     # print(\"three_channel\", three_channel.size())\n",
    "        #     # Model learns optimal initial normalisation\n",
    "        #     normalized_images = self.bn(three_channel)\n",
    "        #     # Get image features\n",
    "        #     image_feature = self.pretrained_model.forward(normalized_images)\n",
    "        #     image_features[i] = image_feature\n",
    "        # # print(\"image_features before reshaping\", image_features.size())\n",
    "        # image_features = image_features.view(image_features.size(0), -1)\n",
    "        # print(\"image_features after reshaping\", image_features.size())\n",
    "        \n",
    "        batch_size = images.shape[0]\n",
    "        \n",
    "        images = images.reshape(-1, 1, 224, 224)\n",
    "        images = torch.cat([images, images, images], dim=1)\n",
    "        normalized_images = self.bn(images)\n",
    "        features = self.pretrained_model(normalized_images)\n",
    "        image_features = features.view(batch_size, -1)\n",
    "        \n",
    "        output = self.fc(image_features)\n",
    "        return output\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = GmiSwinTransformer(hidden_size=hidden_size).to(device)\n",
    "model = GmiSwinTransformer(hidden_size=hidden_size)\n",
    "\n",
    "# print(torchsummary.summary(model, (10, 1, 224, 224)))\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model, optimizer = fabric.setup(model, optimizer)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef425b5cb704f0483708cb91996fdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Index: 0, Loss: 3.6118\n",
      "Epoch: 1, Index: 1, Loss: 2.6630\n",
      "Epoch: 1, Index: 2, Loss: 27.3026\n",
      "Epoch: 1, Index: 3, Loss: 9.1333\n",
      "Epoch: 1, Index: 4, Loss: 3.8627\n",
      "Epoch: 1, Index: 5, Loss: 7.0482\n",
      "Epoch: 1, Index: 6, Loss: 20.3346\n",
      "Epoch: 1, Index: 7, Loss: 9.2550\n",
      "Epoch: 1, Index: 8, Loss: 4.1571\n",
      "Epoch: 1, Index: 9, Loss: 2.2485\n",
      "Epoch: 1, Index: 10, Loss: 4.7197\n",
      "Epoch: 1, Index: 11, Loss: 2.7217\n",
      "Epoch: 1, Index: 12, Loss: 2.2830\n",
      "Epoch: 1, Index: 13, Loss: 4.5214\n",
      "Epoch: 1, Index: 14, Loss: 1.4758\n",
      "Epoch: 1, Index: 15, Loss: 0.4166\n",
      "Epoch: 1, Index: 16, Loss: 0.4257\n",
      "Epoch: 1, Index: 17, Loss: 3.4664\n",
      "Epoch: 1, Index: 18, Loss: 5.3863\n",
      "Epoch: 1, Index: 19, Loss: 1.9935\n",
      "Epoch: 1, Index: 20, Loss: 3.5714\n",
      "Epoch: 1, Index: 21, Loss: 1.2974\n",
      "Epoch: 1, Index: 22, Loss: 4.5597\n",
      "Epoch: 1, Index: 23, Loss: 0.4507\n",
      "Epoch: 1, Index: 24, Loss: 1.3339\n",
      "Epoch: 1, Index: 25, Loss: 3.1829\n",
      "Epoch: 1, Index: 26, Loss: 17.6958\n",
      "Epoch: 1, Index: 27, Loss: 3.0485\n",
      "Epoch: 1, Index: 28, Loss: 0.2290\n",
      "Epoch: 1, Index: 29, Loss: 17.4651\n",
      "Epoch: 1, Index: 30, Loss: 3.7938\n",
      "Epoch: 1, Index: 31, Loss: 1.2589\n",
      "Epoch: 1, Index: 32, Loss: 1.9821\n",
      "Epoch: 1, Index: 33, Loss: 2.8828\n",
      "Epoch: 1, Index: 34, Loss: 3.9662\n",
      "Epoch: 1, Index: 35, Loss: 1.1169\n",
      "Epoch: 1, Index: 36, Loss: 1.4477\n",
      "Epoch: 1, Index: 37, Loss: 0.8834\n",
      "Epoch: 1, Index: 38, Loss: 2.2907\n",
      "Epoch: 1, Index: 39, Loss: 1.4560\n",
      "Epoch: 1, Index: 40, Loss: 5.0229\n",
      "Epoch: 1, Index: 41, Loss: 2.0177\n",
      "Epoch: 1, Index: 42, Loss: 1.2454\n",
      "Epoch: 1, Index: 43, Loss: 6.6572\n",
      "Epoch: 1, Index: 44, Loss: 1.0435\n",
      "Epoch: 1, Index: 45, Loss: 0.4948\n",
      "Epoch: 1, Index: 46, Loss: 2.4096\n",
      "Epoch: 1, Index: 47, Loss: 2.1788\n",
      "Epoch: 1, Index: 48, Loss: 0.9829\n",
      "Epoch: 1, Index: 49, Loss: 0.3720\n",
      "Epoch: 1, Index: 50, Loss: 2.1149\n",
      "Epoch: 1, Index: 51, Loss: 0.7234\n",
      "Epoch: 1, Index: 52, Loss: 9.5815\n",
      "Epoch: 1, Index: 53, Loss: 1.5816\n",
      "Epoch: 1, Index: 54, Loss: 1.2428\n",
      "Epoch: 1, Index: 55, Loss: 0.9660\n",
      "Epoch: 1, Index: 56, Loss: 2.0313\n",
      "Epoch: 1, Index: 57, Loss: 10.8209\n",
      "Epoch: 1, Index: 58, Loss: 3.0381\n",
      "Epoch: 1, Index: 59, Loss: 0.0191\n",
      "Epoch: 1, Index: 60, Loss: 2.7822\n",
      "Epoch: 1, Index: 61, Loss: 1.6753\n",
      "Epoch: 1, Index: 62, Loss: 0.0957\n",
      "Epoch: 1, Index: 63, Loss: 1.5445\n",
      "Epoch: 1, Index: 64, Loss: 1.8196\n",
      "Epoch: 1, Index: 65, Loss: 2.6696\n",
      "Epoch: 1, Index: 66, Loss: 0.0140\n",
      "Epoch: 1, Index: 67, Loss: 5.8459\n",
      "Epoch: 1, Index: 68, Loss: 0.6629\n",
      "Epoch: 1, Index: 69, Loss: 2.1122\n",
      "Epoch: 1, Index: 70, Loss: 1.3762\n",
      "Epoch: 1, Index: 71, Loss: 2.2784\n",
      "Epoch: 1, Index: 72, Loss: 19.8338\n",
      "Epoch: 1, Index: 73, Loss: 0.1436\n",
      "Epoch: 1, Index: 74, Loss: 8.5418\n",
      "Epoch: 1, Index: 75, Loss: 1.2859\n",
      "Epoch: 1, Index: 76, Loss: 0.5906\n",
      "Epoch: 1, Index: 77, Loss: 0.2878\n",
      "Epoch: 1, Index: 78, Loss: 1.1563\n",
      "Epoch: 1, Index: 79, Loss: 4.5267\n",
      "Epoch: 1, Index: 80, Loss: 0.1133\n",
      "Epoch: 1, Index: 81, Loss: 1.0672\n",
      "Epoch: 1, Index: 82, Loss: 0.9866\n",
      "Epoch: 1, Index: 83, Loss: 2.0972\n",
      "Epoch: 1, Index: 84, Loss: 4.3667\n",
      "Epoch: 1, Index: 85, Loss: 1.0277\n",
      "Epoch: 1, Index: 86, Loss: 1.1464\n",
      "Epoch: 1, Index: 87, Loss: 3.6416\n",
      "Epoch: 1, Index: 88, Loss: 4.6783\n",
      "Epoch: 1, Index: 89, Loss: 0.0701\n",
      "Epoch: 1, Index: 90, Loss: 7.9694\n",
      "Epoch: 1, Index: 91, Loss: 0.3958\n",
      "Epoch: 1, Index: 92, Loss: 1.8236\n",
      "Epoch: 1, Index: 93, Loss: 1.7663\n",
      "Epoch: 1, Index: 94, Loss: 1.3776\n",
      "Epoch: 1, Index: 95, Loss: 0.6563\n",
      "Epoch: 1, Index: 96, Loss: 0.6252\n",
      "Epoch: 1, Index: 97, Loss: 1.7642\n",
      "Epoch: 1, Index: 98, Loss: 5.8958\n",
      "Epoch: 1, Index: 99, Loss: 1.9307\n",
      "Epoch: 1, Index: 100, Loss: 1.0556\n",
      "Epoch: 1, Index: 101, Loss: 1.9139\n",
      "Epoch: 1, Index: 102, Loss: 2.3415\n",
      "Epoch: 1, Index: 103, Loss: 10.2928\n",
      "Epoch: 1, Index: 104, Loss: 1.2520\n",
      "Epoch: 1, Index: 105, Loss: 1.4771\n",
      "Epoch: 1, Index: 106, Loss: 0.5518\n",
      "Epoch: 1, Index: 107, Loss: 0.2574\n",
      "Epoch: 1, Index: 108, Loss: 0.0676\n",
      "Epoch: 1, Index: 109, Loss: 7.2821\n",
      "Epoch: 1, Index: 110, Loss: 3.6802\n",
      "Epoch: 1, Index: 111, Loss: 5.0251\n",
      "Epoch: 1, Index: 112, Loss: 1.3840\n",
      "Epoch: 1, Index: 113, Loss: 3.7628\n",
      "Epoch: 1, Index: 114, Loss: 2.9917\n",
      "Epoch: 1, Index: 115, Loss: 2.3986\n",
      "Epoch: 1, Index: 116, Loss: 1.2374\n",
      "Epoch: 1, Index: 117, Loss: 0.8776\n",
      "Epoch: 1, Index: 118, Loss: 3.2612\n",
      "Epoch: 1, Index: 119, Loss: 0.4623\n",
      "Epoch: 1, Index: 120, Loss: 0.5330\n",
      "Epoch: 1, Index: 121, Loss: 11.9674\n",
      "Epoch: 1, Index: 122, Loss: 2.6399\n",
      "Epoch: 1, Index: 123, Loss: 0.0331\n",
      "Epoch: 1, Index: 124, Loss: 0.1278\n",
      "Epoch: 1, Index: 125, Loss: 2.9703\n",
      "Epoch: 1, Index: 126, Loss: 0.9579\n",
      "Epoch: 1, Index: 127, Loss: 3.4193\n",
      "Epoch: 1, Index: 128, Loss: 3.0605\n",
      "Epoch: 1, Index: 129, Loss: 1.9407\n",
      "Epoch: 1, Index: 130, Loss: 2.0231\n",
      "Epoch: 1, Index: 131, Loss: 3.7918\n",
      "Epoch: 1, Index: 132, Loss: 1.5243\n",
      "Epoch: 1, Index: 133, Loss: 1.1799\n",
      "Epoch: 1, Index: 134, Loss: 6.9588\n",
      "Epoch: 1, Index: 135, Loss: 0.3504\n",
      "Epoch: 1, Index: 136, Loss: 6.0023\n",
      "Epoch: 1, Index: 137, Loss: 0.0557\n",
      "Epoch: 1, Index: 138, Loss: 1.7135\n",
      "Epoch: 1, Index: 139, Loss: 0.5148\n",
      "Epoch: 1, Index: 140, Loss: 4.2727\n",
      "Epoch: 1, Index: 141, Loss: 0.7182\n",
      "Epoch: 1, Index: 142, Loss: 1.7831\n",
      "Epoch: 1, Index: 143, Loss: 0.2544\n",
      "Epoch: 1, Index: 144, Loss: 1.3306\n",
      "Epoch: 1, Index: 145, Loss: 1.4860\n",
      "Epoch: 1, Index: 146, Loss: 0.2389\n",
      "Epoch: 1, Index: 147, Loss: 1.4436\n",
      "Epoch: 1, Index: 148, Loss: 0.0600\n",
      "Epoch: 1, Index: 149, Loss: 1.8953\n",
      "Epoch: 1, Index: 150, Loss: 0.0655\n",
      "Epoch: 1, Index: 151, Loss: 5.4870\n",
      "Epoch: 1, Index: 152, Loss: 2.2017\n",
      "Epoch: 1, Index: 153, Loss: 4.5169\n",
      "Epoch: 1, Index: 154, Loss: 4.0565\n",
      "Epoch: 1, Index: 155, Loss: 0.3605\n",
      "Epoch: 1, Index: 156, Loss: 2.5332\n",
      "Epoch: 1, Index: 157, Loss: 2.6976\n",
      "Epoch: 1, Index: 158, Loss: 0.7319\n",
      "Epoch: 1, Index: 159, Loss: 1.9178\n",
      "Epoch: 1, Index: 160, Loss: 1.0247\n",
      "Epoch: 1, Index: 161, Loss: 0.9298\n",
      "Epoch: 1, Index: 162, Loss: 0.5622\n",
      "Epoch: 1, Index: 163, Loss: 0.1921\n",
      "Epoch: 1, Index: 164, Loss: 0.1882\n",
      "Epoch: 1, Index: 165, Loss: 0.0385\n",
      "Epoch: 1, Index: 166, Loss: 5.3068\n",
      "Epoch: 1, Index: 167, Loss: 1.7333\n",
      "Epoch: 1, Index: 168, Loss: 6.0595\n",
      "Epoch: 1, Index: 169, Loss: 2.0099\n",
      "Epoch: 1, Index: 170, Loss: 2.7007\n",
      "Epoch: 1, Index: 171, Loss: 2.1453\n",
      "Epoch: 1, Index: 172, Loss: 3.3785\n",
      "Epoch: 1, Index: 173, Loss: 0.0730\n",
      "Epoch: 1, Index: 174, Loss: 5.0428\n",
      "Epoch: 1, Index: 175, Loss: 3.4091\n",
      "Epoch: 1, Index: 176, Loss: 3.9754\n",
      "Epoch: 1, Index: 177, Loss: 0.3973\n",
      "Epoch: 1, Index: 178, Loss: 0.6972\n",
      "Epoch: 1, Index: 179, Loss: 5.2042\n",
      "Epoch: 1, Index: 180, Loss: 8.0720\n",
      "Epoch: 1, Index: 181, Loss: 1.0132\n",
      "Epoch: 1, Index: 182, Loss: 3.8113\n",
      "Epoch: 1, Index: 183, Loss: 0.5849\n",
      "Epoch: 1, Index: 184, Loss: 4.2577\n",
      "Epoch: 1, Index: 185, Loss: 8.1770\n",
      "Epoch: 1, Index: 186, Loss: 5.9634\n",
      "Epoch: 1, Index: 187, Loss: 6.1860\n",
      "Epoch: 1, Index: 188, Loss: 0.7809\n",
      "Epoch: 1, Index: 189, Loss: 2.5445\n",
      "Epoch: 1, Index: 190, Loss: 0.8671\n",
      "Epoch: 1, Index: 191, Loss: 8.2976\n",
      "Epoch: 1, Index: 192, Loss: 0.3283\n",
      "Epoch: 1, Index: 193, Loss: 6.2516\n",
      "Epoch: 1, Index: 194, Loss: 5.1735\n",
      "Epoch: 1, Index: 195, Loss: 1.4562\n",
      "Epoch: 1, Index: 196, Loss: 0.4814\n",
      "Epoch: 1, Index: 197, Loss: 0.0032\n",
      "Epoch: 1, Index: 198, Loss: 2.8890\n",
      "Epoch: 1, Index: 199, Loss: 0.6475\n",
      "Epoch: 1, Index: 200, Loss: 5.1310\n",
      "Epoch: 1, Index: 201, Loss: 6.2087\n",
      "Epoch: 1, Index: 202, Loss: 1.4311\n",
      "Epoch: 1, Index: 203, Loss: 2.8908\n",
      "Epoch: 1, Index: 204, Loss: 1.0246\n",
      "Epoch: 1, Index: 205, Loss: 2.2903\n",
      "Epoch: 1, Index: 206, Loss: 0.2539\n",
      "Epoch: 1, Index: 207, Loss: 1.9377\n",
      "Epoch: 1, Index: 208, Loss: 2.5620\n",
      "Epoch: 1, Index: 209, Loss: 1.7990\n",
      "Epoch: 1, Index: 210, Loss: 3.0121\n",
      "Epoch: 1, Index: 211, Loss: 1.7389\n",
      "Epoch: 1, Index: 212, Loss: 5.4907\n",
      "Epoch: 1, Index: 213, Loss: 0.2735\n",
      "Epoch: 1, Index: 214, Loss: 0.1987\n",
      "Epoch: 1, Index: 215, Loss: 2.7120\n",
      "Epoch: 1, Index: 216, Loss: 6.4507\n",
      "Epoch: 1, Index: 217, Loss: 0.4356\n",
      "Epoch: 1, Index: 218, Loss: 5.4115\n",
      "Epoch: 1, Index: 219, Loss: 11.7174\n",
      "Epoch: 1, Index: 220, Loss: 14.3938\n",
      "Epoch: 1, Index: 221, Loss: 1.1820\n",
      "Epoch: 1, Index: 222, Loss: 1.1237\n",
      "Epoch: 1, Index: 223, Loss: 1.7736\n",
      "Epoch: 1, Index: 224, Loss: 2.3264\n",
      "Epoch: 1, Index: 225, Loss: 2.5754\n",
      "Epoch: 1, Index: 226, Loss: 0.2843\n",
      "Epoch: 1, Index: 227, Loss: 2.9024\n",
      "Epoch: 1, Index: 228, Loss: 5.2882\n",
      "Epoch: 1, Index: 229, Loss: 6.7111\n",
      "Epoch: 1, Index: 230, Loss: 0.5265\n",
      "Epoch: 1, Index: 231, Loss: 6.6731\n",
      "Epoch: 1, Index: 232, Loss: 1.8442\n",
      "Epoch: 1, Index: 233, Loss: 1.8590\n",
      "Epoch: 1, Index: 234, Loss: 2.1703\n",
      "Epoch: 1, Index: 235, Loss: 2.8898\n",
      "Epoch: 1, Index: 236, Loss: 1.3986\n",
      "Epoch: 1, Index: 237, Loss: 0.2972\n",
      "Epoch: 1, Index: 238, Loss: 1.1359\n",
      "Epoch: 1, Index: 239, Loss: 1.1642\n",
      "Epoch: 1, Index: 240, Loss: 1.4543\n",
      "Epoch: 1, Index: 241, Loss: 1.5159\n",
      "Epoch: 1, Index: 242, Loss: 0.0257\n",
      "Epoch: 1, Index: 243, Loss: 0.8699\n",
      "Epoch: 1, Index: 244, Loss: 3.0761\n",
      "Epoch: 1, Index: 245, Loss: 1.2581\n",
      "Epoch: 1, Index: 246, Loss: 3.7966\n",
      "Epoch: 1, Index: 247, Loss: 6.4837\n",
      "Epoch: 1, Index: 248, Loss: 2.2686\n",
      "Epoch: 1, Index: 249, Loss: 0.5727\n",
      "Epoch: 1, Index: 250, Loss: 0.9661\n",
      "Epoch: 1, Index: 251, Loss: 2.2150\n",
      "Epoch: 1, Index: 252, Loss: 0.5024\n",
      "Epoch: 1, Index: 253, Loss: 3.1405\n",
      "Epoch: 1, Index: 254, Loss: 1.5283\n",
      "Epoch: 1, Index: 255, Loss: 0.1196\n",
      "Epoch: 1, Index: 256, Loss: 1.1083\n",
      "Epoch: 1, Index: 257, Loss: 0.1000\n",
      "Epoch: 1, Index: 258, Loss: 0.0790\n",
      "Epoch: 1, Index: 259, Loss: 2.7151\n",
      "Epoch: 1, Index: 260, Loss: 2.9756\n",
      "Epoch: 1, Index: 261, Loss: 6.1688\n",
      "Epoch: 1, Index: 262, Loss: 0.9760\n",
      "Epoch: 1, Index: 263, Loss: 2.9901\n",
      "Epoch: 1, Index: 264, Loss: 4.5409\n",
      "Epoch: 1, Index: 265, Loss: 0.0961\n",
      "Epoch: 1, Index: 266, Loss: 3.4603\n",
      "Epoch: 1, Index: 267, Loss: 1.9515\n",
      "Epoch: 1, Index: 268, Loss: 0.4577\n",
      "Epoch: 1, Index: 269, Loss: 0.1648\n",
      "Epoch: 1, Index: 270, Loss: 9.4801\n",
      "Epoch: 1, Index: 271, Loss: 2.9240\n",
      "Epoch: 1, Index: 272, Loss: 4.5022\n",
      "Epoch: 1, Index: 273, Loss: 5.6966\n",
      "Epoch: 1, Index: 274, Loss: 3.0221\n",
      "Epoch: 1, Index: 275, Loss: 2.8715\n",
      "Epoch: 1, Index: 276, Loss: 1.1466\n",
      "Epoch: 1, Index: 277, Loss: 1.5509\n",
      "Epoch: 1, Index: 278, Loss: 1.0016\n",
      "Epoch: 1, Index: 279, Loss: 1.1209\n",
      "Epoch: 1, Index: 280, Loss: 4.4841\n",
      "Epoch: 1, Index: 281, Loss: 1.4720\n",
      "Epoch: 1, Index: 282, Loss: 2.0726\n",
      "Epoch: 1, Index: 283, Loss: 1.8276\n",
      "Epoch: 1, Index: 284, Loss: 0.1441\n",
      "Epoch: 1, Index: 285, Loss: 3.1591\n",
      "Epoch: 1, Index: 286, Loss: 0.5010\n",
      "Epoch: 1, Index: 287, Loss: 5.6480\n",
      "Epoch: 1, Index: 288, Loss: 0.9250\n",
      "Epoch: 1, Index: 289, Loss: 2.2618\n",
      "Epoch: 1, Index: 290, Loss: 0.4319\n",
      "Epoch: 1, Index: 291, Loss: 3.0538\n",
      "Epoch: 1, Index: 292, Loss: 2.4387\n",
      "Epoch: 1, Index: 293, Loss: 3.7319\n",
      "Epoch: 1, Index: 294, Loss: 0.8296\n",
      "Epoch: 1, Index: 295, Loss: 1.2242\n",
      "Epoch: 1, Index: 296, Loss: 0.9874\n",
      "Epoch: 1, Index: 297, Loss: 0.2268\n",
      "Epoch: 1, Index: 298, Loss: 2.9700\n",
      "Epoch: 1, Index: 299, Loss: 0.5482\n",
      "Epoch: 1, Index: 300, Loss: 0.7595\n",
      "Epoch: 1, Index: 301, Loss: 1.6312\n",
      "Epoch: 1, Index: 302, Loss: 0.1333\n",
      "Epoch: 1, Index: 303, Loss: 1.4764\n",
      "Epoch: 1, Index: 304, Loss: 1.6938\n",
      "Epoch: 1, Index: 305, Loss: 0.2384\n",
      "Epoch: 1, Index: 306, Loss: 0.3235\n",
      "Epoch: 1, Index: 307, Loss: 1.6435\n",
      "Epoch: 1, Index: 308, Loss: 2.0831\n",
      "Epoch: 1, Index: 309, Loss: 0.4907\n",
      "Epoch: 1, Index: 310, Loss: 1.9761\n",
      "Epoch: 1, Index: 311, Loss: 0.0421\n",
      "Epoch: 1, Index: 312, Loss: 2.4966\n",
      "Epoch: 1, Index: 313, Loss: 2.1166\n",
      "Epoch: 1, Index: 314, Loss: 2.9031\n",
      "Epoch: 1, Index: 315, Loss: 0.0837\n",
      "Epoch: 1, Index: 316, Loss: 0.1211\n",
      "Epoch: 1, Index: 317, Loss: 0.6668\n",
      "Epoch: 1, Index: 318, Loss: 1.6220\n",
      "Epoch: 1, Index: 319, Loss: 1.3018\n",
      "Epoch: 1, Index: 320, Loss: 2.6333\n",
      "Epoch: 1, Index: 321, Loss: 1.5194\n",
      "Epoch: 1, Index: 322, Loss: 0.8125\n",
      "Epoch: 1, Index: 323, Loss: 1.6975\n",
      "Epoch: 1, Index: 324, Loss: 1.8644\n",
      "Epoch: 1, Index: 325, Loss: 4.7287\n",
      "Epoch: 1, Index: 326, Loss: 0.4429\n",
      "Epoch: 1, Index: 327, Loss: 0.3679\n",
      "Epoch: 1, Index: 328, Loss: 2.2958\n",
      "Epoch: 1, Index: 329, Loss: 0.1685\n",
      "Epoch: 1, Index: 330, Loss: 2.3050\n",
      "Epoch: 1, Index: 331, Loss: 6.1603\n",
      "Epoch: 1, Index: 332, Loss: 1.4825\n",
      "Epoch: 1, Index: 333, Loss: 2.1868\n",
      "Epoch: 1, Index: 334, Loss: 0.9045\n",
      "Epoch: 1, Index: 335, Loss: 4.0778\n",
      "Epoch: 1, Index: 336, Loss: 1.2199\n",
      "Epoch: 1, Index: 337, Loss: 1.0916\n",
      "Epoch: 1, Index: 338, Loss: 2.9979\n",
      "Epoch: 1, Index: 339, Loss: 0.1517\n",
      "Epoch: 1, Index: 340, Loss: 1.4713\n",
      "Epoch: 1, Index: 341, Loss: 2.7425\n",
      "Epoch: 1, Index: 342, Loss: 1.8781\n",
      "Epoch: 1, Index: 343, Loss: 0.5969\n",
      "Epoch: 1, Index: 344, Loss: 1.4457\n",
      "Epoch: 1, Index: 345, Loss: 1.4260\n",
      "Epoch: 1, Index: 346, Loss: 1.1061\n",
      "Epoch: 1, Index: 347, Loss: 1.6640\n",
      "Epoch: 1, Index: 348, Loss: 4.2556\n",
      "Epoch: 1, Index: 349, Loss: 3.0414\n",
      "Epoch: 1, Index: 350, Loss: 1.2802\n",
      "Epoch: 1, Index: 351, Loss: 1.4889\n",
      "Epoch: 1, Index: 352, Loss: 4.1534\n",
      "Epoch: 1, Index: 353, Loss: 4.2989\n",
      "Epoch: 1, Index: 354, Loss: 0.1433\n",
      "Epoch: 1, Index: 355, Loss: 0.0219\n",
      "Epoch: 1, Index: 356, Loss: 1.6743\n",
      "Epoch: 1, Index: 357, Loss: 3.1972\n",
      "Epoch: 1, Index: 358, Loss: 3.5412\n",
      "Epoch: 1, Index: 359, Loss: 1.6846\n",
      "Epoch: 1, Index: 360, Loss: 3.7377\n",
      "Epoch: 1, Index: 361, Loss: 0.9063\n",
      "Epoch: 1, Index: 362, Loss: 0.8904\n",
      "Epoch: 1, Index: 363, Loss: 0.0140\n",
      "Epoch: 1, Index: 364, Loss: 3.9195\n",
      "Epoch: 1, Index: 365, Loss: 2.1790\n",
      "Epoch: 1, Index: 366, Loss: 0.7386\n",
      "Epoch: 1, Index: 367, Loss: 0.1092\n",
      "Epoch: 1, Index: 368, Loss: 2.5472\n",
      "Epoch: 1, Index: 369, Loss: 4.9359\n",
      "Epoch: 1, Index: 370, Loss: 2.0846\n",
      "Epoch: 1, Index: 371, Loss: 1.7718\n",
      "Epoch: 1, Index: 372, Loss: 0.0498\n",
      "Epoch: 1, Index: 373, Loss: 1.1952\n",
      "Epoch: 1, Index: 374, Loss: 0.0574\n",
      "Epoch: 1, Index: 375, Loss: 0.3892\n",
      "Epoch: 1, Index: 376, Loss: 0.4246\n",
      "Epoch: 1, Index: 377, Loss: 0.0591\n",
      "Epoch: 1, Index: 378, Loss: 0.5415\n",
      "Epoch: 1, Index: 379, Loss: 0.0216\n",
      "Epoch: 1, Index: 380, Loss: 1.3864\n",
      "Epoch: 1, Index: 381, Loss: 5.7977\n",
      "Epoch: 1, Index: 382, Loss: 2.0105\n",
      "Epoch: 1, Index: 383, Loss: 0.4187\n",
      "Epoch: 1, Index: 384, Loss: 2.3045\n",
      "Epoch: 1, Index: 385, Loss: 2.4089\n",
      "Epoch: 1, Index: 386, Loss: 2.4469\n",
      "Epoch: 1, Index: 387, Loss: 0.0271\n",
      "Epoch: 1, Index: 388, Loss: 0.3692\n",
      "Epoch: 1, Index: 389, Loss: 1.2977\n",
      "Epoch: 1, Index: 390, Loss: 2.0122\n",
      "Epoch: 1, Index: 391, Loss: 0.3056\n",
      "Epoch: 1, Index: 392, Loss: 0.5760\n",
      "Epoch: 1, Index: 393, Loss: 2.0310\n",
      "Epoch: 1, Index: 394, Loss: 0.7270\n",
      "Epoch: 1, Index: 395, Loss: 0.1198\n",
      "Epoch: 1, Index: 396, Loss: 17.4763\n",
      "Epoch: 1, Index: 397, Loss: 0.0510\n",
      "Epoch: 1, Index: 398, Loss: 1.7180\n",
      "Epoch: 1, Index: 399, Loss: 2.3569\n",
      "Epoch: 1, Index: 400, Loss: 0.0414\n",
      "Epoch: 1, Index: 401, Loss: 3.4320\n",
      "Epoch: 1, Index: 402, Loss: 0.0144\n",
      "Epoch: 1, Index: 403, Loss: 3.9242\n",
      "Epoch: 1, Index: 404, Loss: 0.3345\n",
      "Epoch: 1, Index: 405, Loss: 2.0964\n",
      "Epoch: 1, Index: 406, Loss: 0.8898\n",
      "Epoch: 1, Index: 407, Loss: 1.1676\n",
      "Epoch: 1, Index: 408, Loss: 0.4045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ba75ab28cd480d95dcbdb45e67a366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Index: 0, Loss: 0.8907\n",
      "Epoch: 2, Index: 1, Loss: 0.2188\n",
      "Epoch: 2, Index: 2, Loss: 2.6096\n",
      "Epoch: 2, Index: 3, Loss: 0.2577\n",
      "Epoch: 2, Index: 4, Loss: 1.5382\n",
      "Epoch: 2, Index: 5, Loss: 0.8263\n",
      "Epoch: 2, Index: 6, Loss: 2.2758\n",
      "Epoch: 2, Index: 7, Loss: 2.1016\n",
      "Epoch: 2, Index: 8, Loss: 3.9134\n",
      "Epoch: 2, Index: 9, Loss: 1.4010\n",
      "Epoch: 2, Index: 10, Loss: 2.1411\n",
      "Epoch: 2, Index: 11, Loss: 1.1385\n",
      "Epoch: 2, Index: 12, Loss: 1.8884\n",
      "Epoch: 2, Index: 13, Loss: 0.3844\n",
      "Epoch: 2, Index: 14, Loss: 1.4854\n",
      "Epoch: 2, Index: 15, Loss: 0.1406\n",
      "Epoch: 2, Index: 16, Loss: 0.3395\n",
      "Epoch: 2, Index: 17, Loss: 2.5658\n",
      "Epoch: 2, Index: 18, Loss: 2.4869\n",
      "Epoch: 2, Index: 19, Loss: 0.4774\n",
      "Epoch: 2, Index: 20, Loss: 0.1233\n",
      "Epoch: 2, Index: 21, Loss: 1.4606\n",
      "Epoch: 2, Index: 22, Loss: 1.8459\n",
      "Epoch: 2, Index: 23, Loss: 3.3059\n",
      "Epoch: 2, Index: 24, Loss: 3.7524\n",
      "Epoch: 2, Index: 25, Loss: 4.4331\n",
      "Epoch: 2, Index: 26, Loss: 2.6486\n",
      "Epoch: 2, Index: 27, Loss: 10.3429\n",
      "Epoch: 2, Index: 28, Loss: 0.9027\n",
      "Epoch: 2, Index: 29, Loss: 0.8260\n",
      "Epoch: 2, Index: 30, Loss: 0.3716\n",
      "Epoch: 2, Index: 31, Loss: 2.3979\n",
      "Epoch: 2, Index: 32, Loss: 1.9825\n",
      "Epoch: 2, Index: 33, Loss: 1.4223\n",
      "Epoch: 2, Index: 34, Loss: 0.4200\n",
      "Epoch: 2, Index: 35, Loss: 0.3048\n",
      "Epoch: 2, Index: 36, Loss: 1.1055\n",
      "Epoch: 2, Index: 37, Loss: 2.6149\n",
      "Epoch: 2, Index: 38, Loss: 2.1534\n",
      "Epoch: 2, Index: 39, Loss: 3.2693\n",
      "Epoch: 2, Index: 40, Loss: 1.6407\n",
      "Epoch: 2, Index: 41, Loss: 0.6131\n",
      "Epoch: 2, Index: 42, Loss: 2.9141\n",
      "Epoch: 2, Index: 43, Loss: 0.5574\n",
      "Epoch: 2, Index: 44, Loss: 3.5888\n",
      "Epoch: 2, Index: 45, Loss: 1.5123\n",
      "Epoch: 2, Index: 46, Loss: 0.0191\n",
      "Epoch: 2, Index: 47, Loss: 0.9281\n",
      "Epoch: 2, Index: 48, Loss: 0.3597\n",
      "Epoch: 2, Index: 49, Loss: 2.1701\n",
      "Epoch: 2, Index: 50, Loss: 1.4635\n",
      "Epoch: 2, Index: 51, Loss: 0.3481\n",
      "Epoch: 2, Index: 52, Loss: 0.7942\n",
      "Epoch: 2, Index: 53, Loss: 9.2164\n",
      "Epoch: 2, Index: 54, Loss: 0.3513\n",
      "Epoch: 2, Index: 55, Loss: 2.5296\n",
      "Epoch: 2, Index: 56, Loss: 0.5738\n",
      "Epoch: 2, Index: 57, Loss: 4.8736\n",
      "Epoch: 2, Index: 58, Loss: 1.8812\n",
      "Epoch: 2, Index: 59, Loss: 0.1908\n",
      "Epoch: 2, Index: 60, Loss: 1.1611\n",
      "Epoch: 2, Index: 61, Loss: 11.3993\n",
      "Epoch: 2, Index: 62, Loss: 0.2590\n",
      "Epoch: 2, Index: 63, Loss: 1.6645\n",
      "Epoch: 2, Index: 64, Loss: 0.2704\n",
      "Epoch: 2, Index: 65, Loss: 0.0486\n",
      "Epoch: 2, Index: 66, Loss: 0.5490\n",
      "Epoch: 2, Index: 67, Loss: 2.1597\n",
      "Epoch: 2, Index: 68, Loss: 1.2875\n",
      "Epoch: 2, Index: 69, Loss: 1.4211\n",
      "Epoch: 2, Index: 70, Loss: 0.2461\n",
      "Epoch: 2, Index: 71, Loss: 0.0815\n",
      "Epoch: 2, Index: 72, Loss: 0.0683\n",
      "Epoch: 2, Index: 73, Loss: 0.7954\n",
      "Epoch: 2, Index: 74, Loss: 1.0931\n",
      "Epoch: 2, Index: 75, Loss: 1.5359\n",
      "Epoch: 2, Index: 76, Loss: 1.9279\n",
      "Epoch: 2, Index: 77, Loss: 2.0189\n",
      "Epoch: 2, Index: 78, Loss: 3.8661\n",
      "Epoch: 2, Index: 79, Loss: 0.1803\n",
      "Epoch: 2, Index: 80, Loss: 1.1247\n",
      "Epoch: 2, Index: 81, Loss: 4.2754\n",
      "Epoch: 2, Index: 82, Loss: 1.4521\n",
      "Epoch: 2, Index: 83, Loss: 9.3255\n",
      "Epoch: 2, Index: 84, Loss: 1.7907\n",
      "Epoch: 2, Index: 85, Loss: 1.8265\n",
      "Epoch: 2, Index: 86, Loss: 2.9731\n",
      "Epoch: 2, Index: 87, Loss: 0.9583\n",
      "Epoch: 2, Index: 88, Loss: 6.0144\n",
      "Epoch: 2, Index: 89, Loss: 0.7095\n",
      "Epoch: 2, Index: 90, Loss: 0.4067\n",
      "Epoch: 2, Index: 91, Loss: 1.2505\n",
      "Epoch: 2, Index: 92, Loss: 0.1994\n",
      "Epoch: 2, Index: 93, Loss: 0.0497\n",
      "Epoch: 2, Index: 94, Loss: 0.5908\n",
      "Epoch: 2, Index: 95, Loss: 2.5427\n",
      "Epoch: 2, Index: 96, Loss: 1.5502\n",
      "Epoch: 2, Index: 97, Loss: 0.0577\n",
      "Epoch: 2, Index: 98, Loss: 4.4628\n",
      "Epoch: 2, Index: 99, Loss: 1.1021\n",
      "Epoch: 2, Index: 100, Loss: 1.6727\n",
      "Epoch: 2, Index: 101, Loss: 0.5001\n",
      "Epoch: 2, Index: 102, Loss: 4.1648\n",
      "Epoch: 2, Index: 103, Loss: 0.4828\n",
      "Epoch: 2, Index: 104, Loss: 2.7575\n",
      "Epoch: 2, Index: 105, Loss: 1.4896\n",
      "Epoch: 2, Index: 106, Loss: 9.8149\n",
      "Epoch: 2, Index: 107, Loss: 0.2750\n",
      "Epoch: 2, Index: 108, Loss: 4.7853\n",
      "Epoch: 2, Index: 109, Loss: 1.6082\n",
      "Epoch: 2, Index: 110, Loss: 0.0740\n",
      "Epoch: 2, Index: 111, Loss: 0.5574\n",
      "Epoch: 2, Index: 112, Loss: 4.2932\n",
      "Epoch: 2, Index: 113, Loss: 0.2081\n",
      "Epoch: 2, Index: 114, Loss: 6.9904\n",
      "Epoch: 2, Index: 115, Loss: 7.1634\n",
      "Epoch: 2, Index: 116, Loss: 0.4868\n",
      "Epoch: 2, Index: 117, Loss: 0.4557\n",
      "Epoch: 2, Index: 118, Loss: 2.3301\n",
      "Epoch: 2, Index: 119, Loss: 9.5712\n",
      "Epoch: 2, Index: 120, Loss: 0.2806\n",
      "Epoch: 2, Index: 121, Loss: 0.4912\n",
      "Epoch: 2, Index: 122, Loss: 4.2025\n",
      "Epoch: 2, Index: 123, Loss: 3.4547\n",
      "Epoch: 2, Index: 124, Loss: 1.8492\n",
      "Epoch: 2, Index: 125, Loss: 0.5057\n",
      "Epoch: 2, Index: 126, Loss: 1.2868\n",
      "Epoch: 2, Index: 127, Loss: 2.2850\n",
      "Epoch: 2, Index: 128, Loss: 4.7562\n",
      "Epoch: 2, Index: 129, Loss: 0.5702\n",
      "Epoch: 2, Index: 130, Loss: 0.4943\n",
      "Epoch: 2, Index: 131, Loss: 4.5084\n",
      "Epoch: 2, Index: 132, Loss: 1.2173\n",
      "Epoch: 2, Index: 133, Loss: 3.2554\n",
      "Epoch: 2, Index: 134, Loss: 0.0620\n",
      "Epoch: 2, Index: 135, Loss: 3.3739\n",
      "Epoch: 2, Index: 136, Loss: 3.9553\n",
      "Epoch: 2, Index: 137, Loss: 10.7065\n",
      "Epoch: 2, Index: 138, Loss: 4.3648\n",
      "Epoch: 2, Index: 139, Loss: 7.8509\n",
      "Epoch: 2, Index: 140, Loss: 0.5766\n",
      "Epoch: 2, Index: 141, Loss: 5.6640\n",
      "Epoch: 2, Index: 142, Loss: 0.2933\n",
      "Epoch: 2, Index: 143, Loss: 0.7094\n",
      "Epoch: 2, Index: 144, Loss: 1.1838\n",
      "Epoch: 2, Index: 145, Loss: 3.4036\n",
      "Epoch: 2, Index: 146, Loss: 1.3707\n",
      "Epoch: 2, Index: 147, Loss: 4.6596\n",
      "Epoch: 2, Index: 148, Loss: 0.9529\n",
      "Epoch: 2, Index: 149, Loss: 3.0706\n",
      "Epoch: 2, Index: 150, Loss: 2.4340\n",
      "Epoch: 2, Index: 151, Loss: 1.0746\n",
      "Epoch: 2, Index: 152, Loss: 1.4147\n",
      "Epoch: 2, Index: 153, Loss: 3.0579\n",
      "Epoch: 2, Index: 154, Loss: 4.1667\n",
      "Epoch: 2, Index: 155, Loss: 5.2579\n",
      "Epoch: 2, Index: 156, Loss: 1.8932\n",
      "Epoch: 2, Index: 157, Loss: 0.7091\n",
      "Epoch: 2, Index: 158, Loss: 0.0999\n",
      "Epoch: 2, Index: 159, Loss: 3.0712\n",
      "Epoch: 2, Index: 160, Loss: 2.5501\n",
      "Epoch: 2, Index: 161, Loss: 1.6414\n",
      "Epoch: 2, Index: 162, Loss: 2.3060\n",
      "Epoch: 2, Index: 163, Loss: 6.7206\n",
      "Epoch: 2, Index: 164, Loss: 0.2259\n",
      "Epoch: 2, Index: 165, Loss: 17.9874\n",
      "Epoch: 2, Index: 166, Loss: 0.0617\n",
      "Epoch: 2, Index: 167, Loss: 2.6853\n",
      "Epoch: 2, Index: 168, Loss: 0.4577\n",
      "Epoch: 2, Index: 169, Loss: 2.8997\n",
      "Epoch: 2, Index: 170, Loss: 2.6773\n",
      "Epoch: 2, Index: 171, Loss: 0.3475\n",
      "Epoch: 2, Index: 172, Loss: 2.7965\n",
      "Epoch: 2, Index: 173, Loss: 1.6749\n",
      "Epoch: 2, Index: 174, Loss: 1.3664\n",
      "Epoch: 2, Index: 175, Loss: 0.1161\n",
      "Epoch: 2, Index: 176, Loss: 0.5013\n",
      "Epoch: 2, Index: 177, Loss: 3.5061\n",
      "Epoch: 2, Index: 178, Loss: 2.1003\n",
      "Epoch: 2, Index: 179, Loss: 3.4338\n",
      "Epoch: 2, Index: 180, Loss: 6.1764\n",
      "Epoch: 2, Index: 181, Loss: 0.8373\n",
      "Epoch: 2, Index: 182, Loss: 0.1276\n",
      "Epoch: 2, Index: 183, Loss: 2.9882\n",
      "Epoch: 2, Index: 184, Loss: 1.3668\n",
      "Epoch: 2, Index: 185, Loss: 4.4593\n",
      "Epoch: 2, Index: 186, Loss: 0.8483\n",
      "Epoch: 2, Index: 187, Loss: 2.8408\n",
      "Epoch: 2, Index: 188, Loss: 0.7587\n",
      "Epoch: 2, Index: 189, Loss: 0.5469\n",
      "Epoch: 2, Index: 190, Loss: 1.4087\n",
      "Epoch: 2, Index: 191, Loss: 1.9175\n",
      "Epoch: 2, Index: 192, Loss: 3.9260\n",
      "Epoch: 2, Index: 193, Loss: 1.0601\n",
      "Epoch: 2, Index: 194, Loss: 1.3120\n",
      "Epoch: 2, Index: 195, Loss: 0.3793\n",
      "Epoch: 2, Index: 196, Loss: 0.9908\n",
      "Epoch: 2, Index: 197, Loss: 0.0483\n",
      "Epoch: 2, Index: 198, Loss: 1.4419\n",
      "Epoch: 2, Index: 199, Loss: 8.8721\n",
      "Epoch: 2, Index: 200, Loss: 0.0161\n",
      "Epoch: 2, Index: 201, Loss: 1.9890\n",
      "Epoch: 2, Index: 202, Loss: 1.6409\n",
      "Epoch: 2, Index: 203, Loss: 2.8159\n",
      "Epoch: 2, Index: 204, Loss: 4.1433\n",
      "Epoch: 2, Index: 205, Loss: 2.8427\n",
      "Epoch: 2, Index: 206, Loss: 1.9967\n",
      "Epoch: 2, Index: 207, Loss: 0.1504\n",
      "Epoch: 2, Index: 208, Loss: 0.4022\n",
      "Epoch: 2, Index: 209, Loss: 0.2160\n",
      "Epoch: 2, Index: 210, Loss: 1.4617\n",
      "Epoch: 2, Index: 211, Loss: 0.3433\n",
      "Epoch: 2, Index: 212, Loss: 0.9615\n",
      "Epoch: 2, Index: 213, Loss: 0.5493\n",
      "Epoch: 2, Index: 214, Loss: 2.0897\n",
      "Epoch: 2, Index: 215, Loss: 0.1081\n",
      "Epoch: 2, Index: 216, Loss: 0.0930\n",
      "Epoch: 2, Index: 217, Loss: 1.6481\n",
      "Epoch: 2, Index: 218, Loss: 0.1434\n",
      "Epoch: 2, Index: 219, Loss: 2.7881\n",
      "Epoch: 2, Index: 220, Loss: 7.4890\n",
      "Epoch: 2, Index: 221, Loss: 1.4746\n",
      "Epoch: 2, Index: 222, Loss: 0.1773\n",
      "Epoch: 2, Index: 223, Loss: 0.4833\n",
      "Epoch: 2, Index: 224, Loss: 3.8166\n",
      "Epoch: 2, Index: 225, Loss: 2.8503\n",
      "Epoch: 2, Index: 226, Loss: 0.7843\n",
      "Epoch: 2, Index: 227, Loss: 0.6630\n",
      "Epoch: 2, Index: 228, Loss: 0.8343\n",
      "Epoch: 2, Index: 229, Loss: 2.7735\n",
      "Epoch: 2, Index: 230, Loss: 0.4354\n",
      "Epoch: 2, Index: 231, Loss: 2.9360\n",
      "Epoch: 2, Index: 232, Loss: 0.0685\n",
      "Epoch: 2, Index: 233, Loss: 0.4587\n",
      "Epoch: 2, Index: 234, Loss: 0.5793\n",
      "Epoch: 2, Index: 235, Loss: 0.0973\n",
      "Epoch: 2, Index: 236, Loss: 5.6467\n",
      "Epoch: 2, Index: 237, Loss: 0.2992\n",
      "Epoch: 2, Index: 238, Loss: 3.5001\n",
      "Epoch: 2, Index: 239, Loss: 1.1395\n",
      "Epoch: 2, Index: 240, Loss: 0.7095\n",
      "Epoch: 2, Index: 241, Loss: 0.0315\n",
      "Epoch: 2, Index: 242, Loss: 1.9371\n",
      "Epoch: 2, Index: 243, Loss: 1.7096\n",
      "Epoch: 2, Index: 244, Loss: 0.3929\n",
      "Epoch: 2, Index: 245, Loss: 0.1439\n",
      "Epoch: 2, Index: 246, Loss: 1.1383\n",
      "Epoch: 2, Index: 247, Loss: 0.0595\n",
      "Epoch: 2, Index: 248, Loss: 0.2929\n",
      "Epoch: 2, Index: 249, Loss: 0.9171\n",
      "Epoch: 2, Index: 250, Loss: 6.0469\n",
      "Epoch: 2, Index: 251, Loss: 0.2769\n",
      "Epoch: 2, Index: 252, Loss: 1.7478\n",
      "Epoch: 2, Index: 253, Loss: 0.2438\n",
      "Epoch: 2, Index: 254, Loss: 0.7156\n",
      "Epoch: 2, Index: 255, Loss: 0.9469\n",
      "Epoch: 2, Index: 256, Loss: 1.5676\n",
      "Epoch: 2, Index: 257, Loss: 22.0156\n",
      "Epoch: 2, Index: 258, Loss: 1.3568\n",
      "Epoch: 2, Index: 259, Loss: 3.2643\n",
      "Epoch: 2, Index: 260, Loss: 2.1468\n",
      "Epoch: 2, Index: 261, Loss: 4.3379\n",
      "Epoch: 2, Index: 262, Loss: 3.1339\n",
      "Epoch: 2, Index: 263, Loss: 2.8828\n",
      "Epoch: 2, Index: 264, Loss: 2.8431\n",
      "Epoch: 2, Index: 265, Loss: 0.9957\n",
      "Epoch: 2, Index: 266, Loss: 0.9151\n",
      "Epoch: 2, Index: 267, Loss: 1.8120\n",
      "Epoch: 2, Index: 268, Loss: 0.5376\n",
      "Epoch: 2, Index: 269, Loss: 2.5692\n",
      "Epoch: 2, Index: 270, Loss: 0.4037\n",
      "Epoch: 2, Index: 271, Loss: 1.9556\n",
      "Epoch: 2, Index: 272, Loss: 2.0202\n",
      "Epoch: 2, Index: 273, Loss: 6.8513\n",
      "Epoch: 2, Index: 274, Loss: 4.2667\n",
      "Epoch: 2, Index: 275, Loss: 0.6331\n",
      "Epoch: 2, Index: 276, Loss: 0.2008\n",
      "Epoch: 2, Index: 277, Loss: 3.5337\n",
      "Epoch: 2, Index: 278, Loss: 0.4648\n",
      "Epoch: 2, Index: 279, Loss: 1.8556\n",
      "Epoch: 2, Index: 280, Loss: 1.8673\n",
      "Epoch: 2, Index: 281, Loss: 2.1599\n",
      "Epoch: 2, Index: 282, Loss: 2.8671\n",
      "Epoch: 2, Index: 283, Loss: 1.0437\n",
      "Epoch: 2, Index: 284, Loss: 3.4868\n",
      "Epoch: 2, Index: 285, Loss: 2.6789\n",
      "Epoch: 2, Index: 286, Loss: 0.0808\n",
      "Epoch: 2, Index: 287, Loss: 4.5452\n",
      "Epoch: 2, Index: 288, Loss: 4.8658\n",
      "Epoch: 2, Index: 289, Loss: 6.5467\n",
      "Epoch: 2, Index: 290, Loss: 0.4698\n",
      "Epoch: 2, Index: 291, Loss: 3.0452\n",
      "Epoch: 2, Index: 292, Loss: 4.9823\n",
      "Epoch: 2, Index: 293, Loss: 0.8400\n",
      "Epoch: 2, Index: 294, Loss: 5.9789\n",
      "Epoch: 2, Index: 295, Loss: 1.1077\n",
      "Epoch: 2, Index: 296, Loss: 3.0151\n",
      "Epoch: 2, Index: 297, Loss: 0.9648\n",
      "Epoch: 2, Index: 298, Loss: 1.6684\n",
      "Epoch: 2, Index: 299, Loss: 1.1096\n",
      "Epoch: 2, Index: 300, Loss: 0.3260\n",
      "Epoch: 2, Index: 301, Loss: 1.8678\n",
      "Epoch: 2, Index: 302, Loss: 0.5132\n",
      "Epoch: 2, Index: 303, Loss: 0.4833\n",
      "Epoch: 2, Index: 304, Loss: 1.3566\n",
      "Epoch: 2, Index: 305, Loss: 0.1571\n",
      "Epoch: 2, Index: 306, Loss: 0.4427\n",
      "Epoch: 2, Index: 307, Loss: 12.3562\n",
      "Epoch: 2, Index: 308, Loss: 0.7028\n",
      "Epoch: 2, Index: 309, Loss: 0.4474\n",
      "Epoch: 2, Index: 310, Loss: 0.6974\n",
      "Epoch: 2, Index: 311, Loss: 4.1794\n",
      "Epoch: 2, Index: 312, Loss: 6.0876\n",
      "Epoch: 2, Index: 313, Loss: 1.1084\n",
      "Epoch: 2, Index: 314, Loss: 0.0847\n",
      "Epoch: 2, Index: 315, Loss: 2.4544\n",
      "Epoch: 2, Index: 316, Loss: 0.8969\n",
      "Epoch: 2, Index: 317, Loss: 5.2766\n",
      "Epoch: 2, Index: 318, Loss: 3.0442\n",
      "Epoch: 2, Index: 319, Loss: 0.5646\n",
      "Epoch: 2, Index: 320, Loss: 1.4660\n",
      "Epoch: 2, Index: 321, Loss: 2.5337\n",
      "Epoch: 2, Index: 322, Loss: 1.4557\n",
      "Epoch: 2, Index: 323, Loss: 5.3163\n",
      "Epoch: 2, Index: 324, Loss: 2.4916\n",
      "Epoch: 2, Index: 325, Loss: 6.7786\n",
      "Epoch: 2, Index: 326, Loss: 0.8606\n",
      "Epoch: 2, Index: 327, Loss: 0.7892\n",
      "Epoch: 2, Index: 328, Loss: 2.6924\n",
      "Epoch: 2, Index: 329, Loss: 0.8059\n",
      "Epoch: 2, Index: 330, Loss: 0.0931\n",
      "Epoch: 2, Index: 331, Loss: 5.7877\n",
      "Epoch: 2, Index: 332, Loss: 0.2043\n",
      "Epoch: 2, Index: 333, Loss: 0.3808\n",
      "Epoch: 2, Index: 334, Loss: 3.5410\n",
      "Epoch: 2, Index: 335, Loss: 4.2242\n",
      "Epoch: 2, Index: 336, Loss: 3.9076\n",
      "Epoch: 2, Index: 337, Loss: 0.5003\n",
      "Epoch: 2, Index: 338, Loss: 3.8218\n",
      "Epoch: 2, Index: 339, Loss: 1.1189\n",
      "Epoch: 2, Index: 340, Loss: 1.4649\n",
      "Epoch: 2, Index: 341, Loss: 0.1644\n",
      "Epoch: 2, Index: 342, Loss: 3.7654\n",
      "Epoch: 2, Index: 343, Loss: 7.6670\n",
      "Epoch: 2, Index: 344, Loss: 0.4217\n",
      "Epoch: 2, Index: 345, Loss: 1.8890\n",
      "Epoch: 2, Index: 346, Loss: 1.3317\n",
      "Epoch: 2, Index: 347, Loss: 0.1715\n",
      "Epoch: 2, Index: 348, Loss: 0.8706\n",
      "Epoch: 2, Index: 349, Loss: 0.1276\n",
      "Epoch: 2, Index: 350, Loss: 1.5421\n",
      "Epoch: 2, Index: 351, Loss: 1.5659\n",
      "Epoch: 2, Index: 352, Loss: 2.6291\n",
      "Epoch: 2, Index: 353, Loss: 0.3343\n",
      "Epoch: 2, Index: 354, Loss: 1.9261\n",
      "Epoch: 2, Index: 355, Loss: 0.4895\n",
      "Epoch: 2, Index: 356, Loss: 1.0051\n",
      "Epoch: 2, Index: 357, Loss: 0.8194\n",
      "Epoch: 2, Index: 358, Loss: 4.0758\n",
      "Epoch: 2, Index: 359, Loss: 5.7425\n",
      "Epoch: 2, Index: 360, Loss: 0.5108\n",
      "Epoch: 2, Index: 361, Loss: 0.1545\n",
      "Epoch: 2, Index: 362, Loss: 1.1788\n",
      "Epoch: 2, Index: 363, Loss: 1.5737\n",
      "Epoch: 2, Index: 364, Loss: 1.1425\n",
      "Epoch: 2, Index: 365, Loss: 0.8465\n",
      "Epoch: 2, Index: 366, Loss: 0.9246\n",
      "Epoch: 2, Index: 367, Loss: 0.2391\n",
      "Epoch: 2, Index: 368, Loss: 0.3589\n",
      "Epoch: 2, Index: 369, Loss: 4.4614\n",
      "Epoch: 2, Index: 370, Loss: 0.8363\n",
      "Epoch: 2, Index: 371, Loss: 2.0427\n",
      "Epoch: 2, Index: 372, Loss: 1.2723\n",
      "Epoch: 2, Index: 373, Loss: 0.8361\n",
      "Epoch: 2, Index: 374, Loss: 0.5733\n",
      "Epoch: 2, Index: 375, Loss: 2.6252\n",
      "Epoch: 2, Index: 376, Loss: 0.6853\n",
      "Epoch: 2, Index: 377, Loss: 1.4622\n",
      "Epoch: 2, Index: 378, Loss: 1.2734\n",
      "Epoch: 2, Index: 379, Loss: 0.5574\n",
      "Epoch: 2, Index: 380, Loss: 0.4273\n",
      "Epoch: 2, Index: 381, Loss: 4.3689\n",
      "Epoch: 2, Index: 382, Loss: 0.6984\n",
      "Epoch: 2, Index: 383, Loss: 4.6353\n",
      "Epoch: 2, Index: 384, Loss: 0.4351\n",
      "Epoch: 2, Index: 385, Loss: 3.0323\n",
      "Epoch: 2, Index: 386, Loss: 2.4246\n",
      "Epoch: 2, Index: 387, Loss: 0.8201\n",
      "Epoch: 2, Index: 388, Loss: 0.1610\n",
      "Epoch: 2, Index: 389, Loss: 2.2735\n",
      "Epoch: 2, Index: 390, Loss: 5.1694\n",
      "Epoch: 2, Index: 391, Loss: 2.8776\n",
      "Epoch: 2, Index: 392, Loss: 3.2856\n",
      "Epoch: 2, Index: 393, Loss: 1.1993\n",
      "Epoch: 2, Index: 394, Loss: 8.3107\n",
      "Epoch: 2, Index: 395, Loss: 1.2932\n",
      "Epoch: 2, Index: 396, Loss: 1.2376\n",
      "Epoch: 2, Index: 397, Loss: 0.0401\n",
      "Epoch: 2, Index: 398, Loss: 2.4002\n",
      "Epoch: 2, Index: 399, Loss: 2.9731\n",
      "Epoch: 2, Index: 400, Loss: 1.7784\n",
      "Epoch: 2, Index: 401, Loss: 0.4771\n",
      "Epoch: 2, Index: 402, Loss: 0.5562\n",
      "Epoch: 2, Index: 403, Loss: 1.0059\n",
      "Epoch: 2, Index: 404, Loss: 0.4093\n",
      "Epoch: 2, Index: 405, Loss: 6.6016\n",
      "Epoch: 2, Index: 406, Loss: 2.8709\n",
      "Epoch: 2, Index: 407, Loss: 1.0849\n",
      "Epoch: 2, Index: 408, Loss: 8.2158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e853fb8ec2d4b28b952e82f0c7e1ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Index: 0, Loss: 4.3077\n",
      "Epoch: 3, Index: 1, Loss: 0.7765\n",
      "Epoch: 3, Index: 2, Loss: 0.3343\n",
      "Epoch: 3, Index: 3, Loss: 1.1792\n",
      "Epoch: 3, Index: 4, Loss: 0.4895\n",
      "Epoch: 3, Index: 5, Loss: 1.7153\n",
      "Epoch: 3, Index: 6, Loss: 0.6704\n",
      "Epoch: 3, Index: 7, Loss: 1.1624\n",
      "Epoch: 3, Index: 8, Loss: 2.8275\n",
      "Epoch: 3, Index: 9, Loss: 0.2669\n",
      "Epoch: 3, Index: 10, Loss: 0.1390\n",
      "Epoch: 3, Index: 11, Loss: 1.6228\n",
      "Epoch: 3, Index: 12, Loss: 0.3876\n",
      "Epoch: 3, Index: 13, Loss: 1.1248\n",
      "Epoch: 3, Index: 14, Loss: 8.7954\n",
      "Epoch: 3, Index: 15, Loss: 0.4266\n",
      "Epoch: 3, Index: 16, Loss: 0.0986\n",
      "Epoch: 3, Index: 17, Loss: 0.9078\n",
      "Epoch: 3, Index: 18, Loss: 1.0853\n",
      "Epoch: 3, Index: 19, Loss: 3.7312\n",
      "Epoch: 3, Index: 20, Loss: 6.7197\n",
      "Epoch: 3, Index: 21, Loss: 1.8755\n",
      "Epoch: 3, Index: 22, Loss: 3.5270\n",
      "Epoch: 3, Index: 23, Loss: 0.0105\n",
      "Epoch: 3, Index: 24, Loss: 1.2437\n",
      "Epoch: 3, Index: 25, Loss: 0.4367\n",
      "Epoch: 3, Index: 26, Loss: 2.6133\n",
      "Epoch: 3, Index: 27, Loss: 1.6974\n",
      "Epoch: 3, Index: 28, Loss: 0.4573\n",
      "Epoch: 3, Index: 29, Loss: 0.5863\n",
      "Epoch: 3, Index: 30, Loss: 2.4584\n",
      "Epoch: 3, Index: 31, Loss: 0.3703\n",
      "Epoch: 3, Index: 32, Loss: 1.7276\n",
      "Epoch: 3, Index: 33, Loss: 0.6503\n",
      "Epoch: 3, Index: 34, Loss: 0.6411\n",
      "Epoch: 3, Index: 35, Loss: 4.3835\n",
      "Epoch: 3, Index: 36, Loss: 1.1377\n",
      "Epoch: 3, Index: 37, Loss: 2.3058\n",
      "Epoch: 3, Index: 38, Loss: 1.2966\n",
      "Epoch: 3, Index: 39, Loss: 6.2176\n",
      "Epoch: 3, Index: 40, Loss: 0.1758\n",
      "Epoch: 3, Index: 41, Loss: 1.1324\n",
      "Epoch: 3, Index: 42, Loss: 1.1013\n",
      "Epoch: 3, Index: 43, Loss: 2.9897\n",
      "Epoch: 3, Index: 44, Loss: 0.9877\n",
      "Epoch: 3, Index: 45, Loss: 2.1838\n",
      "Epoch: 3, Index: 46, Loss: 0.4221\n",
      "Epoch: 3, Index: 47, Loss: 0.7454\n",
      "Epoch: 3, Index: 48, Loss: 3.2446\n",
      "Epoch: 3, Index: 49, Loss: 0.6417\n",
      "Epoch: 3, Index: 50, Loss: 2.1907\n",
      "Epoch: 3, Index: 51, Loss: 0.4689\n",
      "Epoch: 3, Index: 52, Loss: 0.6816\n",
      "Epoch: 3, Index: 53, Loss: 0.2559\n",
      "Epoch: 3, Index: 54, Loss: 0.7135\n",
      "Epoch: 3, Index: 55, Loss: 5.2214\n",
      "Epoch: 3, Index: 56, Loss: 1.4016\n",
      "Epoch: 3, Index: 57, Loss: 4.7647\n",
      "Epoch: 3, Index: 58, Loss: 12.7605\n",
      "Epoch: 3, Index: 59, Loss: 6.0294\n",
      "Epoch: 3, Index: 60, Loss: 2.8495\n",
      "Epoch: 3, Index: 61, Loss: 2.0933\n",
      "Epoch: 3, Index: 62, Loss: 1.7899\n",
      "Epoch: 3, Index: 63, Loss: 1.5909\n",
      "Epoch: 3, Index: 64, Loss: 1.2944\n",
      "Epoch: 3, Index: 65, Loss: 1.1902\n",
      "Epoch: 3, Index: 66, Loss: 0.5247\n",
      "Epoch: 3, Index: 67, Loss: 0.8310\n",
      "Epoch: 3, Index: 68, Loss: 0.4717\n",
      "Epoch: 3, Index: 69, Loss: 2.3367\n",
      "Epoch: 3, Index: 70, Loss: 1.9452\n",
      "Epoch: 3, Index: 71, Loss: 3.7080\n",
      "Epoch: 3, Index: 72, Loss: 0.8513\n",
      "Epoch: 3, Index: 73, Loss: 2.0429\n",
      "Epoch: 3, Index: 74, Loss: 1.1761\n",
      "Epoch: 3, Index: 75, Loss: 2.0927\n",
      "Epoch: 3, Index: 76, Loss: 1.5129\n",
      "Epoch: 3, Index: 77, Loss: 0.1665\n",
      "Epoch: 3, Index: 78, Loss: 0.3007\n",
      "Epoch: 3, Index: 79, Loss: 4.9870\n",
      "Epoch: 3, Index: 80, Loss: 8.8930\n",
      "Epoch: 3, Index: 81, Loss: 2.5486\n",
      "Epoch: 3, Index: 82, Loss: 0.6939\n",
      "Epoch: 3, Index: 83, Loss: 2.4017\n",
      "Epoch: 3, Index: 84, Loss: 2.2765\n",
      "Epoch: 3, Index: 85, Loss: 4.5362\n",
      "Epoch: 3, Index: 86, Loss: 0.5756\n",
      "Epoch: 3, Index: 87, Loss: 1.8411\n",
      "Epoch: 3, Index: 88, Loss: 0.0294\n",
      "Epoch: 3, Index: 89, Loss: 2.4741\n",
      "Epoch: 3, Index: 90, Loss: 0.8271\n",
      "Epoch: 3, Index: 91, Loss: 2.3751\n",
      "Epoch: 3, Index: 92, Loss: 5.7101\n",
      "Epoch: 3, Index: 93, Loss: 0.3417\n",
      "Epoch: 3, Index: 94, Loss: 1.8768\n",
      "Epoch: 3, Index: 95, Loss: 0.0120\n",
      "Epoch: 3, Index: 96, Loss: 1.3774\n",
      "Epoch: 3, Index: 97, Loss: 0.7539\n",
      "Epoch: 3, Index: 98, Loss: 1.8974\n",
      "Epoch: 3, Index: 99, Loss: 4.8502\n",
      "Epoch: 3, Index: 100, Loss: 1.8024\n",
      "Epoch: 3, Index: 101, Loss: 0.4565\n",
      "Epoch: 3, Index: 102, Loss: 0.6742\n",
      "Epoch: 3, Index: 103, Loss: 0.3346\n",
      "Epoch: 3, Index: 104, Loss: 0.8550\n",
      "Epoch: 3, Index: 105, Loss: 1.2549\n",
      "Epoch: 3, Index: 106, Loss: 6.3369\n",
      "Epoch: 3, Index: 107, Loss: 0.3603\n",
      "Epoch: 3, Index: 108, Loss: 1.1343\n",
      "Epoch: 3, Index: 109, Loss: 0.7343\n",
      "Epoch: 3, Index: 110, Loss: 0.8373\n",
      "Epoch: 3, Index: 111, Loss: 0.1057\n",
      "Epoch: 3, Index: 112, Loss: 0.5662\n",
      "Epoch: 3, Index: 113, Loss: 0.2314\n",
      "Epoch: 3, Index: 114, Loss: 2.6703\n",
      "Epoch: 3, Index: 115, Loss: 0.8557\n",
      "Epoch: 3, Index: 116, Loss: 4.8298\n",
      "Epoch: 3, Index: 117, Loss: 0.8197\n",
      "Epoch: 3, Index: 118, Loss: 0.2853\n",
      "Epoch: 3, Index: 119, Loss: 0.3200\n",
      "Epoch: 3, Index: 120, Loss: 5.2846\n",
      "Epoch: 3, Index: 121, Loss: 1.6040\n",
      "Epoch: 3, Index: 122, Loss: 0.2176\n",
      "Epoch: 3, Index: 123, Loss: 1.1121\n",
      "Epoch: 3, Index: 124, Loss: 0.1050\n",
      "Epoch: 3, Index: 125, Loss: 0.5561\n",
      "Epoch: 3, Index: 126, Loss: 2.5589\n",
      "Epoch: 3, Index: 127, Loss: 0.1668\n",
      "Epoch: 3, Index: 128, Loss: 0.8059\n",
      "Epoch: 3, Index: 129, Loss: 0.4034\n",
      "Epoch: 3, Index: 130, Loss: 1.2278\n",
      "Epoch: 3, Index: 131, Loss: 0.7577\n",
      "Epoch: 3, Index: 132, Loss: 3.3324\n",
      "Epoch: 3, Index: 133, Loss: 0.7330\n",
      "Epoch: 3, Index: 134, Loss: 4.4684\n",
      "Epoch: 3, Index: 135, Loss: 1.5369\n",
      "Epoch: 3, Index: 136, Loss: 5.1960\n",
      "Epoch: 3, Index: 137, Loss: 0.1400\n",
      "Epoch: 3, Index: 138, Loss: 1.1017\n",
      "Epoch: 3, Index: 139, Loss: 1.9607\n",
      "Epoch: 3, Index: 140, Loss: 0.3518\n",
      "Epoch: 3, Index: 141, Loss: 0.8648\n",
      "Epoch: 3, Index: 142, Loss: 0.7593\n",
      "Epoch: 3, Index: 143, Loss: 0.3755\n",
      "Epoch: 3, Index: 144, Loss: 0.2547\n",
      "Epoch: 3, Index: 145, Loss: 1.5063\n",
      "Epoch: 3, Index: 146, Loss: 0.8246\n",
      "Epoch: 3, Index: 147, Loss: 0.5036\n",
      "Epoch: 3, Index: 148, Loss: 1.2238\n",
      "Epoch: 3, Index: 149, Loss: 2.4926\n",
      "Epoch: 3, Index: 150, Loss: 3.1995\n",
      "Epoch: 3, Index: 151, Loss: 1.1433\n",
      "Epoch: 3, Index: 152, Loss: 0.2370\n",
      "Epoch: 3, Index: 153, Loss: 1.2422\n",
      "Epoch: 3, Index: 154, Loss: 3.2044\n",
      "Epoch: 3, Index: 155, Loss: 0.8579\n",
      "Epoch: 3, Index: 156, Loss: 0.3994\n",
      "Epoch: 3, Index: 157, Loss: 13.9481\n",
      "Epoch: 3, Index: 158, Loss: 3.9056\n",
      "Epoch: 3, Index: 159, Loss: 3.1565\n",
      "Epoch: 3, Index: 160, Loss: 2.3928\n",
      "Epoch: 3, Index: 161, Loss: 2.1250\n",
      "Epoch: 3, Index: 162, Loss: 1.9919\n",
      "Epoch: 3, Index: 163, Loss: 0.5326\n",
      "Epoch: 3, Index: 164, Loss: 1.2508\n",
      "Epoch: 3, Index: 165, Loss: 0.3306\n",
      "Epoch: 3, Index: 166, Loss: 2.5196\n",
      "Epoch: 3, Index: 167, Loss: 4.8653\n",
      "Epoch: 3, Index: 168, Loss: 1.1303\n",
      "Epoch: 3, Index: 169, Loss: 0.2964\n",
      "Epoch: 3, Index: 170, Loss: 2.2438\n",
      "Epoch: 3, Index: 171, Loss: 2.1944\n",
      "Epoch: 3, Index: 172, Loss: 0.5596\n",
      "Epoch: 3, Index: 173, Loss: 0.0453\n",
      "Epoch: 3, Index: 174, Loss: 0.6756\n",
      "Epoch: 3, Index: 175, Loss: 1.0578\n",
      "Epoch: 3, Index: 176, Loss: 1.2650\n",
      "Epoch: 3, Index: 177, Loss: 15.1553\n",
      "Epoch: 3, Index: 178, Loss: 2.3992\n",
      "Epoch: 3, Index: 179, Loss: 0.3274\n",
      "Epoch: 3, Index: 180, Loss: 0.2557\n",
      "Epoch: 3, Index: 181, Loss: 4.8484\n",
      "Epoch: 3, Index: 182, Loss: 4.3452\n",
      "Epoch: 3, Index: 183, Loss: 0.0657\n",
      "Epoch: 3, Index: 184, Loss: 1.5438\n",
      "Epoch: 3, Index: 185, Loss: 4.5455\n",
      "Epoch: 3, Index: 186, Loss: 0.6090\n",
      "Epoch: 3, Index: 187, Loss: 0.8599\n",
      "Epoch: 3, Index: 188, Loss: 0.3731\n",
      "Epoch: 3, Index: 189, Loss: 3.2106\n",
      "Epoch: 3, Index: 190, Loss: 1.1209\n",
      "Epoch: 3, Index: 191, Loss: 4.2036\n",
      "Epoch: 3, Index: 192, Loss: 4.4201\n",
      "Epoch: 3, Index: 193, Loss: 0.6000\n",
      "Epoch: 3, Index: 194, Loss: 0.0286\n",
      "Epoch: 3, Index: 195, Loss: 4.5286\n",
      "Epoch: 3, Index: 196, Loss: 8.6768\n",
      "Epoch: 3, Index: 197, Loss: 2.8343\n",
      "Epoch: 3, Index: 198, Loss: 0.8268\n",
      "Epoch: 3, Index: 199, Loss: 0.1182\n",
      "Epoch: 3, Index: 200, Loss: 1.8415\n",
      "Epoch: 3, Index: 201, Loss: 0.6536\n",
      "Epoch: 3, Index: 202, Loss: 1.9078\n",
      "Epoch: 3, Index: 203, Loss: 3.5968\n",
      "Epoch: 3, Index: 204, Loss: 0.2426\n",
      "Epoch: 3, Index: 205, Loss: 4.8424\n",
      "Epoch: 3, Index: 206, Loss: 0.8568\n",
      "Epoch: 3, Index: 207, Loss: 3.0003\n",
      "Epoch: 3, Index: 208, Loss: 0.5905\n",
      "Epoch: 3, Index: 209, Loss: 0.2691\n",
      "Epoch: 3, Index: 210, Loss: 2.7023\n",
      "Epoch: 3, Index: 211, Loss: 2.8021\n",
      "Epoch: 3, Index: 212, Loss: 0.3666\n",
      "Epoch: 3, Index: 213, Loss: 10.1561\n",
      "Epoch: 3, Index: 214, Loss: 0.1093\n",
      "Epoch: 3, Index: 215, Loss: 0.0864\n",
      "Epoch: 3, Index: 216, Loss: 6.4044\n",
      "Epoch: 3, Index: 217, Loss: 3.1179\n",
      "Epoch: 3, Index: 218, Loss: 0.1010\n",
      "Epoch: 3, Index: 219, Loss: 1.4818\n",
      "Epoch: 3, Index: 220, Loss: 0.1205\n",
      "Epoch: 3, Index: 221, Loss: 1.8624\n",
      "Epoch: 3, Index: 222, Loss: 7.3193\n",
      "Epoch: 3, Index: 223, Loss: 7.5281\n",
      "Epoch: 3, Index: 224, Loss: 3.7142\n",
      "Epoch: 3, Index: 225, Loss: 4.1166\n",
      "Epoch: 3, Index: 226, Loss: 4.4236\n",
      "Epoch: 3, Index: 227, Loss: 0.8869\n",
      "Epoch: 3, Index: 228, Loss: 3.7716\n",
      "Epoch: 3, Index: 229, Loss: 0.3548\n",
      "Epoch: 3, Index: 230, Loss: 1.5028\n",
      "Epoch: 3, Index: 231, Loss: 0.3819\n",
      "Epoch: 3, Index: 232, Loss: 7.8271\n",
      "Epoch: 3, Index: 233, Loss: 0.4591\n",
      "Epoch: 3, Index: 234, Loss: 0.0877\n",
      "Epoch: 3, Index: 235, Loss: 1.3109\n",
      "Epoch: 3, Index: 236, Loss: 1.0431\n",
      "Epoch: 3, Index: 237, Loss: 4.9827\n",
      "Epoch: 3, Index: 238, Loss: 1.0655\n",
      "Epoch: 3, Index: 239, Loss: 7.4365\n",
      "Epoch: 3, Index: 240, Loss: 7.8310\n",
      "Epoch: 3, Index: 241, Loss: 0.9904\n",
      "Epoch: 3, Index: 242, Loss: 6.7666\n",
      "Epoch: 3, Index: 243, Loss: 3.7800\n",
      "Epoch: 3, Index: 244, Loss: 4.7277\n",
      "Epoch: 3, Index: 245, Loss: 2.4112\n",
      "Epoch: 3, Index: 246, Loss: 4.6338\n",
      "Epoch: 3, Index: 247, Loss: 1.1047\n",
      "Epoch: 3, Index: 248, Loss: 0.7011\n",
      "Epoch: 3, Index: 249, Loss: 3.8296\n",
      "Epoch: 3, Index: 250, Loss: 0.6509\n",
      "Epoch: 3, Index: 251, Loss: 1.5640\n",
      "Epoch: 3, Index: 252, Loss: 0.6221\n",
      "Epoch: 3, Index: 253, Loss: 2.8523\n",
      "Epoch: 3, Index: 254, Loss: 3.3687\n",
      "Epoch: 3, Index: 255, Loss: 1.6692\n",
      "Epoch: 3, Index: 256, Loss: 1.4153\n",
      "Epoch: 3, Index: 257, Loss: 2.0795\n",
      "Epoch: 3, Index: 258, Loss: 1.4996\n",
      "Epoch: 3, Index: 259, Loss: 1.1358\n",
      "Epoch: 3, Index: 260, Loss: 1.8581\n",
      "Epoch: 3, Index: 261, Loss: 2.3092\n",
      "Epoch: 3, Index: 262, Loss: 0.5957\n",
      "Epoch: 3, Index: 263, Loss: 4.7854\n",
      "Epoch: 3, Index: 264, Loss: 0.7820\n",
      "Epoch: 3, Index: 265, Loss: 1.0544\n",
      "Epoch: 3, Index: 266, Loss: 6.4353\n",
      "Epoch: 3, Index: 267, Loss: 2.8715\n",
      "Epoch: 3, Index: 268, Loss: 1.0265\n",
      "Epoch: 3, Index: 269, Loss: 1.8092\n",
      "Epoch: 3, Index: 270, Loss: 0.8043\n",
      "Epoch: 3, Index: 271, Loss: 0.2412\n",
      "Epoch: 3, Index: 272, Loss: 0.8691\n",
      "Epoch: 3, Index: 273, Loss: 0.0663\n",
      "Epoch: 3, Index: 274, Loss: 3.4847\n",
      "Epoch: 3, Index: 275, Loss: 0.5782\n",
      "Epoch: 3, Index: 276, Loss: 1.5211\n",
      "Epoch: 3, Index: 277, Loss: 4.2158\n",
      "Epoch: 3, Index: 278, Loss: 0.9766\n",
      "Epoch: 3, Index: 279, Loss: 2.2297\n",
      "Epoch: 3, Index: 280, Loss: 2.5464\n",
      "Epoch: 3, Index: 281, Loss: 1.6718\n",
      "Epoch: 3, Index: 282, Loss: 1.6520\n",
      "Epoch: 3, Index: 283, Loss: 6.6616\n",
      "Epoch: 3, Index: 284, Loss: 0.7391\n",
      "Epoch: 3, Index: 285, Loss: 4.0462\n",
      "Epoch: 3, Index: 286, Loss: 2.5162\n",
      "Epoch: 3, Index: 287, Loss: 0.0778\n",
      "Epoch: 3, Index: 288, Loss: 2.9114\n",
      "Epoch: 3, Index: 289, Loss: 0.9667\n",
      "Epoch: 3, Index: 290, Loss: 2.8418\n",
      "Epoch: 3, Index: 291, Loss: 0.5654\n",
      "Epoch: 3, Index: 292, Loss: 0.4134\n",
      "Epoch: 3, Index: 293, Loss: 2.1806\n",
      "Epoch: 3, Index: 294, Loss: 2.1309\n",
      "Epoch: 3, Index: 295, Loss: 1.3698\n",
      "Epoch: 3, Index: 296, Loss: 8.9508\n",
      "Epoch: 3, Index: 297, Loss: 0.9035\n",
      "Epoch: 3, Index: 298, Loss: 2.2941\n",
      "Epoch: 3, Index: 299, Loss: 3.4080\n",
      "Epoch: 3, Index: 300, Loss: 3.0742\n",
      "Epoch: 3, Index: 301, Loss: 5.2448\n",
      "Epoch: 3, Index: 302, Loss: 0.1232\n",
      "Epoch: 3, Index: 303, Loss: 1.2842\n",
      "Epoch: 3, Index: 304, Loss: 4.2666\n",
      "Epoch: 3, Index: 305, Loss: 3.3404\n",
      "Epoch: 3, Index: 306, Loss: 1.4510\n",
      "Epoch: 3, Index: 307, Loss: 1.5880\n",
      "Epoch: 3, Index: 308, Loss: 2.6773\n",
      "Epoch: 3, Index: 309, Loss: 0.0026\n",
      "Epoch: 3, Index: 310, Loss: 2.1891\n",
      "Epoch: 3, Index: 311, Loss: 0.7843\n",
      "Epoch: 3, Index: 312, Loss: 1.8475\n",
      "Epoch: 3, Index: 313, Loss: 2.9716\n",
      "Epoch: 3, Index: 314, Loss: 2.3613\n",
      "Epoch: 3, Index: 315, Loss: 1.7884\n",
      "Epoch: 3, Index: 316, Loss: 2.6760\n",
      "Epoch: 3, Index: 317, Loss: 0.2422\n",
      "Epoch: 3, Index: 318, Loss: 0.7715\n",
      "Epoch: 3, Index: 319, Loss: 0.3659\n",
      "Epoch: 3, Index: 320, Loss: 0.1715\n",
      "Epoch: 3, Index: 321, Loss: 2.9462\n",
      "Epoch: 3, Index: 322, Loss: 0.5214\n",
      "Epoch: 3, Index: 323, Loss: 1.3196\n",
      "Epoch: 3, Index: 324, Loss: 0.0585\n",
      "Epoch: 3, Index: 325, Loss: 1.2495\n",
      "Epoch: 3, Index: 326, Loss: 0.1861\n",
      "Epoch: 3, Index: 327, Loss: 0.5159\n",
      "Epoch: 3, Index: 328, Loss: 3.1788\n",
      "Epoch: 3, Index: 329, Loss: 0.2135\n",
      "Epoch: 3, Index: 330, Loss: 1.7786\n",
      "Epoch: 3, Index: 331, Loss: 0.7117\n",
      "Epoch: 3, Index: 332, Loss: 1.8935\n",
      "Epoch: 3, Index: 333, Loss: 2.1221\n",
      "Epoch: 3, Index: 334, Loss: 0.4546\n",
      "Epoch: 3, Index: 335, Loss: 7.9299\n",
      "Epoch: 3, Index: 336, Loss: 0.4514\n",
      "Epoch: 3, Index: 337, Loss: 1.0030\n",
      "Epoch: 3, Index: 338, Loss: 2.8287\n",
      "Epoch: 3, Index: 339, Loss: 3.0730\n",
      "Epoch: 3, Index: 340, Loss: 4.6511\n",
      "Epoch: 3, Index: 341, Loss: 0.0767\n",
      "Epoch: 3, Index: 342, Loss: 5.6145\n",
      "Epoch: 3, Index: 343, Loss: 2.9665\n",
      "Epoch: 3, Index: 344, Loss: 0.8572\n",
      "Epoch: 3, Index: 345, Loss: 0.2927\n",
      "Epoch: 3, Index: 346, Loss: 4.1061\n",
      "Epoch: 3, Index: 347, Loss: 9.0212\n",
      "Epoch: 3, Index: 348, Loss: 2.8885\n",
      "Epoch: 3, Index: 349, Loss: 3.8942\n",
      "Epoch: 3, Index: 350, Loss: 4.1489\n",
      "Epoch: 3, Index: 351, Loss: 4.5801\n",
      "Epoch: 3, Index: 352, Loss: 0.4471\n",
      "Epoch: 3, Index: 353, Loss: 1.2707\n",
      "Epoch: 3, Index: 354, Loss: 1.5429\n",
      "Epoch: 3, Index: 355, Loss: 1.8282\n",
      "Epoch: 3, Index: 356, Loss: 4.7302\n",
      "Epoch: 3, Index: 357, Loss: 0.9853\n",
      "Epoch: 3, Index: 358, Loss: 0.6630\n",
      "Epoch: 3, Index: 359, Loss: 2.7778\n",
      "Epoch: 3, Index: 360, Loss: 1.3706\n",
      "Epoch: 3, Index: 361, Loss: 10.1635\n",
      "Epoch: 3, Index: 362, Loss: 0.8694\n",
      "Epoch: 3, Index: 363, Loss: 5.8640\n",
      "Epoch: 3, Index: 364, Loss: 0.9905\n",
      "Epoch: 3, Index: 365, Loss: 2.6154\n",
      "Epoch: 3, Index: 366, Loss: 2.3039\n",
      "Epoch: 3, Index: 367, Loss: 0.1480\n",
      "Epoch: 3, Index: 368, Loss: 0.0168\n",
      "Epoch: 3, Index: 369, Loss: 1.0648\n",
      "Epoch: 3, Index: 370, Loss: 3.3894\n",
      "Epoch: 3, Index: 371, Loss: 0.7872\n",
      "Epoch: 3, Index: 372, Loss: 2.0822\n",
      "Epoch: 3, Index: 373, Loss: 1.7994\n",
      "Epoch: 3, Index: 374, Loss: 2.5574\n",
      "Epoch: 3, Index: 375, Loss: 3.1998\n",
      "Epoch: 3, Index: 376, Loss: 0.7983\n",
      "Epoch: 3, Index: 377, Loss: 2.1379\n",
      "Epoch: 3, Index: 378, Loss: 1.5103\n",
      "Epoch: 3, Index: 379, Loss: 4.5521\n",
      "Epoch: 3, Index: 380, Loss: 4.2451\n",
      "Epoch: 3, Index: 381, Loss: 3.1481\n",
      "Epoch: 3, Index: 382, Loss: 1.0642\n",
      "Epoch: 3, Index: 383, Loss: 0.8747\n",
      "Epoch: 3, Index: 384, Loss: 1.7398\n",
      "Epoch: 3, Index: 385, Loss: 3.9044\n",
      "Epoch: 3, Index: 386, Loss: 13.9898\n",
      "Epoch: 3, Index: 387, Loss: 6.3863\n",
      "Epoch: 3, Index: 388, Loss: 0.2677\n",
      "Epoch: 3, Index: 389, Loss: 1.4651\n",
      "Epoch: 3, Index: 390, Loss: 0.8616\n",
      "Epoch: 3, Index: 391, Loss: 1.8314\n",
      "Epoch: 3, Index: 392, Loss: 0.3341\n",
      "Epoch: 3, Index: 393, Loss: 0.8160\n",
      "Epoch: 3, Index: 394, Loss: 0.5732\n",
      "Epoch: 3, Index: 395, Loss: 2.2456\n",
      "Epoch: 3, Index: 396, Loss: 0.8107\n",
      "Epoch: 3, Index: 397, Loss: 2.4643\n",
      "Epoch: 3, Index: 398, Loss: 4.0104\n",
      "Epoch: 3, Index: 399, Loss: 0.0473\n",
      "Epoch: 3, Index: 400, Loss: 0.1493\n",
      "Epoch: 3, Index: 401, Loss: 0.9567\n",
      "Epoch: 3, Index: 402, Loss: 1.6556\n",
      "Epoch: 3, Index: 403, Loss: 0.8926\n",
      "Epoch: 3, Index: 404, Loss: 0.2191\n",
      "Epoch: 3, Index: 405, Loss: 6.4745\n",
      "Epoch: 3, Index: 406, Loss: 1.4779\n",
      "Epoch: 3, Index: 407, Loss: 1.1322\n",
      "Epoch: 3, Index: 408, Loss: 3.4003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e1f4c21f9e4b46aa3d41f5e82ad6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Index: 0, Loss: 9.1812\n",
      "Epoch: 4, Index: 1, Loss: 4.4443\n",
      "Epoch: 4, Index: 2, Loss: 1.9107\n",
      "Epoch: 4, Index: 3, Loss: 5.0175\n",
      "Epoch: 4, Index: 4, Loss: 7.7066\n",
      "Epoch: 4, Index: 5, Loss: 4.6654\n",
      "Epoch: 4, Index: 6, Loss: 4.5994\n",
      "Epoch: 4, Index: 7, Loss: 3.9171\n",
      "Epoch: 4, Index: 8, Loss: 3.8539\n",
      "Epoch: 4, Index: 9, Loss: 6.5827\n",
      "Epoch: 4, Index: 10, Loss: 8.1823\n",
      "Epoch: 4, Index: 11, Loss: 2.0197\n",
      "Epoch: 4, Index: 12, Loss: 1.8954\n",
      "Epoch: 4, Index: 13, Loss: 0.0554\n",
      "Epoch: 4, Index: 14, Loss: 2.2871\n",
      "Epoch: 4, Index: 15, Loss: 2.1674\n",
      "Epoch: 4, Index: 16, Loss: 0.4578\n",
      "Epoch: 4, Index: 17, Loss: 2.6237\n",
      "Epoch: 4, Index: 18, Loss: 0.2443\n",
      "Epoch: 4, Index: 19, Loss: 4.1054\n",
      "Epoch: 4, Index: 20, Loss: 0.2453\n",
      "Epoch: 4, Index: 21, Loss: 8.1046\n",
      "Epoch: 4, Index: 22, Loss: 1.3504\n",
      "Epoch: 4, Index: 23, Loss: 3.1248\n",
      "Epoch: 4, Index: 24, Loss: 6.1617\n",
      "Epoch: 4, Index: 25, Loss: 0.2385\n",
      "Epoch: 4, Index: 26, Loss: 0.1862\n",
      "Epoch: 4, Index: 27, Loss: 3.3882\n",
      "Epoch: 4, Index: 28, Loss: 1.3457\n",
      "Epoch: 4, Index: 29, Loss: 4.0177\n",
      "Epoch: 4, Index: 30, Loss: 1.3252\n",
      "Epoch: 4, Index: 31, Loss: 3.8018\n",
      "Epoch: 4, Index: 32, Loss: 0.1413\n",
      "Epoch: 4, Index: 33, Loss: 1.9240\n",
      "Epoch: 4, Index: 34, Loss: 0.4440\n",
      "Epoch: 4, Index: 35, Loss: 3.1031\n",
      "Epoch: 4, Index: 36, Loss: 1.9462\n",
      "Epoch: 4, Index: 37, Loss: 0.3558\n",
      "Epoch: 4, Index: 38, Loss: 2.8828\n",
      "Epoch: 4, Index: 39, Loss: 1.8469\n",
      "Epoch: 4, Index: 40, Loss: 0.1780\n",
      "Epoch: 4, Index: 41, Loss: 0.9187\n",
      "Epoch: 4, Index: 42, Loss: 0.9085\n",
      "Epoch: 4, Index: 43, Loss: 1.3988\n",
      "Epoch: 4, Index: 44, Loss: 0.0814\n",
      "Epoch: 4, Index: 45, Loss: 0.4497\n",
      "Epoch: 4, Index: 46, Loss: 0.4054\n",
      "Epoch: 4, Index: 47, Loss: 2.6698\n",
      "Epoch: 4, Index: 48, Loss: 4.5317\n",
      "Epoch: 4, Index: 49, Loss: 0.8876\n",
      "Epoch: 4, Index: 50, Loss: 1.3801\n",
      "Epoch: 4, Index: 51, Loss: 3.1692\n",
      "Epoch: 4, Index: 52, Loss: 1.3007\n",
      "Epoch: 4, Index: 53, Loss: 0.6476\n",
      "Epoch: 4, Index: 54, Loss: 0.3967\n",
      "Epoch: 4, Index: 55, Loss: 0.3473\n",
      "Epoch: 4, Index: 56, Loss: 1.6393\n",
      "Epoch: 4, Index: 57, Loss: 0.8508\n",
      "Epoch: 4, Index: 58, Loss: 1.9515\n",
      "Epoch: 4, Index: 59, Loss: 0.1361\n",
      "Epoch: 4, Index: 60, Loss: 1.7217\n",
      "Epoch: 4, Index: 61, Loss: 0.1577\n",
      "Epoch: 4, Index: 62, Loss: 1.3169\n",
      "Epoch: 4, Index: 63, Loss: 2.9340\n",
      "Epoch: 4, Index: 64, Loss: 0.2582\n",
      "Epoch: 4, Index: 65, Loss: 1.3670\n",
      "Epoch: 4, Index: 66, Loss: 0.0243\n",
      "Epoch: 4, Index: 67, Loss: 0.5230\n",
      "Epoch: 4, Index: 68, Loss: 1.7561\n",
      "Epoch: 4, Index: 69, Loss: 2.3069\n",
      "Epoch: 4, Index: 70, Loss: 1.0117\n",
      "Epoch: 4, Index: 71, Loss: 1.6670\n",
      "Epoch: 4, Index: 72, Loss: 2.9518\n",
      "Epoch: 4, Index: 73, Loss: 5.3733\n",
      "Epoch: 4, Index: 74, Loss: 0.6330\n",
      "Epoch: 4, Index: 75, Loss: 5.9939\n",
      "Epoch: 4, Index: 76, Loss: 1.2170\n",
      "Epoch: 4, Index: 77, Loss: 1.1006\n",
      "Epoch: 4, Index: 78, Loss: 0.3613\n",
      "Epoch: 4, Index: 79, Loss: 1.2415\n",
      "Epoch: 4, Index: 80, Loss: 3.8406\n",
      "Epoch: 4, Index: 81, Loss: 1.0774\n",
      "Epoch: 4, Index: 82, Loss: 7.7124\n",
      "Epoch: 4, Index: 83, Loss: 0.2960\n",
      "Epoch: 4, Index: 84, Loss: 0.5245\n",
      "Epoch: 4, Index: 85, Loss: 11.9129\n",
      "Epoch: 4, Index: 86, Loss: 0.2011\n",
      "Epoch: 4, Index: 87, Loss: 4.2501\n",
      "Epoch: 4, Index: 88, Loss: 5.4162\n",
      "Epoch: 4, Index: 89, Loss: 6.2503\n",
      "Epoch: 4, Index: 90, Loss: 0.0849\n",
      "Epoch: 4, Index: 91, Loss: 0.6477\n",
      "Epoch: 4, Index: 92, Loss: 4.3782\n",
      "Epoch: 4, Index: 93, Loss: 0.6383\n",
      "Epoch: 4, Index: 94, Loss: 0.5637\n",
      "Epoch: 4, Index: 95, Loss: 2.2866\n",
      "Epoch: 4, Index: 96, Loss: 0.6814\n",
      "Epoch: 4, Index: 97, Loss: 0.8097\n",
      "Epoch: 4, Index: 98, Loss: 2.1763\n",
      "Epoch: 4, Index: 99, Loss: 4.5497\n",
      "Epoch: 4, Index: 100, Loss: 2.1336\n",
      "Epoch: 4, Index: 101, Loss: 1.3528\n",
      "Epoch: 4, Index: 102, Loss: 1.1057\n",
      "Epoch: 4, Index: 103, Loss: 0.0244\n",
      "Epoch: 4, Index: 104, Loss: 2.1501\n",
      "Epoch: 4, Index: 105, Loss: 0.3481\n",
      "Epoch: 4, Index: 106, Loss: 3.6070\n",
      "Epoch: 4, Index: 107, Loss: 7.3499\n",
      "Epoch: 4, Index: 108, Loss: 0.0845\n",
      "Epoch: 4, Index: 109, Loss: 0.6653\n",
      "Epoch: 4, Index: 110, Loss: 0.9250\n",
      "Epoch: 4, Index: 111, Loss: 0.7427\n",
      "Epoch: 4, Index: 112, Loss: 1.6887\n",
      "Epoch: 4, Index: 113, Loss: 1.9390\n",
      "Epoch: 4, Index: 114, Loss: 2.2460\n",
      "Epoch: 4, Index: 115, Loss: 2.7489\n",
      "Epoch: 4, Index: 116, Loss: 0.5013\n",
      "Epoch: 4, Index: 117, Loss: 1.0975\n",
      "Epoch: 4, Index: 118, Loss: 2.0216\n",
      "Epoch: 4, Index: 119, Loss: 2.6521\n",
      "Epoch: 4, Index: 120, Loss: 0.5809\n",
      "Epoch: 4, Index: 121, Loss: 2.4699\n",
      "Epoch: 4, Index: 122, Loss: 1.0063\n",
      "Epoch: 4, Index: 123, Loss: 4.0615\n",
      "Epoch: 4, Index: 124, Loss: 0.9941\n",
      "Epoch: 4, Index: 125, Loss: 4.5341\n",
      "Epoch: 4, Index: 126, Loss: 1.5070\n",
      "Epoch: 4, Index: 127, Loss: 0.5209\n",
      "Epoch: 4, Index: 128, Loss: 2.9379\n",
      "Epoch: 4, Index: 129, Loss: 0.1324\n",
      "Epoch: 4, Index: 130, Loss: 0.9976\n",
      "Epoch: 4, Index: 131, Loss: 2.9467\n",
      "Epoch: 4, Index: 132, Loss: 5.6734\n",
      "Epoch: 4, Index: 133, Loss: 3.4276\n",
      "Epoch: 4, Index: 134, Loss: 1.8465\n",
      "Epoch: 4, Index: 135, Loss: 1.3980\n",
      "Epoch: 4, Index: 136, Loss: 0.0793\n",
      "Epoch: 4, Index: 137, Loss: 2.3594\n",
      "Epoch: 4, Index: 138, Loss: 1.0851\n",
      "Epoch: 4, Index: 139, Loss: 0.1101\n",
      "Epoch: 4, Index: 140, Loss: 1.5737\n",
      "Epoch: 4, Index: 141, Loss: 6.6675\n",
      "Epoch: 4, Index: 142, Loss: 4.0232\n",
      "Epoch: 4, Index: 143, Loss: 0.2975\n",
      "Epoch: 4, Index: 144, Loss: 0.2377\n",
      "Epoch: 4, Index: 145, Loss: 1.3978\n",
      "Epoch: 4, Index: 146, Loss: 0.2464\n",
      "Epoch: 4, Index: 147, Loss: 7.4302\n",
      "Epoch: 4, Index: 148, Loss: 5.2222\n",
      "Epoch: 4, Index: 149, Loss: 0.4115\n",
      "Epoch: 4, Index: 150, Loss: 2.2507\n",
      "Epoch: 4, Index: 151, Loss: 2.1517\n",
      "Epoch: 4, Index: 152, Loss: 3.1554\n",
      "Epoch: 4, Index: 153, Loss: 2.0220\n",
      "Epoch: 4, Index: 154, Loss: 1.1353\n",
      "Epoch: 4, Index: 155, Loss: 0.1411\n",
      "Epoch: 4, Index: 156, Loss: 0.6790\n",
      "Epoch: 4, Index: 157, Loss: 3.7534\n",
      "Epoch: 4, Index: 158, Loss: 0.8978\n",
      "Epoch: 4, Index: 159, Loss: 2.0597\n",
      "Epoch: 4, Index: 160, Loss: 0.0510\n",
      "Epoch: 4, Index: 161, Loss: 1.3654\n",
      "Epoch: 4, Index: 162, Loss: 0.8239\n",
      "Epoch: 4, Index: 163, Loss: 2.0379\n",
      "Epoch: 4, Index: 164, Loss: 2.6283\n",
      "Epoch: 4, Index: 165, Loss: 1.9482\n",
      "Epoch: 4, Index: 166, Loss: 0.6486\n",
      "Epoch: 4, Index: 167, Loss: 17.2192\n",
      "Epoch: 4, Index: 168, Loss: 0.0574\n",
      "Epoch: 4, Index: 169, Loss: 1.5011\n",
      "Epoch: 4, Index: 170, Loss: 1.2145\n",
      "Epoch: 4, Index: 171, Loss: 0.0387\n",
      "Epoch: 4, Index: 172, Loss: 1.5595\n",
      "Epoch: 4, Index: 173, Loss: 4.7684\n",
      "Epoch: 4, Index: 174, Loss: 0.8899\n",
      "Epoch: 4, Index: 175, Loss: 1.6352\n",
      "Epoch: 4, Index: 176, Loss: 1.0735\n",
      "Epoch: 4, Index: 177, Loss: 1.1483\n",
      "Epoch: 4, Index: 178, Loss: 1.2614\n",
      "Epoch: 4, Index: 179, Loss: 0.8553\n",
      "Epoch: 4, Index: 180, Loss: 0.1650\n",
      "Epoch: 4, Index: 181, Loss: 1.2950\n",
      "Epoch: 4, Index: 182, Loss: 0.8666\n",
      "Epoch: 4, Index: 183, Loss: 0.2698\n",
      "Epoch: 4, Index: 184, Loss: 0.0760\n",
      "Epoch: 4, Index: 185, Loss: 1.1654\n",
      "Epoch: 4, Index: 186, Loss: 1.2451\n",
      "Epoch: 4, Index: 187, Loss: 1.2457\n",
      "Epoch: 4, Index: 188, Loss: 0.5181\n",
      "Epoch: 4, Index: 189, Loss: 1.5976\n",
      "Epoch: 4, Index: 190, Loss: 0.4308\n",
      "Epoch: 4, Index: 191, Loss: 0.9602\n",
      "Epoch: 4, Index: 192, Loss: 6.2391\n",
      "Epoch: 4, Index: 193, Loss: 2.6249\n",
      "Epoch: 4, Index: 194, Loss: 0.8476\n",
      "Epoch: 4, Index: 195, Loss: 0.7160\n",
      "Epoch: 4, Index: 196, Loss: 0.9846\n",
      "Epoch: 4, Index: 197, Loss: 2.2606\n",
      "Epoch: 4, Index: 198, Loss: 1.4585\n",
      "Epoch: 4, Index: 199, Loss: 2.0101\n",
      "Epoch: 4, Index: 200, Loss: 2.5121\n",
      "Epoch: 4, Index: 201, Loss: 0.0748\n",
      "Epoch: 4, Index: 202, Loss: 1.6835\n",
      "Epoch: 4, Index: 203, Loss: 1.7236\n",
      "Epoch: 4, Index: 204, Loss: 1.5330\n",
      "Epoch: 4, Index: 205, Loss: 1.0987\n",
      "Epoch: 4, Index: 206, Loss: 0.7348\n",
      "Epoch: 4, Index: 207, Loss: 0.1616\n",
      "Epoch: 4, Index: 208, Loss: 1.4171\n",
      "Epoch: 4, Index: 209, Loss: 11.0474\n",
      "Epoch: 4, Index: 210, Loss: 2.5814\n",
      "Epoch: 4, Index: 211, Loss: 2.5245\n",
      "Epoch: 4, Index: 212, Loss: 0.9395\n",
      "Epoch: 4, Index: 213, Loss: 0.9603\n",
      "Epoch: 4, Index: 214, Loss: 0.5892\n",
      "Epoch: 4, Index: 215, Loss: 0.9777\n",
      "Epoch: 4, Index: 216, Loss: 1.7084\n",
      "Epoch: 4, Index: 217, Loss: 0.8090\n",
      "Epoch: 4, Index: 218, Loss: 0.1968\n",
      "Epoch: 4, Index: 219, Loss: 0.5166\n",
      "Epoch: 4, Index: 220, Loss: 1.6523\n",
      "Epoch: 4, Index: 221, Loss: 1.2817\n",
      "Epoch: 4, Index: 222, Loss: 0.1501\n",
      "Epoch: 4, Index: 223, Loss: 2.3202\n",
      "Epoch: 4, Index: 224, Loss: 2.2999\n",
      "Epoch: 4, Index: 225, Loss: 5.3730\n",
      "Epoch: 4, Index: 226, Loss: 0.2396\n",
      "Epoch: 4, Index: 227, Loss: 2.1125\n",
      "Epoch: 4, Index: 228, Loss: 0.8945\n",
      "Epoch: 4, Index: 229, Loss: 0.3776\n",
      "Epoch: 4, Index: 230, Loss: 0.9523\n",
      "Epoch: 4, Index: 231, Loss: 0.2309\n",
      "Epoch: 4, Index: 232, Loss: 0.4042\n",
      "Epoch: 4, Index: 233, Loss: 0.9132\n",
      "Epoch: 4, Index: 234, Loss: 0.4316\n",
      "Epoch: 4, Index: 235, Loss: 18.9121\n",
      "Epoch: 4, Index: 236, Loss: 3.6527\n",
      "Epoch: 4, Index: 237, Loss: 2.2907\n",
      "Epoch: 4, Index: 238, Loss: 0.3806\n",
      "Epoch: 4, Index: 239, Loss: 2.4983\n",
      "Epoch: 4, Index: 240, Loss: 0.0425\n",
      "Epoch: 4, Index: 241, Loss: 0.9362\n",
      "Epoch: 4, Index: 242, Loss: 5.6017\n",
      "Epoch: 4, Index: 243, Loss: 1.8173\n",
      "Epoch: 4, Index: 244, Loss: 2.2388\n",
      "Epoch: 4, Index: 245, Loss: 1.8016\n",
      "Epoch: 4, Index: 246, Loss: 5.3609\n",
      "Epoch: 4, Index: 247, Loss: 2.0778\n",
      "Epoch: 4, Index: 248, Loss: 1.4586\n",
      "Epoch: 4, Index: 249, Loss: 1.6143\n",
      "Epoch: 4, Index: 250, Loss: 0.4163\n",
      "Epoch: 4, Index: 251, Loss: 0.6232\n",
      "Epoch: 4, Index: 252, Loss: 8.1473\n",
      "Epoch: 4, Index: 253, Loss: 3.1104\n",
      "Epoch: 4, Index: 254, Loss: 0.7209\n",
      "Epoch: 4, Index: 255, Loss: 0.3643\n",
      "Epoch: 4, Index: 256, Loss: 0.2135\n",
      "Epoch: 4, Index: 257, Loss: 3.0450\n",
      "Epoch: 4, Index: 258, Loss: 0.6931\n",
      "Epoch: 4, Index: 259, Loss: 10.9102\n",
      "Epoch: 4, Index: 260, Loss: 2.4547\n",
      "Epoch: 4, Index: 261, Loss: 0.3715\n",
      "Epoch: 4, Index: 262, Loss: 0.3988\n",
      "Epoch: 4, Index: 263, Loss: 6.3466\n",
      "Epoch: 4, Index: 264, Loss: 4.3325\n",
      "Epoch: 4, Index: 265, Loss: 2.4440\n",
      "Epoch: 4, Index: 266, Loss: 0.3084\n",
      "Epoch: 4, Index: 267, Loss: 3.5381\n",
      "Epoch: 4, Index: 268, Loss: 0.0945\n",
      "Epoch: 4, Index: 269, Loss: 5.4656\n",
      "Epoch: 4, Index: 270, Loss: 0.0779\n",
      "Epoch: 4, Index: 271, Loss: 2.3841\n",
      "Epoch: 4, Index: 272, Loss: 3.5150\n",
      "Epoch: 4, Index: 273, Loss: 0.0288\n",
      "Epoch: 4, Index: 274, Loss: 0.3284\n",
      "Epoch: 4, Index: 275, Loss: 0.1561\n",
      "Epoch: 4, Index: 276, Loss: 0.6926\n",
      "Epoch: 4, Index: 277, Loss: 0.4744\n",
      "Epoch: 4, Index: 278, Loss: 0.9476\n",
      "Epoch: 4, Index: 279, Loss: 1.4298\n",
      "Epoch: 4, Index: 280, Loss: 1.9787\n",
      "Epoch: 4, Index: 281, Loss: 0.5377\n",
      "Epoch: 4, Index: 282, Loss: 0.8799\n",
      "Epoch: 4, Index: 283, Loss: 0.6143\n",
      "Epoch: 4, Index: 284, Loss: 2.6722\n",
      "Epoch: 4, Index: 285, Loss: 0.6463\n",
      "Epoch: 4, Index: 286, Loss: 2.4660\n",
      "Epoch: 4, Index: 287, Loss: 0.8329\n",
      "Epoch: 4, Index: 288, Loss: 1.5972\n",
      "Epoch: 4, Index: 289, Loss: 2.9283\n",
      "Epoch: 4, Index: 290, Loss: 0.8520\n",
      "Epoch: 4, Index: 291, Loss: 4.3595\n",
      "Epoch: 4, Index: 292, Loss: 0.8002\n",
      "Epoch: 4, Index: 293, Loss: 0.0789\n",
      "Epoch: 4, Index: 294, Loss: 1.0677\n",
      "Epoch: 4, Index: 295, Loss: 0.0036\n",
      "Epoch: 4, Index: 296, Loss: 2.0891\n",
      "Epoch: 4, Index: 297, Loss: 0.5729\n",
      "Epoch: 4, Index: 298, Loss: 3.9834\n",
      "Epoch: 4, Index: 299, Loss: 0.9385\n",
      "Epoch: 4, Index: 300, Loss: 0.1327\n",
      "Epoch: 4, Index: 301, Loss: 1.9758\n",
      "Epoch: 4, Index: 302, Loss: 0.3659\n",
      "Epoch: 4, Index: 303, Loss: 0.1859\n",
      "Epoch: 4, Index: 304, Loss: 1.0459\n",
      "Epoch: 4, Index: 305, Loss: 1.5283\n",
      "Epoch: 4, Index: 306, Loss: 0.6025\n",
      "Epoch: 4, Index: 307, Loss: 6.3440\n",
      "Epoch: 4, Index: 308, Loss: 1.3657\n",
      "Epoch: 4, Index: 309, Loss: 0.7042\n",
      "Epoch: 4, Index: 310, Loss: 12.7513\n",
      "Epoch: 4, Index: 311, Loss: 1.1088\n",
      "Epoch: 4, Index: 312, Loss: 1.1006\n",
      "Epoch: 4, Index: 313, Loss: 1.7037\n",
      "Epoch: 4, Index: 314, Loss: 0.6197\n",
      "Epoch: 4, Index: 315, Loss: 4.6060\n",
      "Epoch: 4, Index: 316, Loss: 11.2814\n",
      "Epoch: 4, Index: 317, Loss: 0.0824\n",
      "Epoch: 4, Index: 318, Loss: 1.2997\n",
      "Epoch: 4, Index: 319, Loss: 0.0976\n",
      "Epoch: 4, Index: 320, Loss: 1.8938\n",
      "Epoch: 4, Index: 321, Loss: 1.5249\n",
      "Epoch: 4, Index: 322, Loss: 0.8636\n",
      "Epoch: 4, Index: 323, Loss: 0.9805\n",
      "Epoch: 4, Index: 324, Loss: 0.5158\n",
      "Epoch: 4, Index: 325, Loss: 3.5296\n",
      "Epoch: 4, Index: 326, Loss: 1.2010\n",
      "Epoch: 4, Index: 327, Loss: 2.0869\n",
      "Epoch: 4, Index: 328, Loss: 1.1499\n",
      "Epoch: 4, Index: 329, Loss: 1.1318\n",
      "Epoch: 4, Index: 330, Loss: 2.0101\n",
      "Epoch: 4, Index: 331, Loss: 1.5321\n",
      "Epoch: 4, Index: 332, Loss: 1.9882\n",
      "Epoch: 4, Index: 333, Loss: 1.9770\n",
      "Epoch: 4, Index: 334, Loss: 1.5833\n",
      "Epoch: 4, Index: 335, Loss: 0.5997\n",
      "Epoch: 4, Index: 336, Loss: 0.3668\n",
      "Epoch: 4, Index: 337, Loss: 0.1794\n",
      "Epoch: 4, Index: 338, Loss: 0.6383\n",
      "Epoch: 4, Index: 339, Loss: 1.7957\n",
      "Epoch: 4, Index: 340, Loss: 1.3031\n",
      "Epoch: 4, Index: 341, Loss: 0.5023\n",
      "Epoch: 4, Index: 342, Loss: 4.0434\n",
      "Epoch: 4, Index: 343, Loss: 0.5818\n",
      "Epoch: 4, Index: 344, Loss: 1.6734\n",
      "Epoch: 4, Index: 345, Loss: 3.4261\n",
      "Epoch: 4, Index: 346, Loss: 0.6173\n",
      "Epoch: 4, Index: 347, Loss: 1.3739\n",
      "Epoch: 4, Index: 348, Loss: 6.7547\n",
      "Epoch: 4, Index: 349, Loss: 12.0367\n",
      "Epoch: 4, Index: 350, Loss: 2.2721\n",
      "Epoch: 4, Index: 351, Loss: 3.4207\n",
      "Epoch: 4, Index: 352, Loss: 2.3119\n",
      "Epoch: 4, Index: 353, Loss: 0.9077\n",
      "Epoch: 4, Index: 354, Loss: 1.4167\n",
      "Epoch: 4, Index: 355, Loss: 1.2805\n",
      "Epoch: 4, Index: 356, Loss: 2.7789\n",
      "Epoch: 4, Index: 357, Loss: 0.1001\n",
      "Epoch: 4, Index: 358, Loss: 1.0945\n",
      "Epoch: 4, Index: 359, Loss: 1.3049\n",
      "Epoch: 4, Index: 360, Loss: 0.6646\n",
      "Epoch: 4, Index: 361, Loss: 0.4058\n",
      "Epoch: 4, Index: 362, Loss: 0.2022\n",
      "Epoch: 4, Index: 363, Loss: 3.2882\n",
      "Epoch: 4, Index: 364, Loss: 0.1317\n",
      "Epoch: 4, Index: 365, Loss: 0.6998\n",
      "Epoch: 4, Index: 366, Loss: 8.2630\n",
      "Epoch: 4, Index: 367, Loss: 2.2268\n",
      "Epoch: 4, Index: 368, Loss: 0.6376\n",
      "Epoch: 4, Index: 369, Loss: 0.1401\n",
      "Epoch: 4, Index: 370, Loss: 1.3073\n",
      "Epoch: 4, Index: 371, Loss: 0.9233\n",
      "Epoch: 4, Index: 372, Loss: 0.6302\n",
      "Epoch: 4, Index: 373, Loss: 0.3958\n",
      "Epoch: 4, Index: 374, Loss: 1.2687\n",
      "Epoch: 4, Index: 375, Loss: 1.5956\n",
      "Epoch: 4, Index: 376, Loss: 5.4300\n",
      "Epoch: 4, Index: 377, Loss: 0.8435\n",
      "Epoch: 4, Index: 378, Loss: 0.8450\n",
      "Epoch: 4, Index: 379, Loss: 1.7299\n",
      "Epoch: 4, Index: 380, Loss: 0.3926\n",
      "Epoch: 4, Index: 381, Loss: 7.0877\n",
      "Epoch: 4, Index: 382, Loss: 0.0812\n",
      "Epoch: 4, Index: 383, Loss: 1.6100\n",
      "Epoch: 4, Index: 384, Loss: 1.6641\n",
      "Epoch: 4, Index: 385, Loss: 2.5317\n",
      "Epoch: 4, Index: 386, Loss: 0.8143\n",
      "Epoch: 4, Index: 387, Loss: 0.5603\n",
      "Epoch: 4, Index: 388, Loss: 5.2251\n",
      "Epoch: 4, Index: 389, Loss: 1.2297\n",
      "Epoch: 4, Index: 390, Loss: 0.8758\n",
      "Epoch: 4, Index: 391, Loss: 0.2478\n",
      "Epoch: 4, Index: 392, Loss: 1.5962\n",
      "Epoch: 4, Index: 393, Loss: 0.4832\n",
      "Epoch: 4, Index: 394, Loss: 2.6872\n",
      "Epoch: 4, Index: 395, Loss: 0.6799\n",
      "Epoch: 4, Index: 396, Loss: 1.3640\n",
      "Epoch: 4, Index: 397, Loss: 5.4543\n",
      "Epoch: 4, Index: 398, Loss: 1.5262\n",
      "Epoch: 4, Index: 399, Loss: 1.1621\n",
      "Epoch: 4, Index: 400, Loss: 1.8487\n",
      "Epoch: 4, Index: 401, Loss: 0.4173\n",
      "Epoch: 4, Index: 402, Loss: 3.6169\n",
      "Epoch: 4, Index: 403, Loss: 0.0480\n",
      "Epoch: 4, Index: 404, Loss: 2.4767\n",
      "Epoch: 4, Index: 405, Loss: 0.4082\n",
      "Epoch: 4, Index: 406, Loss: 0.7191\n",
      "Epoch: 4, Index: 407, Loss: 0.5241\n",
      "Epoch: 4, Index: 408, Loss: 0.6912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a991d787213c466280df12c70f75ce40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Index: 0, Loss: 0.6898\n",
      "Epoch: 5, Index: 1, Loss: 1.4140\n",
      "Epoch: 5, Index: 2, Loss: 1.3751\n",
      "Epoch: 5, Index: 3, Loss: 2.1495\n",
      "Epoch: 5, Index: 4, Loss: 0.9303\n",
      "Epoch: 5, Index: 5, Loss: 4.5388\n",
      "Epoch: 5, Index: 6, Loss: 2.8365\n",
      "Epoch: 5, Index: 7, Loss: 3.3196\n",
      "Epoch: 5, Index: 8, Loss: 0.7264\n",
      "Epoch: 5, Index: 9, Loss: 0.6848\n",
      "Epoch: 5, Index: 10, Loss: 0.2478\n",
      "Epoch: 5, Index: 11, Loss: 4.5803\n",
      "Epoch: 5, Index: 12, Loss: 0.2390\n",
      "Epoch: 5, Index: 13, Loss: 0.1096\n",
      "Epoch: 5, Index: 14, Loss: 0.8488\n",
      "Epoch: 5, Index: 15, Loss: 1.7773\n",
      "Epoch: 5, Index: 16, Loss: 0.7728\n",
      "Epoch: 5, Index: 17, Loss: 0.7860\n",
      "Epoch: 5, Index: 18, Loss: 1.0747\n",
      "Epoch: 5, Index: 19, Loss: 0.3597\n",
      "Epoch: 5, Index: 20, Loss: 5.3524\n",
      "Epoch: 5, Index: 21, Loss: 0.6541\n",
      "Epoch: 5, Index: 22, Loss: 0.5908\n",
      "Epoch: 5, Index: 23, Loss: 4.7740\n",
      "Epoch: 5, Index: 24, Loss: 0.5275\n",
      "Epoch: 5, Index: 25, Loss: 0.4471\n",
      "Epoch: 5, Index: 26, Loss: 0.2663\n",
      "Epoch: 5, Index: 27, Loss: 6.1426\n",
      "Epoch: 5, Index: 28, Loss: 1.1821\n",
      "Epoch: 5, Index: 29, Loss: 0.5703\n",
      "Epoch: 5, Index: 30, Loss: 1.3316\n",
      "Epoch: 5, Index: 31, Loss: 2.0872\n",
      "Epoch: 5, Index: 32, Loss: 3.6704\n",
      "Epoch: 5, Index: 33, Loss: 0.8297\n",
      "Epoch: 5, Index: 34, Loss: 14.0198\n",
      "Epoch: 5, Index: 35, Loss: 0.5759\n",
      "Epoch: 5, Index: 36, Loss: 0.9956\n",
      "Epoch: 5, Index: 37, Loss: 0.1939\n",
      "Epoch: 5, Index: 38, Loss: 0.0813\n",
      "Epoch: 5, Index: 39, Loss: 0.0979\n",
      "Epoch: 5, Index: 40, Loss: 0.6985\n",
      "Epoch: 5, Index: 41, Loss: 0.0665\n",
      "Epoch: 5, Index: 42, Loss: 1.5335\n",
      "Epoch: 5, Index: 43, Loss: 0.2666\n",
      "Epoch: 5, Index: 44, Loss: 0.2487\n",
      "Epoch: 5, Index: 45, Loss: 1.9606\n",
      "Epoch: 5, Index: 46, Loss: 1.0853\n",
      "Epoch: 5, Index: 47, Loss: 0.6881\n",
      "Epoch: 5, Index: 48, Loss: 0.9996\n",
      "Epoch: 5, Index: 49, Loss: 3.8532\n",
      "Epoch: 5, Index: 50, Loss: 1.0395\n",
      "Epoch: 5, Index: 51, Loss: 2.7942\n",
      "Epoch: 5, Index: 52, Loss: 0.3664\n",
      "Epoch: 5, Index: 53, Loss: 2.2978\n",
      "Epoch: 5, Index: 54, Loss: 3.9733\n",
      "Epoch: 5, Index: 55, Loss: 3.4964\n",
      "Epoch: 5, Index: 56, Loss: 0.5575\n",
      "Epoch: 5, Index: 57, Loss: 0.2880\n",
      "Epoch: 5, Index: 58, Loss: 5.3959\n",
      "Epoch: 5, Index: 59, Loss: 2.4914\n",
      "Epoch: 5, Index: 60, Loss: 0.6990\n",
      "Epoch: 5, Index: 61, Loss: 1.1492\n",
      "Epoch: 5, Index: 62, Loss: 0.6645\n",
      "Epoch: 5, Index: 63, Loss: 0.9259\n",
      "Epoch: 5, Index: 64, Loss: 0.2666\n",
      "Epoch: 5, Index: 65, Loss: 1.4168\n",
      "Epoch: 5, Index: 66, Loss: 2.8054\n",
      "Epoch: 5, Index: 67, Loss: 0.6994\n",
      "Epoch: 5, Index: 68, Loss: 1.5647\n",
      "Epoch: 5, Index: 69, Loss: 4.3890\n",
      "Epoch: 5, Index: 70, Loss: 0.4106\n",
      "Epoch: 5, Index: 71, Loss: 0.1905\n",
      "Epoch: 5, Index: 72, Loss: 1.2714\n",
      "Epoch: 5, Index: 73, Loss: 2.6273\n",
      "Epoch: 5, Index: 74, Loss: 0.1979\n",
      "Epoch: 5, Index: 75, Loss: 0.9686\n",
      "Epoch: 5, Index: 76, Loss: 2.4051\n",
      "Epoch: 5, Index: 77, Loss: 4.3754\n",
      "Epoch: 5, Index: 78, Loss: 3.1813\n",
      "Epoch: 5, Index: 79, Loss: 3.0072\n",
      "Epoch: 5, Index: 80, Loss: 0.6433\n",
      "Epoch: 5, Index: 81, Loss: 0.7070\n",
      "Epoch: 5, Index: 82, Loss: 0.2901\n",
      "Epoch: 5, Index: 83, Loss: 0.6469\n",
      "Epoch: 5, Index: 84, Loss: 0.3611\n",
      "Epoch: 5, Index: 85, Loss: 5.4756\n",
      "Epoch: 5, Index: 86, Loss: 1.5375\n",
      "Epoch: 5, Index: 87, Loss: 0.5424\n",
      "Epoch: 5, Index: 88, Loss: 2.6278\n",
      "Epoch: 5, Index: 89, Loss: 0.5331\n",
      "Epoch: 5, Index: 90, Loss: 2.9113\n",
      "Epoch: 5, Index: 91, Loss: 3.2742\n",
      "Epoch: 5, Index: 92, Loss: 5.3306\n",
      "Epoch: 5, Index: 93, Loss: 0.4437\n",
      "Epoch: 5, Index: 94, Loss: 9.3210\n",
      "Epoch: 5, Index: 95, Loss: 1.3936\n",
      "Epoch: 5, Index: 96, Loss: 0.5137\n",
      "Epoch: 5, Index: 97, Loss: 3.5826\n",
      "Epoch: 5, Index: 98, Loss: 0.0449\n",
      "Epoch: 5, Index: 99, Loss: 0.0437\n",
      "Epoch: 5, Index: 100, Loss: 0.7793\n",
      "Epoch: 5, Index: 101, Loss: 1.9588\n",
      "Epoch: 5, Index: 102, Loss: 1.1170\n",
      "Epoch: 5, Index: 103, Loss: 8.6655\n",
      "Epoch: 5, Index: 104, Loss: 0.2320\n",
      "Epoch: 5, Index: 105, Loss: 1.3962\n",
      "Epoch: 5, Index: 106, Loss: 6.4888\n",
      "Epoch: 5, Index: 107, Loss: 3.2615\n",
      "Epoch: 5, Index: 108, Loss: 0.9172\n",
      "Epoch: 5, Index: 109, Loss: 0.2656\n",
      "Epoch: 5, Index: 110, Loss: 1.8486\n",
      "Epoch: 5, Index: 111, Loss: 1.1231\n",
      "Epoch: 5, Index: 112, Loss: 1.0487\n",
      "Epoch: 5, Index: 113, Loss: 1.5530\n",
      "Epoch: 5, Index: 114, Loss: 2.6501\n",
      "Epoch: 5, Index: 115, Loss: 0.4744\n",
      "Epoch: 5, Index: 116, Loss: 3.9360\n",
      "Epoch: 5, Index: 117, Loss: 1.7284\n",
      "Epoch: 5, Index: 118, Loss: 2.5524\n",
      "Epoch: 5, Index: 119, Loss: 1.2350\n",
      "Epoch: 5, Index: 120, Loss: 0.1694\n",
      "Epoch: 5, Index: 121, Loss: 2.3572\n",
      "Epoch: 5, Index: 122, Loss: 1.8370\n",
      "Epoch: 5, Index: 123, Loss: 3.3699\n",
      "Epoch: 5, Index: 124, Loss: 1.4883\n",
      "Epoch: 5, Index: 125, Loss: 0.2941\n",
      "Epoch: 5, Index: 126, Loss: 0.1736\n",
      "Epoch: 5, Index: 127, Loss: 0.1232\n",
      "Epoch: 5, Index: 128, Loss: 2.6377\n",
      "Epoch: 5, Index: 129, Loss: 0.3303\n",
      "Epoch: 5, Index: 130, Loss: 1.0928\n",
      "Epoch: 5, Index: 131, Loss: 0.5172\n",
      "Epoch: 5, Index: 132, Loss: 0.4275\n",
      "Epoch: 5, Index: 133, Loss: 2.3064\n",
      "Epoch: 5, Index: 134, Loss: 1.2229\n",
      "Epoch: 5, Index: 135, Loss: 2.9954\n",
      "Epoch: 5, Index: 136, Loss: 2.4270\n",
      "Epoch: 5, Index: 137, Loss: 2.0819\n",
      "Epoch: 5, Index: 138, Loss: 0.0885\n",
      "Epoch: 5, Index: 139, Loss: 1.0108\n",
      "Epoch: 5, Index: 140, Loss: 3.8278\n",
      "Epoch: 5, Index: 141, Loss: 1.2230\n",
      "Epoch: 5, Index: 142, Loss: 1.3644\n",
      "Epoch: 5, Index: 143, Loss: 1.5007\n",
      "Epoch: 5, Index: 144, Loss: 0.5099\n",
      "Epoch: 5, Index: 145, Loss: 0.5889\n",
      "Epoch: 5, Index: 146, Loss: 0.2814\n",
      "Epoch: 5, Index: 147, Loss: 1.2106\n",
      "Epoch: 5, Index: 148, Loss: 2.4997\n",
      "Epoch: 5, Index: 149, Loss: 1.5613\n",
      "Epoch: 5, Index: 150, Loss: 0.1723\n",
      "Epoch: 5, Index: 151, Loss: 1.3371\n",
      "Epoch: 5, Index: 152, Loss: 1.3467\n",
      "Epoch: 5, Index: 153, Loss: 0.1567\n",
      "Epoch: 5, Index: 154, Loss: 4.3575\n",
      "Epoch: 5, Index: 155, Loss: 0.3749\n",
      "Epoch: 5, Index: 156, Loss: 0.6412\n",
      "Epoch: 5, Index: 157, Loss: 0.5818\n",
      "Epoch: 5, Index: 158, Loss: 3.0430\n",
      "Epoch: 5, Index: 159, Loss: 1.9126\n",
      "Epoch: 5, Index: 160, Loss: 3.2145\n",
      "Epoch: 5, Index: 161, Loss: 3.6044\n",
      "Epoch: 5, Index: 162, Loss: 0.0875\n",
      "Epoch: 5, Index: 163, Loss: 0.0895\n",
      "Epoch: 5, Index: 164, Loss: 0.4781\n",
      "Epoch: 5, Index: 165, Loss: 0.7256\n",
      "Epoch: 5, Index: 166, Loss: 1.4259\n",
      "Epoch: 5, Index: 167, Loss: 1.3459\n",
      "Epoch: 5, Index: 168, Loss: 0.2107\n",
      "Epoch: 5, Index: 169, Loss: 0.5276\n",
      "Epoch: 5, Index: 170, Loss: 1.8852\n",
      "Epoch: 5, Index: 171, Loss: 0.2143\n",
      "Epoch: 5, Index: 172, Loss: 1.0594\n",
      "Epoch: 5, Index: 173, Loss: 3.4270\n",
      "Epoch: 5, Index: 174, Loss: 0.3774\n",
      "Epoch: 5, Index: 175, Loss: 0.7659\n",
      "Epoch: 5, Index: 176, Loss: 1.8949\n",
      "Epoch: 5, Index: 177, Loss: 0.0999\n",
      "Epoch: 5, Index: 178, Loss: 1.2114\n",
      "Epoch: 5, Index: 179, Loss: 0.0932\n",
      "Epoch: 5, Index: 180, Loss: 0.0302\n",
      "Epoch: 5, Index: 181, Loss: 0.7471\n",
      "Epoch: 5, Index: 182, Loss: 2.2008\n",
      "Epoch: 5, Index: 183, Loss: 0.1588\n",
      "Epoch: 5, Index: 184, Loss: 3.3725\n",
      "Epoch: 5, Index: 185, Loss: 1.8162\n",
      "Epoch: 5, Index: 186, Loss: 0.7434\n",
      "Epoch: 5, Index: 187, Loss: 0.4129\n",
      "Epoch: 5, Index: 188, Loss: 1.2832\n",
      "Epoch: 5, Index: 189, Loss: 2.6659\n",
      "Epoch: 5, Index: 190, Loss: 5.0768\n",
      "Epoch: 5, Index: 191, Loss: 0.1058\n",
      "Epoch: 5, Index: 192, Loss: 0.2466\n",
      "Epoch: 5, Index: 193, Loss: 0.2510\n",
      "Epoch: 5, Index: 194, Loss: 6.4751\n",
      "Epoch: 5, Index: 195, Loss: 3.9630\n",
      "Epoch: 5, Index: 196, Loss: 2.1787\n",
      "Epoch: 5, Index: 197, Loss: 2.6931\n",
      "Epoch: 5, Index: 198, Loss: 1.2882\n",
      "Epoch: 5, Index: 199, Loss: 2.8459\n",
      "Epoch: 5, Index: 200, Loss: 0.3174\n",
      "Epoch: 5, Index: 201, Loss: 0.0422\n",
      "Epoch: 5, Index: 202, Loss: 0.5074\n",
      "Epoch: 5, Index: 203, Loss: 3.2012\n",
      "Epoch: 5, Index: 204, Loss: 1.3924\n",
      "Epoch: 5, Index: 205, Loss: 2.6835\n",
      "Epoch: 5, Index: 206, Loss: 0.3798\n",
      "Epoch: 5, Index: 207, Loss: 7.7131\n",
      "Epoch: 5, Index: 208, Loss: 0.9543\n",
      "Epoch: 5, Index: 209, Loss: 5.2926\n",
      "Epoch: 5, Index: 210, Loss: 2.1901\n",
      "Epoch: 5, Index: 211, Loss: 2.2877\n",
      "Epoch: 5, Index: 212, Loss: 5.1314\n",
      "Epoch: 5, Index: 213, Loss: 0.0942\n",
      "Epoch: 5, Index: 214, Loss: 3.2318\n",
      "Epoch: 5, Index: 215, Loss: 1.1341\n",
      "Epoch: 5, Index: 216, Loss: 0.8923\n",
      "Epoch: 5, Index: 217, Loss: 0.0005\n",
      "Epoch: 5, Index: 218, Loss: 0.4026\n",
      "Epoch: 5, Index: 219, Loss: 3.0659\n",
      "Epoch: 5, Index: 220, Loss: 2.7502\n",
      "Epoch: 5, Index: 221, Loss: 1.1611\n",
      "Epoch: 5, Index: 222, Loss: 0.3284\n",
      "Epoch: 5, Index: 223, Loss: 8.4806\n",
      "Epoch: 5, Index: 224, Loss: 1.7316\n",
      "Epoch: 5, Index: 225, Loss: 1.6625\n",
      "Epoch: 5, Index: 226, Loss: 1.6205\n",
      "Epoch: 5, Index: 227, Loss: 1.5474\n",
      "Epoch: 5, Index: 228, Loss: 1.2825\n",
      "Epoch: 5, Index: 229, Loss: 3.9063\n",
      "Epoch: 5, Index: 230, Loss: 1.0250\n",
      "Epoch: 5, Index: 231, Loss: 0.4321\n",
      "Epoch: 5, Index: 232, Loss: 1.5399\n",
      "Epoch: 5, Index: 233, Loss: 0.6000\n",
      "Epoch: 5, Index: 234, Loss: 1.6357\n",
      "Epoch: 5, Index: 235, Loss: 0.0352\n",
      "Epoch: 5, Index: 236, Loss: 0.0681\n",
      "Epoch: 5, Index: 237, Loss: 2.0879\n",
      "Epoch: 5, Index: 238, Loss: 0.4935\n",
      "Epoch: 5, Index: 239, Loss: 2.8602\n",
      "Epoch: 5, Index: 240, Loss: 5.4188\n",
      "Epoch: 5, Index: 241, Loss: 0.7698\n",
      "Epoch: 5, Index: 242, Loss: 0.0367\n",
      "Epoch: 5, Index: 243, Loss: 0.8974\n",
      "Epoch: 5, Index: 244, Loss: 3.3778\n",
      "Epoch: 5, Index: 245, Loss: 1.0735\n",
      "Epoch: 5, Index: 246, Loss: 1.9488\n",
      "Epoch: 5, Index: 247, Loss: 0.8913\n",
      "Epoch: 5, Index: 248, Loss: 0.9904\n",
      "Epoch: 5, Index: 249, Loss: 3.3643\n",
      "Epoch: 5, Index: 250, Loss: 0.6721\n",
      "Epoch: 5, Index: 251, Loss: 1.0525\n",
      "Epoch: 5, Index: 252, Loss: 1.1944\n",
      "Epoch: 5, Index: 253, Loss: 1.7579\n",
      "Epoch: 5, Index: 254, Loss: 2.9261\n",
      "Epoch: 5, Index: 255, Loss: 0.3408\n",
      "Epoch: 5, Index: 256, Loss: 0.8542\n",
      "Epoch: 5, Index: 257, Loss: 0.6748\n",
      "Epoch: 5, Index: 258, Loss: 2.9723\n",
      "Epoch: 5, Index: 259, Loss: 1.1889\n",
      "Epoch: 5, Index: 260, Loss: 0.0221\n",
      "Epoch: 5, Index: 261, Loss: 0.7038\n",
      "Epoch: 5, Index: 262, Loss: 0.1403\n",
      "Epoch: 5, Index: 263, Loss: 1.1853\n",
      "Epoch: 5, Index: 264, Loss: 2.6697\n",
      "Epoch: 5, Index: 265, Loss: 0.5073\n",
      "Epoch: 5, Index: 266, Loss: 0.7120\n",
      "Epoch: 5, Index: 267, Loss: 1.0154\n",
      "Epoch: 5, Index: 268, Loss: 0.9959\n",
      "Epoch: 5, Index: 269, Loss: 0.0800\n",
      "Epoch: 5, Index: 270, Loss: 1.0825\n",
      "Epoch: 5, Index: 271, Loss: 0.4202\n",
      "Epoch: 5, Index: 272, Loss: 0.7018\n",
      "Epoch: 5, Index: 273, Loss: 1.8483\n",
      "Epoch: 5, Index: 274, Loss: 5.1551\n",
      "Epoch: 5, Index: 275, Loss: 2.1927\n",
      "Epoch: 5, Index: 276, Loss: 0.9761\n",
      "Epoch: 5, Index: 277, Loss: 0.2131\n",
      "Epoch: 5, Index: 278, Loss: 1.8495\n",
      "Epoch: 5, Index: 279, Loss: 0.0444\n",
      "Epoch: 5, Index: 280, Loss: 1.3508\n",
      "Epoch: 5, Index: 281, Loss: 2.5815\n",
      "Epoch: 5, Index: 282, Loss: 1.3324\n",
      "Epoch: 5, Index: 283, Loss: 5.6804\n",
      "Epoch: 5, Index: 284, Loss: 5.5089\n",
      "Epoch: 5, Index: 285, Loss: 5.5857\n",
      "Epoch: 5, Index: 286, Loss: 1.3879\n",
      "Epoch: 5, Index: 287, Loss: 4.1991\n",
      "Epoch: 5, Index: 288, Loss: 2.7600\n",
      "Epoch: 5, Index: 289, Loss: 0.0358\n",
      "Epoch: 5, Index: 290, Loss: 2.4686\n",
      "Epoch: 5, Index: 291, Loss: 0.1012\n",
      "Epoch: 5, Index: 292, Loss: 0.0268\n",
      "Epoch: 5, Index: 293, Loss: 1.0004\n",
      "Epoch: 5, Index: 294, Loss: 1.2869\n",
      "Epoch: 5, Index: 295, Loss: 1.6424\n",
      "Epoch: 5, Index: 296, Loss: 0.0747\n",
      "Epoch: 5, Index: 297, Loss: 1.2483\n",
      "Epoch: 5, Index: 298, Loss: 3.4927\n",
      "Epoch: 5, Index: 299, Loss: 6.7861\n",
      "Epoch: 5, Index: 300, Loss: 1.6337\n",
      "Epoch: 5, Index: 301, Loss: 2.7577\n",
      "Epoch: 5, Index: 302, Loss: 0.7390\n",
      "Epoch: 5, Index: 303, Loss: 0.3562\n",
      "Epoch: 5, Index: 304, Loss: 2.2616\n",
      "Epoch: 5, Index: 305, Loss: 10.5760\n",
      "Epoch: 5, Index: 306, Loss: 0.9370\n",
      "Epoch: 5, Index: 307, Loss: 3.9709\n",
      "Epoch: 5, Index: 308, Loss: 0.2649\n",
      "Epoch: 5, Index: 309, Loss: 0.6275\n",
      "Epoch: 5, Index: 310, Loss: 0.7675\n",
      "Epoch: 5, Index: 311, Loss: 1.6549\n",
      "Epoch: 5, Index: 312, Loss: 6.0844\n",
      "Epoch: 5, Index: 313, Loss: 0.3429\n",
      "Epoch: 5, Index: 314, Loss: 0.7765\n",
      "Epoch: 5, Index: 315, Loss: 5.0445\n",
      "Epoch: 5, Index: 316, Loss: 1.4655\n",
      "Epoch: 5, Index: 317, Loss: 2.1638\n",
      "Epoch: 5, Index: 318, Loss: 3.0847\n",
      "Epoch: 5, Index: 319, Loss: 3.6562\n",
      "Epoch: 5, Index: 320, Loss: 1.4787\n",
      "Epoch: 5, Index: 321, Loss: 7.5592\n",
      "Epoch: 5, Index: 322, Loss: 3.9545\n",
      "Epoch: 5, Index: 323, Loss: 2.3654\n",
      "Epoch: 5, Index: 324, Loss: 0.1751\n",
      "Epoch: 5, Index: 325, Loss: 0.2045\n",
      "Epoch: 5, Index: 326, Loss: 0.3618\n",
      "Epoch: 5, Index: 327, Loss: 13.1664\n",
      "Epoch: 5, Index: 328, Loss: 0.2370\n",
      "Epoch: 5, Index: 329, Loss: 1.5155\n",
      "Epoch: 5, Index: 330, Loss: 2.2811\n",
      "Epoch: 5, Index: 331, Loss: 0.9236\n",
      "Epoch: 5, Index: 332, Loss: 0.0079\n",
      "Epoch: 5, Index: 333, Loss: 1.1641\n",
      "Epoch: 5, Index: 334, Loss: 1.5962\n",
      "Epoch: 5, Index: 335, Loss: 0.7620\n",
      "Epoch: 5, Index: 336, Loss: 1.0847\n",
      "Epoch: 5, Index: 337, Loss: 2.0109\n",
      "Epoch: 5, Index: 338, Loss: 0.2401\n",
      "Epoch: 5, Index: 339, Loss: 1.0252\n",
      "Epoch: 5, Index: 340, Loss: 0.2186\n",
      "Epoch: 5, Index: 341, Loss: 2.2842\n",
      "Epoch: 5, Index: 342, Loss: 3.0632\n",
      "Epoch: 5, Index: 343, Loss: 1.4252\n",
      "Epoch: 5, Index: 344, Loss: 1.1741\n",
      "Epoch: 5, Index: 345, Loss: 2.4654\n",
      "Epoch: 5, Index: 346, Loss: 7.2031\n",
      "Epoch: 5, Index: 347, Loss: 7.5097\n",
      "Epoch: 5, Index: 348, Loss: 2.5902\n",
      "Epoch: 5, Index: 349, Loss: 0.7978\n",
      "Epoch: 5, Index: 350, Loss: 3.2951\n",
      "Epoch: 5, Index: 351, Loss: 0.9381\n",
      "Epoch: 5, Index: 352, Loss: 1.1108\n",
      "Epoch: 5, Index: 353, Loss: 0.0727\n",
      "Epoch: 5, Index: 354, Loss: 12.9759\n",
      "Epoch: 5, Index: 355, Loss: 1.0201\n",
      "Epoch: 5, Index: 356, Loss: 0.5820\n",
      "Epoch: 5, Index: 357, Loss: 2.8088\n",
      "Epoch: 5, Index: 358, Loss: 2.0734\n",
      "Epoch: 5, Index: 359, Loss: 6.1443\n",
      "Epoch: 5, Index: 360, Loss: 3.6045\n",
      "Epoch: 5, Index: 361, Loss: 1.2289\n",
      "Epoch: 5, Index: 362, Loss: 6.8060\n",
      "Epoch: 5, Index: 363, Loss: 4.3317\n",
      "Epoch: 5, Index: 364, Loss: 0.7612\n",
      "Epoch: 5, Index: 365, Loss: 1.0338\n",
      "Epoch: 5, Index: 366, Loss: 0.4985\n",
      "Epoch: 5, Index: 367, Loss: 1.3523\n",
      "Epoch: 5, Index: 368, Loss: 1.6526\n",
      "Epoch: 5, Index: 369, Loss: 0.3407\n",
      "Epoch: 5, Index: 370, Loss: 6.4109\n",
      "Epoch: 5, Index: 371, Loss: 0.7109\n",
      "Epoch: 5, Index: 372, Loss: 2.1077\n",
      "Epoch: 5, Index: 373, Loss: 3.1237\n",
      "Epoch: 5, Index: 374, Loss: 2.1938\n",
      "Epoch: 5, Index: 375, Loss: 1.2703\n",
      "Epoch: 5, Index: 376, Loss: 0.4175\n",
      "Epoch: 5, Index: 377, Loss: 0.5425\n",
      "Epoch: 5, Index: 378, Loss: 0.5215\n",
      "Epoch: 5, Index: 379, Loss: 2.3230\n",
      "Epoch: 5, Index: 380, Loss: 1.8709\n",
      "Epoch: 5, Index: 381, Loss: 1.0754\n",
      "Epoch: 5, Index: 382, Loss: 5.4580\n",
      "Epoch: 5, Index: 383, Loss: 2.4688\n",
      "Epoch: 5, Index: 384, Loss: 2.3995\n",
      "Epoch: 5, Index: 385, Loss: 2.1424\n",
      "Epoch: 5, Index: 386, Loss: 2.7434\n",
      "Epoch: 5, Index: 387, Loss: 2.9809\n",
      "Epoch: 5, Index: 388, Loss: 3.9395\n",
      "Epoch: 5, Index: 389, Loss: 6.0505\n",
      "Epoch: 5, Index: 390, Loss: 0.0475\n",
      "Epoch: 5, Index: 391, Loss: 2.8566\n",
      "Epoch: 5, Index: 392, Loss: 8.5758\n",
      "Epoch: 5, Index: 393, Loss: 3.7403\n",
      "Epoch: 5, Index: 394, Loss: 0.8488\n",
      "Epoch: 5, Index: 395, Loss: 4.6750\n",
      "Epoch: 5, Index: 396, Loss: 5.4453\n",
      "Epoch: 5, Index: 397, Loss: 4.9290\n",
      "Epoch: 5, Index: 398, Loss: 3.4595\n",
      "Epoch: 5, Index: 399, Loss: 2.8569\n",
      "Epoch: 5, Index: 400, Loss: 1.4899\n",
      "Epoch: 5, Index: 401, Loss: 1.3613\n",
      "Epoch: 5, Index: 402, Loss: 0.4229\n",
      "Epoch: 5, Index: 403, Loss: 2.2272\n",
      "Epoch: 5, Index: 404, Loss: 1.9836\n",
      "Epoch: 5, Index: 405, Loss: 3.7839\n",
      "Epoch: 5, Index: 406, Loss: 1.5566\n",
      "Epoch: 5, Index: 407, Loss: 5.1749\n",
      "Epoch: 5, Index: 408, Loss: 0.3427\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1164725cfa417e906e7a675c157362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Index: 0, Loss: 8.2199\n",
      "Epoch: 6, Index: 1, Loss: 0.9182\n",
      "Epoch: 6, Index: 2, Loss: 0.2843\n",
      "Epoch: 6, Index: 3, Loss: 0.6193\n",
      "Epoch: 6, Index: 4, Loss: 2.7305\n",
      "Epoch: 6, Index: 5, Loss: 3.9321\n",
      "Epoch: 6, Index: 6, Loss: 1.2844\n",
      "Epoch: 6, Index: 7, Loss: 4.0737\n",
      "Epoch: 6, Index: 8, Loss: 3.2548\n",
      "Epoch: 6, Index: 9, Loss: 1.4788\n",
      "Epoch: 6, Index: 10, Loss: 4.3661\n",
      "Epoch: 6, Index: 11, Loss: 4.4971\n",
      "Epoch: 6, Index: 12, Loss: 0.5815\n",
      "Epoch: 6, Index: 13, Loss: 1.9418\n",
      "Epoch: 6, Index: 14, Loss: 1.7934\n",
      "Epoch: 6, Index: 15, Loss: 2.6790\n",
      "Epoch: 6, Index: 16, Loss: 0.2166\n",
      "Epoch: 6, Index: 17, Loss: 2.1682\n",
      "Epoch: 6, Index: 18, Loss: 1.9731\n",
      "Epoch: 6, Index: 19, Loss: 0.3229\n",
      "Epoch: 6, Index: 20, Loss: 4.2666\n",
      "Epoch: 6, Index: 21, Loss: 0.0549\n",
      "Epoch: 6, Index: 22, Loss: 1.2072\n",
      "Epoch: 6, Index: 23, Loss: 0.3138\n",
      "Epoch: 6, Index: 24, Loss: 2.0371\n",
      "Epoch: 6, Index: 25, Loss: 0.6690\n",
      "Epoch: 6, Index: 26, Loss: 2.7666\n",
      "Epoch: 6, Index: 27, Loss: 0.8165\n",
      "Epoch: 6, Index: 28, Loss: 0.7252\n",
      "Epoch: 6, Index: 29, Loss: 2.7741\n",
      "Epoch: 6, Index: 30, Loss: 0.7855\n",
      "Epoch: 6, Index: 31, Loss: 0.0097\n",
      "Epoch: 6, Index: 32, Loss: 1.4144\n",
      "Epoch: 6, Index: 33, Loss: 11.1463\n",
      "Epoch: 6, Index: 34, Loss: 2.0074\n",
      "Epoch: 6, Index: 35, Loss: 1.3732\n",
      "Epoch: 6, Index: 36, Loss: 6.1911\n",
      "Epoch: 6, Index: 37, Loss: 0.3586\n",
      "Epoch: 6, Index: 38, Loss: 3.4242\n",
      "Epoch: 6, Index: 39, Loss: 2.4468\n",
      "Epoch: 6, Index: 40, Loss: 1.3357\n",
      "Epoch: 6, Index: 41, Loss: 0.2126\n",
      "Epoch: 6, Index: 42, Loss: 2.4460\n",
      "Epoch: 6, Index: 43, Loss: 0.7645\n",
      "Epoch: 6, Index: 44, Loss: 0.2736\n",
      "Epoch: 6, Index: 45, Loss: 0.0953\n",
      "Epoch: 6, Index: 46, Loss: 0.3718\n",
      "Epoch: 6, Index: 47, Loss: 0.2754\n",
      "Epoch: 6, Index: 48, Loss: 4.8199\n",
      "Epoch: 6, Index: 49, Loss: 4.6568\n",
      "Epoch: 6, Index: 50, Loss: 1.6119\n",
      "Epoch: 6, Index: 51, Loss: 4.7952\n",
      "Epoch: 6, Index: 52, Loss: 2.2991\n",
      "Epoch: 6, Index: 53, Loss: 0.1020\n",
      "Epoch: 6, Index: 54, Loss: 6.9088\n",
      "Epoch: 6, Index: 55, Loss: 1.7990\n",
      "Epoch: 6, Index: 56, Loss: 0.0460\n",
      "Epoch: 6, Index: 57, Loss: 3.9665\n",
      "Epoch: 6, Index: 58, Loss: 0.6782\n",
      "Epoch: 6, Index: 59, Loss: 0.5031\n",
      "Epoch: 6, Index: 60, Loss: 0.0476\n",
      "Epoch: 6, Index: 61, Loss: 1.6655\n",
      "Epoch: 6, Index: 62, Loss: 0.3403\n",
      "Epoch: 6, Index: 63, Loss: 2.4771\n",
      "Epoch: 6, Index: 64, Loss: 1.2285\n",
      "Epoch: 6, Index: 65, Loss: 1.0838\n",
      "Epoch: 6, Index: 66, Loss: 5.2071\n",
      "Epoch: 6, Index: 67, Loss: 6.8920\n",
      "Epoch: 6, Index: 68, Loss: 0.9905\n",
      "Epoch: 6, Index: 69, Loss: 4.6667\n",
      "Epoch: 6, Index: 70, Loss: 4.3643\n",
      "Epoch: 6, Index: 71, Loss: 2.7609\n",
      "Epoch: 6, Index: 72, Loss: 1.1627\n",
      "Epoch: 6, Index: 73, Loss: 0.4504\n",
      "Epoch: 6, Index: 74, Loss: 0.2021\n",
      "Epoch: 6, Index: 75, Loss: 0.1795\n",
      "Epoch: 6, Index: 76, Loss: 0.5224\n",
      "Epoch: 6, Index: 77, Loss: 1.3801\n",
      "Epoch: 6, Index: 78, Loss: 0.8369\n",
      "Epoch: 6, Index: 79, Loss: 0.2230\n",
      "Epoch: 6, Index: 80, Loss: 0.2884\n",
      "Epoch: 6, Index: 81, Loss: 0.2160\n",
      "Epoch: 6, Index: 82, Loss: 0.7181\n",
      "Epoch: 6, Index: 83, Loss: 2.9017\n",
      "Epoch: 6, Index: 84, Loss: 0.3314\n",
      "Epoch: 6, Index: 85, Loss: 3.0673\n",
      "Epoch: 6, Index: 86, Loss: 2.9284\n",
      "Epoch: 6, Index: 87, Loss: 0.3120\n",
      "Epoch: 6, Index: 88, Loss: 1.5956\n",
      "Epoch: 6, Index: 89, Loss: 0.2608\n",
      "Epoch: 6, Index: 90, Loss: 0.3857\n",
      "Epoch: 6, Index: 91, Loss: 1.0775\n",
      "Epoch: 6, Index: 92, Loss: 0.9445\n",
      "Epoch: 6, Index: 93, Loss: 0.6432\n",
      "Epoch: 6, Index: 94, Loss: 0.9901\n",
      "Epoch: 6, Index: 95, Loss: 0.1998\n",
      "Epoch: 6, Index: 96, Loss: 0.1208\n",
      "Epoch: 6, Index: 97, Loss: 4.0431\n",
      "Epoch: 6, Index: 98, Loss: 0.4301\n",
      "Epoch: 6, Index: 99, Loss: 3.6054\n",
      "Epoch: 6, Index: 100, Loss: 0.6912\n",
      "Epoch: 6, Index: 101, Loss: 3.0703\n",
      "Epoch: 6, Index: 102, Loss: 4.3878\n",
      "Epoch: 6, Index: 103, Loss: 2.5714\n",
      "Epoch: 6, Index: 104, Loss: 1.6971\n",
      "Epoch: 6, Index: 105, Loss: 3.1539\n",
      "Epoch: 6, Index: 106, Loss: 1.0574\n",
      "Epoch: 6, Index: 107, Loss: 3.1696\n",
      "Epoch: 6, Index: 108, Loss: 1.9916\n",
      "Epoch: 6, Index: 109, Loss: 2.0519\n",
      "Epoch: 6, Index: 110, Loss: 3.9754\n",
      "Epoch: 6, Index: 111, Loss: 2.6788\n",
      "Epoch: 6, Index: 112, Loss: 3.3515\n",
      "Epoch: 6, Index: 113, Loss: 0.0779\n",
      "Epoch: 6, Index: 114, Loss: 4.8844\n",
      "Epoch: 6, Index: 115, Loss: 2.7129\n",
      "Epoch: 6, Index: 116, Loss: 0.2806\n",
      "Epoch: 6, Index: 117, Loss: 0.4750\n",
      "Epoch: 6, Index: 118, Loss: 12.6249\n",
      "Epoch: 6, Index: 119, Loss: 10.2079\n",
      "Epoch: 6, Index: 120, Loss: 1.1942\n",
      "Epoch: 6, Index: 121, Loss: 1.9321\n",
      "Epoch: 6, Index: 122, Loss: 6.7004\n",
      "Epoch: 6, Index: 123, Loss: 1.4272\n",
      "Epoch: 6, Index: 124, Loss: 0.5890\n",
      "Epoch: 6, Index: 125, Loss: 5.3014\n",
      "Epoch: 6, Index: 126, Loss: 1.0623\n",
      "Epoch: 6, Index: 127, Loss: 7.9574\n",
      "Epoch: 6, Index: 128, Loss: 1.7639\n",
      "Epoch: 6, Index: 129, Loss: 1.9644\n",
      "Epoch: 6, Index: 130, Loss: 1.2750\n",
      "Epoch: 6, Index: 131, Loss: 3.0437\n",
      "Epoch: 6, Index: 132, Loss: 1.2297\n",
      "Epoch: 6, Index: 133, Loss: 1.5060\n",
      "Epoch: 6, Index: 134, Loss: 2.3245\n",
      "Epoch: 6, Index: 135, Loss: 8.5929\n",
      "Epoch: 6, Index: 136, Loss: 1.6491\n",
      "Epoch: 6, Index: 137, Loss: 0.4914\n",
      "Epoch: 6, Index: 138, Loss: 1.1124\n",
      "Epoch: 6, Index: 139, Loss: 1.3846\n",
      "Epoch: 6, Index: 140, Loss: 0.4037\n",
      "Epoch: 6, Index: 141, Loss: 0.0934\n",
      "Epoch: 6, Index: 142, Loss: 0.4701\n",
      "Epoch: 6, Index: 143, Loss: 0.8635\n",
      "Epoch: 6, Index: 144, Loss: 3.3109\n",
      "Epoch: 6, Index: 145, Loss: 1.5631\n",
      "Epoch: 6, Index: 146, Loss: 4.5146\n",
      "Epoch: 6, Index: 147, Loss: 1.7541\n",
      "Epoch: 6, Index: 148, Loss: 0.0069\n",
      "Epoch: 6, Index: 149, Loss: 0.4866\n",
      "Epoch: 6, Index: 150, Loss: 1.1025\n",
      "Epoch: 6, Index: 151, Loss: 4.2754\n",
      "Epoch: 6, Index: 152, Loss: 1.8400\n",
      "Epoch: 6, Index: 153, Loss: 1.9575\n",
      "Epoch: 6, Index: 154, Loss: 2.7590\n",
      "Epoch: 6, Index: 155, Loss: 0.0507\n",
      "Epoch: 6, Index: 156, Loss: 0.1113\n",
      "Epoch: 6, Index: 157, Loss: 5.5301\n",
      "Epoch: 6, Index: 158, Loss: 1.4956\n",
      "Epoch: 6, Index: 159, Loss: 1.1315\n",
      "Epoch: 6, Index: 160, Loss: 2.2396\n",
      "Epoch: 6, Index: 161, Loss: 0.9624\n",
      "Epoch: 6, Index: 162, Loss: 8.8725\n",
      "Epoch: 6, Index: 163, Loss: 0.6310\n",
      "Epoch: 6, Index: 164, Loss: 1.6404\n",
      "Epoch: 6, Index: 165, Loss: 0.9374\n",
      "Epoch: 6, Index: 166, Loss: 3.7916\n",
      "Epoch: 6, Index: 167, Loss: 2.1272\n",
      "Epoch: 6, Index: 168, Loss: 0.6812\n",
      "Epoch: 6, Index: 169, Loss: 0.6044\n",
      "Epoch: 6, Index: 170, Loss: 2.0009\n",
      "Epoch: 6, Index: 171, Loss: 1.7886\n",
      "Epoch: 6, Index: 172, Loss: 0.9172\n",
      "Epoch: 6, Index: 173, Loss: 2.9181\n",
      "Epoch: 6, Index: 174, Loss: 4.6403\n",
      "Epoch: 6, Index: 175, Loss: 1.5244\n",
      "Epoch: 6, Index: 176, Loss: 0.4586\n",
      "Epoch: 6, Index: 177, Loss: 0.1385\n",
      "Epoch: 6, Index: 178, Loss: 3.1471\n",
      "Epoch: 6, Index: 179, Loss: 0.4818\n",
      "Epoch: 6, Index: 180, Loss: 2.7223\n",
      "Epoch: 6, Index: 181, Loss: 1.0488\n",
      "Epoch: 6, Index: 182, Loss: 2.5614\n",
      "Epoch: 6, Index: 183, Loss: 0.7271\n",
      "Epoch: 6, Index: 184, Loss: 0.8315\n",
      "Epoch: 6, Index: 185, Loss: 2.8750\n",
      "Epoch: 6, Index: 186, Loss: 0.5701\n",
      "Epoch: 6, Index: 187, Loss: 0.3614\n",
      "Epoch: 6, Index: 188, Loss: 0.8247\n",
      "Epoch: 6, Index: 189, Loss: 2.6877\n",
      "Epoch: 6, Index: 190, Loss: 2.3786\n",
      "Epoch: 6, Index: 191, Loss: 0.4479\n",
      "Epoch: 6, Index: 192, Loss: 3.2749\n",
      "Epoch: 6, Index: 193, Loss: 2.4256\n",
      "Epoch: 6, Index: 194, Loss: 1.0906\n",
      "Epoch: 6, Index: 195, Loss: 2.3323\n",
      "Epoch: 6, Index: 196, Loss: 0.5241\n",
      "Epoch: 6, Index: 197, Loss: 4.5426\n",
      "Epoch: 6, Index: 198, Loss: 4.5548\n",
      "Epoch: 6, Index: 199, Loss: 2.7106\n",
      "Epoch: 6, Index: 200, Loss: 5.7962\n",
      "Epoch: 6, Index: 201, Loss: 1.7985\n",
      "Epoch: 6, Index: 202, Loss: 1.9975\n",
      "Epoch: 6, Index: 203, Loss: 1.0131\n",
      "Epoch: 6, Index: 204, Loss: 3.5245\n",
      "Epoch: 6, Index: 205, Loss: 2.8858\n",
      "Epoch: 6, Index: 206, Loss: 3.4867\n",
      "Epoch: 6, Index: 207, Loss: 0.9254\n",
      "Epoch: 6, Index: 208, Loss: 0.1970\n",
      "Epoch: 6, Index: 209, Loss: 0.8586\n",
      "Epoch: 6, Index: 210, Loss: 1.4700\n",
      "Epoch: 6, Index: 211, Loss: 0.0986\n",
      "Epoch: 6, Index: 212, Loss: 0.3731\n",
      "Epoch: 6, Index: 213, Loss: 2.1949\n",
      "Epoch: 6, Index: 214, Loss: 4.0039\n",
      "Epoch: 6, Index: 215, Loss: 1.7896\n",
      "Epoch: 6, Index: 216, Loss: 2.6005\n",
      "Epoch: 6, Index: 217, Loss: 1.5930\n",
      "Epoch: 6, Index: 218, Loss: 2.9310\n",
      "Epoch: 6, Index: 219, Loss: 3.3810\n",
      "Epoch: 6, Index: 220, Loss: 2.4328\n",
      "Epoch: 6, Index: 221, Loss: 1.1642\n",
      "Epoch: 6, Index: 222, Loss: 0.4569\n",
      "Epoch: 6, Index: 223, Loss: 2.8283\n",
      "Epoch: 6, Index: 224, Loss: 5.9837\n",
      "Epoch: 6, Index: 225, Loss: 0.5950\n",
      "Epoch: 6, Index: 226, Loss: 0.7733\n",
      "Epoch: 6, Index: 227, Loss: 0.0368\n",
      "Epoch: 6, Index: 228, Loss: 1.2352\n",
      "Epoch: 6, Index: 229, Loss: 1.3015\n",
      "Epoch: 6, Index: 230, Loss: 6.2300\n",
      "Epoch: 6, Index: 231, Loss: 0.6345\n",
      "Epoch: 6, Index: 232, Loss: 2.3170\n",
      "Epoch: 6, Index: 233, Loss: 4.5663\n",
      "Epoch: 6, Index: 234, Loss: 0.6541\n",
      "Epoch: 6, Index: 235, Loss: 0.7508\n",
      "Epoch: 6, Index: 236, Loss: 1.6296\n",
      "Epoch: 6, Index: 237, Loss: 0.1176\n",
      "Epoch: 6, Index: 238, Loss: 0.9833\n",
      "Epoch: 6, Index: 239, Loss: 1.2745\n",
      "Epoch: 6, Index: 240, Loss: 0.2493\n",
      "Epoch: 6, Index: 241, Loss: 0.3558\n",
      "Epoch: 6, Index: 242, Loss: 0.5392\n",
      "Epoch: 6, Index: 243, Loss: 2.2303\n",
      "Epoch: 6, Index: 244, Loss: 1.3669\n",
      "Epoch: 6, Index: 245, Loss: 1.0564\n",
      "Epoch: 6, Index: 246, Loss: 0.0613\n",
      "Epoch: 6, Index: 247, Loss: 0.4806\n",
      "Epoch: 6, Index: 248, Loss: 0.0159\n",
      "Epoch: 6, Index: 249, Loss: 1.9360\n",
      "Epoch: 6, Index: 250, Loss: 0.8681\n",
      "Epoch: 6, Index: 251, Loss: 0.3158\n",
      "Epoch: 6, Index: 252, Loss: 1.3384\n",
      "Epoch: 6, Index: 253, Loss: 1.8595\n",
      "Epoch: 6, Index: 254, Loss: 0.6133\n",
      "Epoch: 6, Index: 255, Loss: 1.8829\n",
      "Epoch: 6, Index: 256, Loss: 0.5047\n",
      "Epoch: 6, Index: 257, Loss: 1.5682\n",
      "Epoch: 6, Index: 258, Loss: 0.6972\n",
      "Epoch: 6, Index: 259, Loss: 0.0347\n",
      "Epoch: 6, Index: 260, Loss: 1.5020\n",
      "Epoch: 6, Index: 261, Loss: 0.6542\n",
      "Epoch: 6, Index: 262, Loss: 0.5493\n",
      "Epoch: 6, Index: 263, Loss: 3.5749\n",
      "Epoch: 6, Index: 264, Loss: 1.3882\n",
      "Epoch: 6, Index: 265, Loss: 0.4237\n",
      "Epoch: 6, Index: 266, Loss: 1.1021\n",
      "Epoch: 6, Index: 267, Loss: 0.6085\n",
      "Epoch: 6, Index: 268, Loss: 1.5960\n",
      "Epoch: 6, Index: 269, Loss: 0.9953\n",
      "Epoch: 6, Index: 270, Loss: 2.2869\n",
      "Epoch: 6, Index: 271, Loss: 2.1179\n",
      "Epoch: 6, Index: 272, Loss: 4.2009\n",
      "Epoch: 6, Index: 273, Loss: 2.9233\n",
      "Epoch: 6, Index: 274, Loss: 1.2536\n",
      "Epoch: 6, Index: 275, Loss: 0.6219\n",
      "Epoch: 6, Index: 276, Loss: 1.4202\n",
      "Epoch: 6, Index: 277, Loss: 2.2245\n",
      "Epoch: 6, Index: 278, Loss: 0.4133\n",
      "Epoch: 6, Index: 279, Loss: 0.6471\n",
      "Epoch: 6, Index: 280, Loss: 2.0923\n",
      "Epoch: 6, Index: 281, Loss: 2.7295\n",
      "Epoch: 6, Index: 282, Loss: 1.8475\n",
      "Epoch: 6, Index: 283, Loss: 2.5787\n",
      "Epoch: 6, Index: 284, Loss: 2.4748\n",
      "Epoch: 6, Index: 285, Loss: 2.4129\n",
      "Epoch: 6, Index: 286, Loss: 5.3674\n",
      "Epoch: 6, Index: 287, Loss: 1.9279\n",
      "Epoch: 6, Index: 288, Loss: 1.6155\n",
      "Epoch: 6, Index: 289, Loss: 0.5797\n",
      "Epoch: 6, Index: 290, Loss: 7.9899\n",
      "Epoch: 6, Index: 291, Loss: 0.2530\n",
      "Epoch: 6, Index: 292, Loss: 2.2105\n",
      "Epoch: 6, Index: 293, Loss: 1.4363\n",
      "Epoch: 6, Index: 294, Loss: 1.0072\n",
      "Epoch: 6, Index: 295, Loss: 2.3594\n",
      "Epoch: 6, Index: 296, Loss: 4.2901\n",
      "Epoch: 6, Index: 297, Loss: 0.7322\n",
      "Epoch: 6, Index: 298, Loss: 2.9413\n",
      "Epoch: 6, Index: 299, Loss: 0.6774\n",
      "Epoch: 6, Index: 300, Loss: 1.3897\n",
      "Epoch: 6, Index: 301, Loss: 1.8218\n",
      "Epoch: 6, Index: 302, Loss: 3.3063\n",
      "Epoch: 6, Index: 303, Loss: 0.0942\n",
      "Epoch: 6, Index: 304, Loss: 6.4831\n",
      "Epoch: 6, Index: 305, Loss: 1.7784\n",
      "Epoch: 6, Index: 306, Loss: 1.9180\n",
      "Epoch: 6, Index: 307, Loss: 0.9420\n",
      "Epoch: 6, Index: 308, Loss: 2.4429\n",
      "Epoch: 6, Index: 309, Loss: 3.1567\n",
      "Epoch: 6, Index: 310, Loss: 0.0756\n",
      "Epoch: 6, Index: 311, Loss: 2.2375\n",
      "Epoch: 6, Index: 312, Loss: 3.0253\n",
      "Epoch: 6, Index: 313, Loss: 5.3450\n",
      "Epoch: 6, Index: 314, Loss: 1.6624\n",
      "Epoch: 6, Index: 315, Loss: 1.8617\n",
      "Epoch: 6, Index: 316, Loss: 1.5588\n",
      "Epoch: 6, Index: 317, Loss: 0.9441\n",
      "Epoch: 6, Index: 318, Loss: 0.7536\n",
      "Epoch: 6, Index: 319, Loss: 5.9807\n",
      "Epoch: 6, Index: 320, Loss: 0.0919\n",
      "Epoch: 6, Index: 321, Loss: 0.7379\n",
      "Epoch: 6, Index: 322, Loss: 0.2239\n",
      "Epoch: 6, Index: 323, Loss: 0.5625\n",
      "Epoch: 6, Index: 324, Loss: 3.3131\n",
      "Epoch: 6, Index: 325, Loss: 1.5290\n",
      "Epoch: 6, Index: 326, Loss: 2.9255\n",
      "Epoch: 6, Index: 327, Loss: 2.4418\n",
      "Epoch: 6, Index: 328, Loss: 0.3644\n",
      "Epoch: 6, Index: 329, Loss: 1.0647\n",
      "Epoch: 6, Index: 330, Loss: 3.2670\n",
      "Epoch: 6, Index: 331, Loss: 0.8704\n",
      "Epoch: 6, Index: 332, Loss: 0.0089\n",
      "Epoch: 6, Index: 333, Loss: 1.1494\n",
      "Epoch: 6, Index: 334, Loss: 0.4082\n",
      "Epoch: 6, Index: 335, Loss: 0.6197\n",
      "Epoch: 6, Index: 336, Loss: 3.3738\n",
      "Epoch: 6, Index: 337, Loss: 1.1697\n",
      "Epoch: 6, Index: 338, Loss: 3.4053\n",
      "Epoch: 6, Index: 339, Loss: 2.2460\n",
      "Epoch: 6, Index: 340, Loss: 1.9995\n",
      "Epoch: 6, Index: 341, Loss: 2.3972\n",
      "Epoch: 6, Index: 342, Loss: 0.3249\n",
      "Epoch: 6, Index: 343, Loss: 1.5886\n",
      "Epoch: 6, Index: 344, Loss: 1.4801\n",
      "Epoch: 6, Index: 345, Loss: 1.0606\n",
      "Epoch: 6, Index: 346, Loss: 1.5121\n",
      "Epoch: 6, Index: 347, Loss: 2.4840\n",
      "Epoch: 6, Index: 348, Loss: 2.0902\n",
      "Epoch: 6, Index: 349, Loss: 1.0046\n",
      "Epoch: 6, Index: 350, Loss: 1.9164\n",
      "Epoch: 6, Index: 351, Loss: 0.1794\n",
      "Epoch: 6, Index: 352, Loss: 0.0932\n",
      "Epoch: 6, Index: 353, Loss: 1.1624\n",
      "Epoch: 6, Index: 354, Loss: 2.0958\n",
      "Epoch: 6, Index: 355, Loss: 1.6296\n",
      "Epoch: 6, Index: 356, Loss: 0.7988\n",
      "Epoch: 6, Index: 357, Loss: 0.3197\n",
      "Epoch: 6, Index: 358, Loss: 0.2631\n",
      "Epoch: 6, Index: 359, Loss: 1.9240\n",
      "Epoch: 6, Index: 360, Loss: 1.2403\n",
      "Epoch: 6, Index: 361, Loss: 0.5055\n",
      "Epoch: 6, Index: 362, Loss: 4.4320\n",
      "Epoch: 6, Index: 363, Loss: 2.9066\n",
      "Epoch: 6, Index: 364, Loss: 3.4394\n",
      "Epoch: 6, Index: 365, Loss: 3.4372\n",
      "Epoch: 6, Index: 366, Loss: 6.3087\n",
      "Epoch: 6, Index: 367, Loss: 0.5385\n",
      "Epoch: 6, Index: 368, Loss: 0.7684\n",
      "Epoch: 6, Index: 369, Loss: 2.0117\n",
      "Epoch: 6, Index: 370, Loss: 2.2445\n",
      "Epoch: 6, Index: 371, Loss: 2.1799\n",
      "Epoch: 6, Index: 372, Loss: 2.5989\n",
      "Epoch: 6, Index: 373, Loss: 2.0217\n",
      "Epoch: 6, Index: 374, Loss: 0.2169\n",
      "Epoch: 6, Index: 375, Loss: 2.9812\n",
      "Epoch: 6, Index: 376, Loss: 5.4099\n",
      "Epoch: 6, Index: 377, Loss: 0.5112\n",
      "Epoch: 6, Index: 378, Loss: 0.2438\n",
      "Epoch: 6, Index: 379, Loss: 0.2793\n",
      "Epoch: 6, Index: 380, Loss: 0.2087\n",
      "Epoch: 6, Index: 381, Loss: 7.4485\n",
      "Epoch: 6, Index: 382, Loss: 2.5028\n",
      "Epoch: 6, Index: 383, Loss: 0.9493\n",
      "Epoch: 6, Index: 384, Loss: 0.0659\n",
      "Epoch: 6, Index: 385, Loss: 0.1259\n",
      "Epoch: 6, Index: 386, Loss: 0.0813\n",
      "Epoch: 6, Index: 387, Loss: 0.6068\n",
      "Epoch: 6, Index: 388, Loss: 0.3529\n",
      "Epoch: 6, Index: 389, Loss: 2.2768\n",
      "Epoch: 6, Index: 390, Loss: 2.4410\n",
      "Epoch: 6, Index: 391, Loss: 0.1103\n",
      "Epoch: 6, Index: 392, Loss: 0.6557\n",
      "Epoch: 6, Index: 393, Loss: 0.1599\n",
      "Epoch: 6, Index: 394, Loss: 1.5932\n",
      "Epoch: 6, Index: 395, Loss: 0.4287\n",
      "Epoch: 6, Index: 396, Loss: 1.8730\n",
      "Epoch: 6, Index: 397, Loss: 1.0953\n",
      "Epoch: 6, Index: 398, Loss: 2.5735\n",
      "Epoch: 6, Index: 399, Loss: 0.1723\n",
      "Epoch: 6, Index: 400, Loss: 5.1198\n",
      "Epoch: 6, Index: 401, Loss: 0.5207\n",
      "Epoch: 6, Index: 402, Loss: 1.5264\n",
      "Epoch: 6, Index: 403, Loss: 1.3647\n",
      "Epoch: 6, Index: 404, Loss: 0.0577\n",
      "Epoch: 6, Index: 405, Loss: 4.5526\n",
      "Epoch: 6, Index: 406, Loss: 2.4341\n",
      "Epoch: 6, Index: 407, Loss: 1.9820\n",
      "Epoch: 6, Index: 408, Loss: 0.5904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33883fe6df54cc1bf89a7c573e3841c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Index: 0, Loss: 0.3241\n",
      "Epoch: 7, Index: 1, Loss: 1.6480\n",
      "Epoch: 7, Index: 2, Loss: 0.1170\n",
      "Epoch: 7, Index: 3, Loss: 0.1236\n",
      "Epoch: 7, Index: 4, Loss: 2.0212\n",
      "Epoch: 7, Index: 5, Loss: 1.9266\n",
      "Epoch: 7, Index: 6, Loss: 0.6035\n",
      "Epoch: 7, Index: 7, Loss: 3.4820\n",
      "Epoch: 7, Index: 8, Loss: 3.3770\n",
      "Epoch: 7, Index: 9, Loss: 0.3786\n",
      "Epoch: 7, Index: 10, Loss: 4.1548\n",
      "Epoch: 7, Index: 11, Loss: 4.0685\n",
      "Epoch: 7, Index: 12, Loss: 0.0121\n",
      "Epoch: 7, Index: 13, Loss: 2.6039\n",
      "Epoch: 7, Index: 14, Loss: 1.3955\n",
      "Epoch: 7, Index: 15, Loss: 0.6679\n",
      "Epoch: 7, Index: 16, Loss: 0.4723\n",
      "Epoch: 7, Index: 17, Loss: 3.6024\n",
      "Epoch: 7, Index: 18, Loss: 4.0253\n",
      "Epoch: 7, Index: 19, Loss: 1.3415\n",
      "Epoch: 7, Index: 20, Loss: 0.8658\n",
      "Epoch: 7, Index: 21, Loss: 1.4087\n",
      "Epoch: 7, Index: 22, Loss: 6.0517\n",
      "Epoch: 7, Index: 23, Loss: 1.4934\n",
      "Epoch: 7, Index: 24, Loss: 1.8995\n",
      "Epoch: 7, Index: 25, Loss: 2.0457\n",
      "Epoch: 7, Index: 26, Loss: 1.3401\n",
      "Epoch: 7, Index: 27, Loss: 0.4244\n",
      "Epoch: 7, Index: 28, Loss: 4.7031\n",
      "Epoch: 7, Index: 29, Loss: 0.7311\n",
      "Epoch: 7, Index: 30, Loss: 1.8254\n",
      "Epoch: 7, Index: 31, Loss: 0.2014\n",
      "Epoch: 7, Index: 32, Loss: 0.9381\n",
      "Epoch: 7, Index: 33, Loss: 0.8216\n",
      "Epoch: 7, Index: 34, Loss: 4.4396\n",
      "Epoch: 7, Index: 35, Loss: 8.1597\n",
      "Epoch: 7, Index: 36, Loss: 3.0566\n",
      "Epoch: 7, Index: 37, Loss: 3.4580\n",
      "Epoch: 7, Index: 38, Loss: 1.2772\n",
      "Epoch: 7, Index: 39, Loss: 2.9031\n",
      "Epoch: 7, Index: 40, Loss: 0.6075\n",
      "Epoch: 7, Index: 41, Loss: 0.2658\n",
      "Epoch: 7, Index: 42, Loss: 2.3209\n",
      "Epoch: 7, Index: 43, Loss: 2.8215\n",
      "Epoch: 7, Index: 44, Loss: 0.7678\n",
      "Epoch: 7, Index: 45, Loss: 0.5846\n",
      "Epoch: 7, Index: 46, Loss: 0.9243\n",
      "Epoch: 7, Index: 47, Loss: 0.9626\n",
      "Epoch: 7, Index: 48, Loss: 7.3950\n",
      "Epoch: 7, Index: 49, Loss: 3.4176\n",
      "Epoch: 7, Index: 50, Loss: 1.7852\n",
      "Epoch: 7, Index: 51, Loss: 1.9015\n",
      "Epoch: 7, Index: 52, Loss: 0.1706\n",
      "Epoch: 7, Index: 53, Loss: 2.5422\n",
      "Epoch: 7, Index: 54, Loss: 0.8795\n",
      "Epoch: 7, Index: 55, Loss: 1.1389\n",
      "Epoch: 7, Index: 56, Loss: 1.4978\n",
      "Epoch: 7, Index: 57, Loss: 2.1110\n",
      "Epoch: 7, Index: 58, Loss: 1.7682\n",
      "Epoch: 7, Index: 59, Loss: 0.1480\n",
      "Epoch: 7, Index: 60, Loss: 1.1460\n",
      "Epoch: 7, Index: 61, Loss: 3.4826\n",
      "Epoch: 7, Index: 62, Loss: 0.3211\n",
      "Epoch: 7, Index: 63, Loss: 1.0051\n",
      "Epoch: 7, Index: 64, Loss: 2.2201\n",
      "Epoch: 7, Index: 65, Loss: 1.0858\n",
      "Epoch: 7, Index: 66, Loss: 0.1958\n",
      "Epoch: 7, Index: 67, Loss: 0.9341\n",
      "Epoch: 7, Index: 68, Loss: 5.6064\n",
      "Epoch: 7, Index: 69, Loss: 1.0050\n",
      "Epoch: 7, Index: 70, Loss: 0.3032\n",
      "Epoch: 7, Index: 71, Loss: 3.3308\n",
      "Epoch: 7, Index: 72, Loss: 0.3698\n",
      "Epoch: 7, Index: 73, Loss: 1.2227\n",
      "Epoch: 7, Index: 74, Loss: 0.0309\n",
      "Epoch: 7, Index: 75, Loss: 2.1946\n",
      "Epoch: 7, Index: 76, Loss: 0.0885\n",
      "Epoch: 7, Index: 77, Loss: 1.7405\n",
      "Epoch: 7, Index: 78, Loss: 1.3846\n",
      "Epoch: 7, Index: 79, Loss: 0.5770\n",
      "Epoch: 7, Index: 80, Loss: 1.4586\n",
      "Epoch: 7, Index: 81, Loss: 0.7471\n",
      "Epoch: 7, Index: 82, Loss: 0.0049\n",
      "Epoch: 7, Index: 83, Loss: 0.2254\n",
      "Epoch: 7, Index: 84, Loss: 4.5617\n",
      "Epoch: 7, Index: 85, Loss: 0.5447\n",
      "Epoch: 7, Index: 86, Loss: 0.8688\n",
      "Epoch: 7, Index: 87, Loss: 3.4892\n",
      "Epoch: 7, Index: 88, Loss: 0.0018\n",
      "Epoch: 7, Index: 89, Loss: 0.4132\n",
      "Epoch: 7, Index: 90, Loss: 0.5271\n",
      "Epoch: 7, Index: 91, Loss: 0.1884\n",
      "Epoch: 7, Index: 92, Loss: 2.0616\n",
      "Epoch: 7, Index: 93, Loss: 1.0856\n",
      "Epoch: 7, Index: 94, Loss: 0.5646\n",
      "Epoch: 7, Index: 95, Loss: 0.9597\n",
      "Epoch: 7, Index: 96, Loss: 5.5935\n",
      "Epoch: 7, Index: 97, Loss: 0.0454\n",
      "Epoch: 7, Index: 98, Loss: 0.2144\n",
      "Epoch: 7, Index: 99, Loss: 0.3526\n",
      "Epoch: 7, Index: 100, Loss: 0.5623\n",
      "Epoch: 7, Index: 101, Loss: 1.0148\n",
      "Epoch: 7, Index: 102, Loss: 5.9357\n",
      "Epoch: 7, Index: 103, Loss: 1.5309\n",
      "Epoch: 7, Index: 104, Loss: 4.3068\n",
      "Epoch: 7, Index: 105, Loss: 0.0511\n",
      "Epoch: 7, Index: 106, Loss: 3.9530\n",
      "Epoch: 7, Index: 107, Loss: 1.5643\n",
      "Epoch: 7, Index: 108, Loss: 4.1210\n",
      "Epoch: 7, Index: 109, Loss: 1.0410\n",
      "Epoch: 7, Index: 110, Loss: 0.5572\n",
      "Epoch: 7, Index: 111, Loss: 1.1538\n",
      "Epoch: 7, Index: 112, Loss: 1.2562\n",
      "Epoch: 7, Index: 113, Loss: 0.4965\n",
      "Epoch: 7, Index: 114, Loss: 0.9904\n",
      "Epoch: 7, Index: 115, Loss: 1.1772\n",
      "Epoch: 7, Index: 116, Loss: 4.3932\n",
      "Epoch: 7, Index: 117, Loss: 0.6181\n",
      "Epoch: 7, Index: 118, Loss: 0.4597\n",
      "Epoch: 7, Index: 119, Loss: 0.0251\n",
      "Epoch: 7, Index: 120, Loss: 0.7530\n",
      "Epoch: 7, Index: 121, Loss: 4.3848\n",
      "Epoch: 7, Index: 122, Loss: 2.6530\n",
      "Epoch: 7, Index: 123, Loss: 0.9202\n",
      "Epoch: 7, Index: 124, Loss: 0.9157\n",
      "Epoch: 7, Index: 125, Loss: 0.3645\n",
      "Epoch: 7, Index: 126, Loss: 2.8730\n",
      "Epoch: 7, Index: 127, Loss: 1.1628\n",
      "Epoch: 7, Index: 128, Loss: 1.7292\n",
      "Epoch: 7, Index: 129, Loss: 0.5209\n",
      "Epoch: 7, Index: 130, Loss: 0.2156\n",
      "Epoch: 7, Index: 131, Loss: 0.9334\n",
      "Epoch: 7, Index: 132, Loss: 1.7704\n",
      "Epoch: 7, Index: 133, Loss: 1.1339\n",
      "Epoch: 7, Index: 134, Loss: 0.4334\n",
      "Epoch: 7, Index: 135, Loss: 0.7637\n",
      "Epoch: 7, Index: 136, Loss: 7.0515\n",
      "Epoch: 7, Index: 137, Loss: 0.6100\n",
      "Epoch: 7, Index: 138, Loss: 0.3033\n",
      "Epoch: 7, Index: 139, Loss: 2.7432\n",
      "Epoch: 7, Index: 140, Loss: 1.1967\n",
      "Epoch: 7, Index: 141, Loss: 0.3291\n",
      "Epoch: 7, Index: 142, Loss: 0.3196\n",
      "Epoch: 7, Index: 143, Loss: 3.6387\n",
      "Epoch: 7, Index: 144, Loss: 0.7811\n",
      "Epoch: 7, Index: 145, Loss: 0.8241\n",
      "Epoch: 7, Index: 146, Loss: 0.0431\n",
      "Epoch: 7, Index: 147, Loss: 0.5182\n",
      "Epoch: 7, Index: 148, Loss: 2.7259\n",
      "Epoch: 7, Index: 149, Loss: 0.0704\n",
      "Epoch: 7, Index: 150, Loss: 0.0183\n",
      "Epoch: 7, Index: 151, Loss: 3.8714\n",
      "Epoch: 7, Index: 152, Loss: 0.3046\n",
      "Epoch: 7, Index: 153, Loss: 2.2535\n",
      "Epoch: 7, Index: 154, Loss: 3.4677\n",
      "Epoch: 7, Index: 155, Loss: 11.5806\n",
      "Epoch: 7, Index: 156, Loss: 0.4957\n",
      "Epoch: 7, Index: 157, Loss: 1.3278\n",
      "Epoch: 7, Index: 158, Loss: 0.2338\n",
      "Epoch: 7, Index: 159, Loss: 0.8949\n",
      "Epoch: 7, Index: 160, Loss: 4.0361\n",
      "Epoch: 7, Index: 161, Loss: 2.8687\n",
      "Epoch: 7, Index: 162, Loss: 0.4591\n",
      "Epoch: 7, Index: 163, Loss: 3.2263\n",
      "Epoch: 7, Index: 164, Loss: 1.0034\n",
      "Epoch: 7, Index: 165, Loss: 1.2646\n",
      "Epoch: 7, Index: 166, Loss: 3.5862\n",
      "Epoch: 7, Index: 167, Loss: 1.1781\n",
      "Epoch: 7, Index: 168, Loss: 8.6375\n",
      "Epoch: 7, Index: 169, Loss: 6.3701\n",
      "Epoch: 7, Index: 170, Loss: 1.8483\n",
      "Epoch: 7, Index: 171, Loss: 0.8215\n",
      "Epoch: 7, Index: 172, Loss: 0.1858\n",
      "Epoch: 7, Index: 173, Loss: 1.1305\n",
      "Epoch: 7, Index: 174, Loss: 0.2717\n",
      "Epoch: 7, Index: 175, Loss: 12.2879\n",
      "Epoch: 7, Index: 176, Loss: 3.6860\n",
      "Epoch: 7, Index: 177, Loss: 0.7856\n",
      "Epoch: 7, Index: 178, Loss: 0.4454\n",
      "Epoch: 7, Index: 179, Loss: 1.3902\n",
      "Epoch: 7, Index: 180, Loss: 0.1544\n",
      "Epoch: 7, Index: 181, Loss: 1.7115\n",
      "Epoch: 7, Index: 182, Loss: 1.7993\n",
      "Epoch: 7, Index: 183, Loss: 0.7801\n",
      "Epoch: 7, Index: 184, Loss: 2.0379\n",
      "Epoch: 7, Index: 185, Loss: 3.0477\n",
      "Epoch: 7, Index: 186, Loss: 0.3013\n",
      "Epoch: 7, Index: 187, Loss: 0.2677\n",
      "Epoch: 7, Index: 188, Loss: 0.3977\n",
      "Epoch: 7, Index: 189, Loss: 1.0348\n",
      "Epoch: 7, Index: 190, Loss: 0.6466\n",
      "Epoch: 7, Index: 191, Loss: 2.0509\n",
      "Epoch: 7, Index: 192, Loss: 0.3367\n",
      "Epoch: 7, Index: 193, Loss: 2.6745\n",
      "Epoch: 7, Index: 194, Loss: 8.1310\n",
      "Epoch: 7, Index: 195, Loss: 0.1054\n",
      "Epoch: 7, Index: 196, Loss: 2.6428\n",
      "Epoch: 7, Index: 197, Loss: 1.0275\n",
      "Epoch: 7, Index: 198, Loss: 1.9832\n",
      "Epoch: 7, Index: 199, Loss: 0.6269\n",
      "Epoch: 7, Index: 200, Loss: 1.5321\n",
      "Epoch: 7, Index: 201, Loss: 1.9545\n",
      "Epoch: 7, Index: 202, Loss: 0.9245\n",
      "Epoch: 7, Index: 203, Loss: 2.1005\n",
      "Epoch: 7, Index: 204, Loss: 0.4022\n",
      "Epoch: 7, Index: 205, Loss: 0.8549\n",
      "Epoch: 7, Index: 206, Loss: 2.5306\n",
      "Epoch: 7, Index: 207, Loss: 0.5474\n",
      "Epoch: 7, Index: 208, Loss: 3.4721\n",
      "Epoch: 7, Index: 209, Loss: 1.8391\n",
      "Epoch: 7, Index: 210, Loss: 2.5235\n",
      "Epoch: 7, Index: 211, Loss: 1.3822\n",
      "Epoch: 7, Index: 212, Loss: 0.7814\n",
      "Epoch: 7, Index: 213, Loss: 2.0781\n",
      "Epoch: 7, Index: 214, Loss: 8.1950\n",
      "Epoch: 7, Index: 215, Loss: 5.8443\n",
      "Epoch: 7, Index: 216, Loss: 0.2276\n",
      "Epoch: 7, Index: 217, Loss: 2.3365\n",
      "Epoch: 7, Index: 218, Loss: 2.1855\n",
      "Epoch: 7, Index: 219, Loss: 2.0005\n",
      "Epoch: 7, Index: 220, Loss: 6.5693\n",
      "Epoch: 7, Index: 221, Loss: 2.4110\n",
      "Epoch: 7, Index: 222, Loss: 1.9521\n",
      "Epoch: 7, Index: 223, Loss: 1.2853\n",
      "Epoch: 7, Index: 224, Loss: 1.7101\n",
      "Epoch: 7, Index: 225, Loss: 1.8148\n",
      "Epoch: 7, Index: 226, Loss: 1.1071\n",
      "Epoch: 7, Index: 227, Loss: 1.5496\n",
      "Epoch: 7, Index: 228, Loss: 1.2150\n",
      "Epoch: 7, Index: 229, Loss: 2.9186\n",
      "Epoch: 7, Index: 230, Loss: 0.9256\n",
      "Epoch: 7, Index: 231, Loss: 2.4626\n",
      "Epoch: 7, Index: 232, Loss: 0.3563\n",
      "Epoch: 7, Index: 233, Loss: 1.6309\n",
      "Epoch: 7, Index: 234, Loss: 0.5305\n",
      "Epoch: 7, Index: 235, Loss: 0.0871\n",
      "Epoch: 7, Index: 236, Loss: 0.7804\n",
      "Epoch: 7, Index: 237, Loss: 0.3433\n",
      "Epoch: 7, Index: 238, Loss: 7.8105\n",
      "Epoch: 7, Index: 239, Loss: 1.8982\n",
      "Epoch: 7, Index: 240, Loss: 0.7079\n",
      "Epoch: 7, Index: 241, Loss: 2.0942\n",
      "Epoch: 7, Index: 242, Loss: 0.5521\n",
      "Epoch: 7, Index: 243, Loss: 1.3034\n",
      "Epoch: 7, Index: 244, Loss: 1.7976\n",
      "Epoch: 7, Index: 245, Loss: 4.2277\n",
      "Epoch: 7, Index: 246, Loss: 1.6074\n",
      "Epoch: 7, Index: 247, Loss: 0.3935\n",
      "Epoch: 7, Index: 248, Loss: 0.8533\n",
      "Epoch: 7, Index: 249, Loss: 0.0061\n",
      "Epoch: 7, Index: 250, Loss: 8.2092\n",
      "Epoch: 7, Index: 251, Loss: 1.6596\n",
      "Epoch: 7, Index: 252, Loss: 0.4578\n",
      "Epoch: 7, Index: 253, Loss: 0.8730\n",
      "Epoch: 7, Index: 254, Loss: 0.8350\n",
      "Epoch: 7, Index: 255, Loss: 1.4060\n",
      "Epoch: 7, Index: 256, Loss: 0.8578\n",
      "Epoch: 7, Index: 257, Loss: 1.0452\n",
      "Epoch: 7, Index: 258, Loss: 1.0892\n",
      "Epoch: 7, Index: 259, Loss: 2.0017\n",
      "Epoch: 7, Index: 260, Loss: 0.0860\n",
      "Epoch: 7, Index: 261, Loss: 0.4673\n",
      "Epoch: 7, Index: 262, Loss: 1.4237\n",
      "Epoch: 7, Index: 263, Loss: 1.9150\n",
      "Epoch: 7, Index: 264, Loss: 1.2365\n",
      "Epoch: 7, Index: 265, Loss: 0.7038\n",
      "Epoch: 7, Index: 266, Loss: 1.6821\n",
      "Epoch: 7, Index: 267, Loss: 2.9856\n",
      "Epoch: 7, Index: 268, Loss: 1.5558\n",
      "Epoch: 7, Index: 269, Loss: 0.1617\n",
      "Epoch: 7, Index: 270, Loss: 0.4152\n",
      "Epoch: 7, Index: 271, Loss: 1.8453\n",
      "Epoch: 7, Index: 272, Loss: 4.0384\n",
      "Epoch: 7, Index: 273, Loss: 0.6319\n",
      "Epoch: 7, Index: 274, Loss: 0.0768\n",
      "Epoch: 7, Index: 275, Loss: 2.9568\n",
      "Epoch: 7, Index: 276, Loss: 6.8516\n",
      "Epoch: 7, Index: 277, Loss: 0.0549\n",
      "Epoch: 7, Index: 278, Loss: 0.1626\n",
      "Epoch: 7, Index: 279, Loss: 0.0293\n",
      "Epoch: 7, Index: 280, Loss: 0.7690\n",
      "Epoch: 7, Index: 281, Loss: 2.8286\n",
      "Epoch: 7, Index: 282, Loss: 2.0115\n",
      "Epoch: 7, Index: 283, Loss: 0.9345\n",
      "Epoch: 7, Index: 284, Loss: 3.9232\n",
      "Epoch: 7, Index: 285, Loss: 0.0164\n",
      "Epoch: 7, Index: 286, Loss: 2.7912\n",
      "Epoch: 7, Index: 287, Loss: 0.7184\n",
      "Epoch: 7, Index: 288, Loss: 0.5786\n",
      "Epoch: 7, Index: 289, Loss: 2.0571\n",
      "Epoch: 7, Index: 290, Loss: 0.1975\n",
      "Epoch: 7, Index: 291, Loss: 3.9623\n",
      "Epoch: 7, Index: 292, Loss: 0.1053\n",
      "Epoch: 7, Index: 293, Loss: 0.0591\n",
      "Epoch: 7, Index: 294, Loss: 1.2217\n",
      "Epoch: 7, Index: 295, Loss: 2.0734\n",
      "Epoch: 7, Index: 296, Loss: 0.6417\n",
      "Epoch: 7, Index: 297, Loss: 1.3851\n",
      "Epoch: 7, Index: 298, Loss: 3.7357\n",
      "Epoch: 7, Index: 299, Loss: 0.7724\n",
      "Epoch: 7, Index: 300, Loss: 0.1502\n",
      "Epoch: 7, Index: 301, Loss: 1.9016\n",
      "Epoch: 7, Index: 302, Loss: 0.6108\n",
      "Epoch: 7, Index: 303, Loss: 0.3425\n",
      "Epoch: 7, Index: 304, Loss: 0.0033\n",
      "Epoch: 7, Index: 305, Loss: 2.2063\n",
      "Epoch: 7, Index: 306, Loss: 5.6948\n",
      "Epoch: 7, Index: 307, Loss: 1.5040\n",
      "Epoch: 7, Index: 308, Loss: 1.4335\n",
      "Epoch: 7, Index: 309, Loss: 3.6777\n",
      "Epoch: 7, Index: 310, Loss: 1.0737\n",
      "Epoch: 7, Index: 311, Loss: 4.0160\n",
      "Epoch: 7, Index: 312, Loss: 1.9722\n",
      "Epoch: 7, Index: 313, Loss: 1.5359\n",
      "Epoch: 7, Index: 314, Loss: 1.6666\n",
      "Epoch: 7, Index: 315, Loss: 1.3967\n",
      "Epoch: 7, Index: 316, Loss: 16.6214\n",
      "Epoch: 7, Index: 317, Loss: 7.0432\n",
      "Epoch: 7, Index: 318, Loss: 0.5576\n",
      "Epoch: 7, Index: 319, Loss: 0.3029\n",
      "Epoch: 7, Index: 320, Loss: 5.0400\n",
      "Epoch: 7, Index: 321, Loss: 4.6354\n",
      "Epoch: 7, Index: 322, Loss: 1.8921\n",
      "Epoch: 7, Index: 323, Loss: 1.9050\n",
      "Epoch: 7, Index: 324, Loss: 0.9270\n",
      "Epoch: 7, Index: 325, Loss: 1.7105\n",
      "Epoch: 7, Index: 326, Loss: 0.5268\n",
      "Epoch: 7, Index: 327, Loss: 0.7700\n",
      "Epoch: 7, Index: 328, Loss: 2.8570\n",
      "Epoch: 7, Index: 329, Loss: 1.2659\n",
      "Epoch: 7, Index: 330, Loss: 5.6483\n",
      "Epoch: 7, Index: 331, Loss: 0.0795\n",
      "Epoch: 7, Index: 332, Loss: 2.0619\n",
      "Epoch: 7, Index: 333, Loss: 1.2614\n",
      "Epoch: 7, Index: 334, Loss: 2.5704\n",
      "Epoch: 7, Index: 335, Loss: 0.2527\n",
      "Epoch: 7, Index: 336, Loss: 0.9824\n",
      "Epoch: 7, Index: 337, Loss: 3.5786\n",
      "Epoch: 7, Index: 338, Loss: 1.0878\n",
      "Epoch: 7, Index: 339, Loss: 2.7010\n",
      "Epoch: 7, Index: 340, Loss: 2.6866\n",
      "Epoch: 7, Index: 341, Loss: 0.9835\n",
      "Epoch: 7, Index: 342, Loss: 0.4791\n",
      "Epoch: 7, Index: 343, Loss: 2.1578\n",
      "Epoch: 7, Index: 344, Loss: 0.3351\n",
      "Epoch: 7, Index: 345, Loss: 1.8247\n",
      "Epoch: 7, Index: 346, Loss: 0.6119\n",
      "Epoch: 7, Index: 347, Loss: 0.6762\n",
      "Epoch: 7, Index: 348, Loss: 1.4467\n",
      "Epoch: 7, Index: 349, Loss: 1.7052\n",
      "Epoch: 7, Index: 350, Loss: 0.8546\n",
      "Epoch: 7, Index: 351, Loss: 1.6837\n",
      "Epoch: 7, Index: 352, Loss: 1.2831\n",
      "Epoch: 7, Index: 353, Loss: 0.6781\n",
      "Epoch: 7, Index: 354, Loss: 1.2002\n",
      "Epoch: 7, Index: 355, Loss: 3.6150\n",
      "Epoch: 7, Index: 356, Loss: 2.8045\n",
      "Epoch: 7, Index: 357, Loss: 2.7335\n",
      "Epoch: 7, Index: 358, Loss: 0.2612\n",
      "Epoch: 7, Index: 359, Loss: 0.0362\n",
      "Epoch: 7, Index: 360, Loss: 5.9648\n",
      "Epoch: 7, Index: 361, Loss: 0.6494\n",
      "Epoch: 7, Index: 362, Loss: 3.2380\n",
      "Epoch: 7, Index: 363, Loss: 1.4047\n",
      "Epoch: 7, Index: 364, Loss: 0.3137\n",
      "Epoch: 7, Index: 365, Loss: 0.4795\n",
      "Epoch: 7, Index: 366, Loss: 0.0984\n",
      "Epoch: 7, Index: 367, Loss: 1.4222\n",
      "Epoch: 7, Index: 368, Loss: 0.6720\n",
      "Epoch: 7, Index: 369, Loss: 2.4249\n",
      "Epoch: 7, Index: 370, Loss: 2.3108\n",
      "Epoch: 7, Index: 371, Loss: 0.4464\n",
      "Epoch: 7, Index: 372, Loss: 13.2622\n",
      "Epoch: 7, Index: 373, Loss: 3.9555\n",
      "Epoch: 7, Index: 374, Loss: 0.6493\n",
      "Epoch: 7, Index: 375, Loss: 0.8432\n",
      "Epoch: 7, Index: 376, Loss: 3.4130\n",
      "Epoch: 7, Index: 377, Loss: 5.1059\n",
      "Epoch: 7, Index: 378, Loss: 1.6862\n",
      "Epoch: 7, Index: 379, Loss: 0.1831\n",
      "Epoch: 7, Index: 380, Loss: 0.0938\n",
      "Epoch: 7, Index: 381, Loss: 2.5410\n",
      "Epoch: 7, Index: 382, Loss: 6.3659\n",
      "Epoch: 7, Index: 383, Loss: 0.3137\n",
      "Epoch: 7, Index: 384, Loss: 1.0737\n",
      "Epoch: 7, Index: 385, Loss: 0.1515\n",
      "Epoch: 7, Index: 386, Loss: 1.5924\n",
      "Epoch: 7, Index: 387, Loss: 1.5155\n",
      "Epoch: 7, Index: 388, Loss: 2.3004\n",
      "Epoch: 7, Index: 389, Loss: 2.0592\n",
      "Epoch: 7, Index: 390, Loss: 1.7701\n",
      "Epoch: 7, Index: 391, Loss: 1.3834\n",
      "Epoch: 7, Index: 392, Loss: 1.8210\n",
      "Epoch: 7, Index: 393, Loss: 1.5593\n",
      "Epoch: 7, Index: 394, Loss: 0.0985\n",
      "Epoch: 7, Index: 395, Loss: 9.5614\n",
      "Epoch: 7, Index: 396, Loss: 2.1523\n",
      "Epoch: 7, Index: 397, Loss: 0.5685\n",
      "Epoch: 7, Index: 398, Loss: 3.0821\n",
      "Epoch: 7, Index: 399, Loss: 6.4181\n",
      "Epoch: 7, Index: 400, Loss: 3.1316\n",
      "Epoch: 7, Index: 401, Loss: 3.0915\n",
      "Epoch: 7, Index: 402, Loss: 0.3937\n",
      "Epoch: 7, Index: 403, Loss: 1.7643\n",
      "Epoch: 7, Index: 404, Loss: 0.4408\n",
      "Epoch: 7, Index: 405, Loss: 1.0717\n",
      "Epoch: 7, Index: 406, Loss: 1.1581\n",
      "Epoch: 7, Index: 407, Loss: 0.1674\n",
      "Epoch: 7, Index: 408, Loss: 1.8232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c4235ef0264c0ab8fd16c70080b63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Index: 0, Loss: 6.3323\n",
      "Epoch: 8, Index: 1, Loss: 1.9731\n",
      "Epoch: 8, Index: 2, Loss: 1.8470\n",
      "Epoch: 8, Index: 3, Loss: 5.8757\n",
      "Epoch: 8, Index: 4, Loss: 1.9625\n",
      "Epoch: 8, Index: 5, Loss: 1.1774\n",
      "Epoch: 8, Index: 6, Loss: 0.1829\n",
      "Epoch: 8, Index: 7, Loss: 0.0300\n",
      "Epoch: 8, Index: 8, Loss: 4.7003\n",
      "Epoch: 8, Index: 9, Loss: 0.8418\n",
      "Epoch: 8, Index: 10, Loss: 5.5548\n",
      "Epoch: 8, Index: 11, Loss: 0.4046\n",
      "Epoch: 8, Index: 12, Loss: 19.8836\n",
      "Epoch: 8, Index: 13, Loss: 0.8995\n",
      "Epoch: 8, Index: 14, Loss: 1.0054\n",
      "Epoch: 8, Index: 15, Loss: 0.1044\n",
      "Epoch: 8, Index: 16, Loss: 0.2785\n",
      "Epoch: 8, Index: 17, Loss: 1.0815\n",
      "Epoch: 8, Index: 18, Loss: 0.4946\n",
      "Epoch: 8, Index: 19, Loss: 1.4209\n",
      "Epoch: 8, Index: 20, Loss: 0.3049\n",
      "Epoch: 8, Index: 21, Loss: 0.0318\n",
      "Epoch: 8, Index: 22, Loss: 4.3763\n",
      "Epoch: 8, Index: 23, Loss: 3.7600\n",
      "Epoch: 8, Index: 24, Loss: 0.2919\n",
      "Epoch: 8, Index: 25, Loss: 2.1088\n",
      "Epoch: 8, Index: 26, Loss: 0.0101\n",
      "Epoch: 8, Index: 27, Loss: 0.6604\n",
      "Epoch: 8, Index: 28, Loss: 0.5086\n",
      "Epoch: 8, Index: 29, Loss: 1.0707\n",
      "Epoch: 8, Index: 30, Loss: 4.2903\n",
      "Epoch: 8, Index: 31, Loss: 4.3054\n",
      "Epoch: 8, Index: 32, Loss: 0.1420\n",
      "Epoch: 8, Index: 33, Loss: 0.3679\n",
      "Epoch: 8, Index: 34, Loss: 1.3400\n",
      "Epoch: 8, Index: 35, Loss: 2.5955\n",
      "Epoch: 8, Index: 36, Loss: 2.0246\n",
      "Epoch: 8, Index: 37, Loss: 3.9642\n",
      "Epoch: 8, Index: 38, Loss: 1.1895\n",
      "Epoch: 8, Index: 39, Loss: 0.8081\n",
      "Epoch: 8, Index: 40, Loss: 3.8680\n",
      "Epoch: 8, Index: 41, Loss: 0.3690\n",
      "Epoch: 8, Index: 42, Loss: 1.1451\n",
      "Epoch: 8, Index: 43, Loss: 0.0988\n",
      "Epoch: 8, Index: 44, Loss: 4.9316\n",
      "Epoch: 8, Index: 45, Loss: 0.8374\n",
      "Epoch: 8, Index: 46, Loss: 4.3036\n",
      "Epoch: 8, Index: 47, Loss: 0.6836\n",
      "Epoch: 8, Index: 48, Loss: 0.9529\n",
      "Epoch: 8, Index: 49, Loss: 0.7982\n",
      "Epoch: 8, Index: 50, Loss: 3.3528\n",
      "Epoch: 8, Index: 51, Loss: 0.7755\n",
      "Epoch: 8, Index: 52, Loss: 0.4862\n",
      "Epoch: 8, Index: 53, Loss: 3.6755\n",
      "Epoch: 8, Index: 54, Loss: 9.3829\n",
      "Epoch: 8, Index: 55, Loss: 1.0524\n",
      "Epoch: 8, Index: 56, Loss: 0.8275\n",
      "Epoch: 8, Index: 57, Loss: 1.5646\n",
      "Epoch: 8, Index: 58, Loss: 1.4269\n",
      "Epoch: 8, Index: 59, Loss: 1.3064\n",
      "Epoch: 8, Index: 60, Loss: 1.4927\n",
      "Epoch: 8, Index: 61, Loss: 0.0996\n",
      "Epoch: 8, Index: 62, Loss: 2.5563\n",
      "Epoch: 8, Index: 63, Loss: 1.9218\n",
      "Epoch: 8, Index: 64, Loss: 0.3866\n",
      "Epoch: 8, Index: 65, Loss: 0.2812\n",
      "Epoch: 8, Index: 66, Loss: 1.0163\n",
      "Epoch: 8, Index: 67, Loss: 0.3511\n",
      "Epoch: 8, Index: 68, Loss: 1.7626\n",
      "Epoch: 8, Index: 69, Loss: 1.3404\n",
      "Epoch: 8, Index: 70, Loss: 0.0083\n",
      "Epoch: 8, Index: 71, Loss: 0.1239\n",
      "Epoch: 8, Index: 72, Loss: 0.9334\n",
      "Epoch: 8, Index: 73, Loss: 0.9138\n",
      "Epoch: 8, Index: 74, Loss: 0.7365\n",
      "Epoch: 8, Index: 75, Loss: 0.4497\n",
      "Epoch: 8, Index: 76, Loss: 0.0987\n",
      "Epoch: 8, Index: 77, Loss: 3.4709\n",
      "Epoch: 8, Index: 78, Loss: 0.0519\n",
      "Epoch: 8, Index: 79, Loss: 1.4529\n",
      "Epoch: 8, Index: 80, Loss: 1.2685\n",
      "Epoch: 8, Index: 81, Loss: 0.0727\n",
      "Epoch: 8, Index: 82, Loss: 2.7742\n",
      "Epoch: 8, Index: 83, Loss: 2.2390\n",
      "Epoch: 8, Index: 84, Loss: 1.6649\n",
      "Epoch: 8, Index: 85, Loss: 1.0528\n",
      "Epoch: 8, Index: 86, Loss: 0.8644\n",
      "Epoch: 8, Index: 87, Loss: 0.9638\n",
      "Epoch: 8, Index: 88, Loss: 0.4872\n",
      "Epoch: 8, Index: 89, Loss: 0.2977\n",
      "Epoch: 8, Index: 90, Loss: 1.7164\n",
      "Epoch: 8, Index: 91, Loss: 0.5661\n",
      "Epoch: 8, Index: 92, Loss: 0.0833\n",
      "Epoch: 8, Index: 93, Loss: 0.0900\n",
      "Epoch: 8, Index: 94, Loss: 3.4630\n",
      "Epoch: 8, Index: 95, Loss: 0.1538\n",
      "Epoch: 8, Index: 96, Loss: 1.7340\n",
      "Epoch: 8, Index: 97, Loss: 3.2276\n",
      "Epoch: 8, Index: 98, Loss: 1.7284\n",
      "Epoch: 8, Index: 99, Loss: 0.4491\n",
      "Epoch: 8, Index: 100, Loss: 1.2480\n",
      "Epoch: 8, Index: 101, Loss: 1.8659\n",
      "Epoch: 8, Index: 102, Loss: 1.3449\n",
      "Epoch: 8, Index: 103, Loss: 1.0479\n",
      "Epoch: 8, Index: 104, Loss: 0.8445\n",
      "Epoch: 8, Index: 105, Loss: 0.8305\n",
      "Epoch: 8, Index: 106, Loss: 2.0255\n",
      "Epoch: 8, Index: 107, Loss: 0.3871\n",
      "Epoch: 8, Index: 108, Loss: 1.6565\n",
      "Epoch: 8, Index: 109, Loss: 0.1339\n",
      "Epoch: 8, Index: 110, Loss: 2.2458\n",
      "Epoch: 8, Index: 111, Loss: 4.9260\n",
      "Epoch: 8, Index: 112, Loss: 0.9048\n",
      "Epoch: 8, Index: 113, Loss: 0.1738\n",
      "Epoch: 8, Index: 114, Loss: 0.6299\n",
      "Epoch: 8, Index: 115, Loss: 1.4870\n",
      "Epoch: 8, Index: 116, Loss: 0.8603\n",
      "Epoch: 8, Index: 117, Loss: 1.9943\n",
      "Epoch: 8, Index: 118, Loss: 0.3096\n",
      "Epoch: 8, Index: 119, Loss: 0.1408\n",
      "Epoch: 8, Index: 120, Loss: 3.0380\n",
      "Epoch: 8, Index: 121, Loss: 4.1434\n",
      "Epoch: 8, Index: 122, Loss: 0.0216\n",
      "Epoch: 8, Index: 123, Loss: 0.9038\n",
      "Epoch: 8, Index: 124, Loss: 1.4172\n",
      "Epoch: 8, Index: 125, Loss: 5.8797\n",
      "Epoch: 8, Index: 126, Loss: 0.0297\n",
      "Epoch: 8, Index: 127, Loss: 1.3947\n",
      "Epoch: 8, Index: 128, Loss: 0.0616\n",
      "Epoch: 8, Index: 129, Loss: 2.1989\n",
      "Epoch: 8, Index: 130, Loss: 1.8097\n",
      "Epoch: 8, Index: 131, Loss: 0.6068\n",
      "Epoch: 8, Index: 132, Loss: 0.9990\n",
      "Epoch: 8, Index: 133, Loss: 0.7430\n",
      "Epoch: 8, Index: 134, Loss: 0.2540\n",
      "Epoch: 8, Index: 135, Loss: 7.8421\n",
      "Epoch: 8, Index: 136, Loss: 1.9212\n",
      "Epoch: 8, Index: 137, Loss: 1.0169\n",
      "Epoch: 8, Index: 138, Loss: 2.0714\n",
      "Epoch: 8, Index: 139, Loss: 3.7288\n",
      "Epoch: 8, Index: 140, Loss: 0.9674\n",
      "Epoch: 8, Index: 141, Loss: 1.7860\n",
      "Epoch: 8, Index: 142, Loss: 0.8995\n",
      "Epoch: 8, Index: 143, Loss: 3.5689\n",
      "Epoch: 8, Index: 144, Loss: 2.9025\n",
      "Epoch: 8, Index: 145, Loss: 0.7723\n",
      "Epoch: 8, Index: 146, Loss: 0.8248\n",
      "Epoch: 8, Index: 147, Loss: 2.0725\n",
      "Epoch: 8, Index: 148, Loss: 0.8268\n",
      "Epoch: 8, Index: 149, Loss: 3.2459\n",
      "Epoch: 8, Index: 150, Loss: 0.5392\n",
      "Epoch: 8, Index: 151, Loss: 0.0913\n",
      "Epoch: 8, Index: 152, Loss: 4.1943\n",
      "Epoch: 8, Index: 153, Loss: 0.7078\n",
      "Epoch: 8, Index: 154, Loss: 2.2192\n",
      "Epoch: 8, Index: 155, Loss: 2.2772\n",
      "Epoch: 8, Index: 156, Loss: 2.0054\n",
      "Epoch: 8, Index: 157, Loss: 0.1279\n",
      "Epoch: 8, Index: 158, Loss: 3.4944\n",
      "Epoch: 8, Index: 159, Loss: 0.9294\n",
      "Epoch: 8, Index: 160, Loss: 0.8504\n",
      "Epoch: 8, Index: 161, Loss: 0.1962\n",
      "Epoch: 8, Index: 162, Loss: 2.0636\n",
      "Epoch: 8, Index: 163, Loss: 0.7192\n",
      "Epoch: 8, Index: 164, Loss: 1.6075\n",
      "Epoch: 8, Index: 165, Loss: 2.3101\n",
      "Epoch: 8, Index: 166, Loss: 7.5226\n",
      "Epoch: 8, Index: 167, Loss: 0.9449\n",
      "Epoch: 8, Index: 168, Loss: 0.1079\n",
      "Epoch: 8, Index: 169, Loss: 0.9035\n",
      "Epoch: 8, Index: 170, Loss: 2.2121\n",
      "Epoch: 8, Index: 171, Loss: 10.1463\n",
      "Epoch: 8, Index: 172, Loss: 1.1902\n",
      "Epoch: 8, Index: 173, Loss: 8.0857\n",
      "Epoch: 8, Index: 174, Loss: 0.5222\n",
      "Epoch: 8, Index: 175, Loss: 0.4761\n",
      "Epoch: 8, Index: 176, Loss: 5.5186\n",
      "Epoch: 8, Index: 177, Loss: 2.3474\n",
      "Epoch: 8, Index: 178, Loss: 0.2368\n",
      "Epoch: 8, Index: 179, Loss: 0.2540\n",
      "Epoch: 8, Index: 180, Loss: 2.3138\n",
      "Epoch: 8, Index: 181, Loss: 3.4935\n",
      "Epoch: 8, Index: 182, Loss: 0.0178\n",
      "Epoch: 8, Index: 183, Loss: 0.9345\n",
      "Epoch: 8, Index: 184, Loss: 1.0432\n",
      "Epoch: 8, Index: 185, Loss: 0.8661\n",
      "Epoch: 8, Index: 186, Loss: 1.3293\n",
      "Epoch: 8, Index: 187, Loss: 4.5471\n",
      "Epoch: 8, Index: 188, Loss: 1.8552\n",
      "Epoch: 8, Index: 189, Loss: 4.5561\n",
      "Epoch: 8, Index: 190, Loss: 0.6653\n",
      "Epoch: 8, Index: 191, Loss: 2.1587\n",
      "Epoch: 8, Index: 192, Loss: 0.1083\n",
      "Epoch: 8, Index: 193, Loss: 1.6240\n",
      "Epoch: 8, Index: 194, Loss: 1.4924\n",
      "Epoch: 8, Index: 195, Loss: 1.8182\n",
      "Epoch: 8, Index: 196, Loss: 3.0116\n",
      "Epoch: 8, Index: 197, Loss: 5.2468\n",
      "Epoch: 8, Index: 198, Loss: 3.7003\n",
      "Epoch: 8, Index: 199, Loss: 0.0555\n",
      "Epoch: 8, Index: 200, Loss: 0.8495\n",
      "Epoch: 8, Index: 201, Loss: 0.7662\n",
      "Epoch: 8, Index: 202, Loss: 0.2558\n",
      "Epoch: 8, Index: 203, Loss: 3.2896\n",
      "Epoch: 8, Index: 204, Loss: 2.3133\n",
      "Epoch: 8, Index: 205, Loss: 0.1026\n",
      "Epoch: 8, Index: 206, Loss: 2.3170\n",
      "Epoch: 8, Index: 207, Loss: 0.8813\n",
      "Epoch: 8, Index: 208, Loss: 7.4957\n",
      "Epoch: 8, Index: 209, Loss: 0.5589\n",
      "Epoch: 8, Index: 210, Loss: 0.0541\n",
      "Epoch: 8, Index: 211, Loss: 1.6828\n",
      "Epoch: 8, Index: 212, Loss: 2.8715\n",
      "Epoch: 8, Index: 213, Loss: 0.7257\n",
      "Epoch: 8, Index: 214, Loss: 2.1312\n",
      "Epoch: 8, Index: 215, Loss: 1.1022\n",
      "Epoch: 8, Index: 216, Loss: 5.7145\n",
      "Epoch: 8, Index: 217, Loss: 0.8011\n",
      "Epoch: 8, Index: 218, Loss: 0.5676\n",
      "Epoch: 8, Index: 219, Loss: 2.1436\n",
      "Epoch: 8, Index: 220, Loss: 0.6113\n",
      "Epoch: 8, Index: 221, Loss: 1.6570\n",
      "Epoch: 8, Index: 222, Loss: 1.5736\n",
      "Epoch: 8, Index: 223, Loss: 3.9615\n",
      "Epoch: 8, Index: 224, Loss: 8.7622\n",
      "Epoch: 8, Index: 225, Loss: 7.4503\n",
      "Epoch: 8, Index: 226, Loss: 1.0348\n",
      "Epoch: 8, Index: 227, Loss: 0.6277\n",
      "Epoch: 8, Index: 228, Loss: 0.2184\n",
      "Epoch: 8, Index: 229, Loss: 3.4761\n",
      "Epoch: 8, Index: 230, Loss: 0.4898\n",
      "Epoch: 8, Index: 231, Loss: 0.4791\n",
      "Epoch: 8, Index: 232, Loss: 0.6475\n",
      "Epoch: 8, Index: 233, Loss: 0.1790\n",
      "Epoch: 8, Index: 234, Loss: 1.5149\n",
      "Epoch: 8, Index: 235, Loss: 1.2048\n",
      "Epoch: 8, Index: 236, Loss: 0.7429\n",
      "Epoch: 8, Index: 237, Loss: 0.0010\n",
      "Epoch: 8, Index: 238, Loss: 0.6437\n",
      "Epoch: 8, Index: 239, Loss: 1.5958\n",
      "Epoch: 8, Index: 240, Loss: 2.0539\n",
      "Epoch: 8, Index: 241, Loss: 0.8247\n",
      "Epoch: 8, Index: 242, Loss: 1.2451\n",
      "Epoch: 8, Index: 243, Loss: 0.2278\n",
      "Epoch: 8, Index: 244, Loss: 0.0715\n",
      "Epoch: 8, Index: 245, Loss: 0.9274\n",
      "Epoch: 8, Index: 246, Loss: 2.5115\n",
      "Epoch: 8, Index: 247, Loss: 4.8660\n",
      "Epoch: 8, Index: 248, Loss: 0.9589\n",
      "Epoch: 8, Index: 249, Loss: 3.5781\n",
      "Epoch: 8, Index: 250, Loss: 0.5541\n",
      "Epoch: 8, Index: 251, Loss: 2.3086\n",
      "Epoch: 8, Index: 252, Loss: 0.7152\n",
      "Epoch: 8, Index: 253, Loss: 1.2273\n",
      "Epoch: 8, Index: 254, Loss: 0.6522\n",
      "Epoch: 8, Index: 255, Loss: 3.6116\n",
      "Epoch: 8, Index: 256, Loss: 0.7939\n",
      "Epoch: 8, Index: 257, Loss: 0.3500\n",
      "Epoch: 8, Index: 258, Loss: 3.4632\n",
      "Epoch: 8, Index: 259, Loss: 2.4979\n",
      "Epoch: 8, Index: 260, Loss: 0.9913\n",
      "Epoch: 8, Index: 261, Loss: 0.6150\n",
      "Epoch: 8, Index: 262, Loss: 0.3140\n",
      "Epoch: 8, Index: 263, Loss: 4.1064\n",
      "Epoch: 8, Index: 264, Loss: 1.8722\n",
      "Epoch: 8, Index: 265, Loss: 2.7159\n",
      "Epoch: 8, Index: 266, Loss: 0.1163\n",
      "Epoch: 8, Index: 267, Loss: 2.0338\n",
      "Epoch: 8, Index: 268, Loss: 0.1479\n",
      "Epoch: 8, Index: 269, Loss: 3.4220\n",
      "Epoch: 8, Index: 270, Loss: 1.3371\n",
      "Epoch: 8, Index: 271, Loss: 4.1038\n",
      "Epoch: 8, Index: 272, Loss: 3.5466\n",
      "Epoch: 8, Index: 273, Loss: 1.8762\n",
      "Epoch: 8, Index: 274, Loss: 1.6541\n",
      "Epoch: 8, Index: 275, Loss: 2.2885\n",
      "Epoch: 8, Index: 276, Loss: 5.5304\n",
      "Epoch: 8, Index: 277, Loss: 1.4572\n",
      "Epoch: 8, Index: 278, Loss: 1.6888\n",
      "Epoch: 8, Index: 279, Loss: 2.7718\n",
      "Epoch: 8, Index: 280, Loss: 2.4318\n",
      "Epoch: 8, Index: 281, Loss: 0.5135\n",
      "Epoch: 8, Index: 282, Loss: 0.0457\n",
      "Epoch: 8, Index: 283, Loss: 3.9112\n",
      "Epoch: 8, Index: 284, Loss: 0.0670\n",
      "Epoch: 8, Index: 285, Loss: 0.1329\n",
      "Epoch: 8, Index: 286, Loss: 0.2154\n",
      "Epoch: 8, Index: 287, Loss: 3.8922\n",
      "Epoch: 8, Index: 288, Loss: 2.8134\n",
      "Epoch: 8, Index: 289, Loss: 0.3212\n",
      "Epoch: 8, Index: 290, Loss: 0.7755\n",
      "Epoch: 8, Index: 291, Loss: 1.1801\n",
      "Epoch: 8, Index: 292, Loss: 1.4903\n",
      "Epoch: 8, Index: 293, Loss: 0.0163\n",
      "Epoch: 8, Index: 294, Loss: 1.3869\n",
      "Epoch: 8, Index: 295, Loss: 5.2396\n",
      "Epoch: 8, Index: 296, Loss: 3.0069\n",
      "Epoch: 8, Index: 297, Loss: 0.9051\n",
      "Epoch: 8, Index: 298, Loss: 2.0139\n",
      "Epoch: 8, Index: 299, Loss: 2.0362\n",
      "Epoch: 8, Index: 300, Loss: 1.9923\n",
      "Epoch: 8, Index: 301, Loss: 2.5169\n",
      "Epoch: 8, Index: 302, Loss: 1.5735\n",
      "Epoch: 8, Index: 303, Loss: 1.2341\n",
      "Epoch: 8, Index: 304, Loss: 0.7996\n",
      "Epoch: 8, Index: 305, Loss: 13.7190\n",
      "Epoch: 8, Index: 306, Loss: 0.0403\n",
      "Epoch: 8, Index: 307, Loss: 1.5445\n",
      "Epoch: 8, Index: 308, Loss: 1.2454\n",
      "Epoch: 8, Index: 309, Loss: 2.9925\n",
      "Epoch: 8, Index: 310, Loss: 0.6777\n",
      "Epoch: 8, Index: 311, Loss: 0.2839\n",
      "Epoch: 8, Index: 312, Loss: 4.2883\n",
      "Epoch: 8, Index: 313, Loss: 2.4031\n",
      "Epoch: 8, Index: 314, Loss: 0.7291\n",
      "Epoch: 8, Index: 315, Loss: 0.5366\n",
      "Epoch: 8, Index: 316, Loss: 2.4690\n",
      "Epoch: 8, Index: 317, Loss: 0.2337\n",
      "Epoch: 8, Index: 318, Loss: 2.2405\n",
      "Epoch: 8, Index: 319, Loss: 0.9542\n",
      "Epoch: 8, Index: 320, Loss: 5.4270\n",
      "Epoch: 8, Index: 321, Loss: 0.3973\n",
      "Epoch: 8, Index: 322, Loss: 2.0566\n",
      "Epoch: 8, Index: 323, Loss: 0.5593\n",
      "Epoch: 8, Index: 324, Loss: 1.8033\n",
      "Epoch: 8, Index: 325, Loss: 0.5034\n",
      "Epoch: 8, Index: 326, Loss: 1.5864\n",
      "Epoch: 8, Index: 327, Loss: 0.4183\n",
      "Epoch: 8, Index: 328, Loss: 0.1642\n",
      "Epoch: 8, Index: 329, Loss: 1.8685\n",
      "Epoch: 8, Index: 330, Loss: 0.6826\n",
      "Epoch: 8, Index: 331, Loss: 0.2193\n",
      "Epoch: 8, Index: 332, Loss: 0.7235\n",
      "Epoch: 8, Index: 333, Loss: 1.6737\n",
      "Epoch: 8, Index: 334, Loss: 1.9790\n",
      "Epoch: 8, Index: 335, Loss: 1.5040\n",
      "Epoch: 8, Index: 336, Loss: 3.3536\n",
      "Epoch: 8, Index: 337, Loss: 2.0917\n",
      "Epoch: 8, Index: 338, Loss: 1.0500\n",
      "Epoch: 8, Index: 339, Loss: 0.5083\n",
      "Epoch: 8, Index: 340, Loss: 0.5759\n",
      "Epoch: 8, Index: 341, Loss: 1.4084\n",
      "Epoch: 8, Index: 342, Loss: 2.5837\n",
      "Epoch: 8, Index: 343, Loss: 1.3785\n",
      "Epoch: 8, Index: 344, Loss: 2.7762\n",
      "Epoch: 8, Index: 345, Loss: 5.3487\n",
      "Epoch: 8, Index: 346, Loss: 4.9396\n",
      "Epoch: 8, Index: 347, Loss: 1.2183\n",
      "Epoch: 8, Index: 348, Loss: 0.2522\n",
      "Epoch: 8, Index: 349, Loss: 0.3654\n",
      "Epoch: 8, Index: 350, Loss: 4.2062\n",
      "Epoch: 8, Index: 351, Loss: 2.7701\n",
      "Epoch: 8, Index: 352, Loss: 2.5324\n",
      "Epoch: 8, Index: 353, Loss: 4.0967\n",
      "Epoch: 8, Index: 354, Loss: 0.6730\n",
      "Epoch: 8, Index: 355, Loss: 3.4480\n",
      "Epoch: 8, Index: 356, Loss: 1.2460\n",
      "Epoch: 8, Index: 357, Loss: 1.0233\n",
      "Epoch: 8, Index: 358, Loss: 3.4577\n",
      "Epoch: 8, Index: 359, Loss: 6.9173\n",
      "Epoch: 8, Index: 360, Loss: 1.1407\n",
      "Epoch: 8, Index: 361, Loss: 0.2895\n",
      "Epoch: 8, Index: 362, Loss: 0.1322\n",
      "Epoch: 8, Index: 363, Loss: 1.8009\n",
      "Epoch: 8, Index: 364, Loss: 0.4932\n",
      "Epoch: 8, Index: 365, Loss: 2.3073\n",
      "Epoch: 8, Index: 366, Loss: 0.1081\n",
      "Epoch: 8, Index: 367, Loss: 0.0220\n",
      "Epoch: 8, Index: 368, Loss: 3.7432\n",
      "Epoch: 8, Index: 369, Loss: 0.0890\n",
      "Epoch: 8, Index: 370, Loss: 0.1182\n",
      "Epoch: 8, Index: 371, Loss: 2.8989\n",
      "Epoch: 8, Index: 372, Loss: 0.8965\n",
      "Epoch: 8, Index: 373, Loss: 1.8552\n",
      "Epoch: 8, Index: 374, Loss: 1.6617\n",
      "Epoch: 8, Index: 375, Loss: 1.4025\n",
      "Epoch: 8, Index: 376, Loss: 0.7590\n",
      "Epoch: 8, Index: 377, Loss: 4.2281\n",
      "Epoch: 8, Index: 378, Loss: 0.8258\n",
      "Epoch: 8, Index: 379, Loss: 0.7111\n",
      "Epoch: 8, Index: 380, Loss: 0.1071\n",
      "Epoch: 8, Index: 381, Loss: 4.3811\n",
      "Epoch: 8, Index: 382, Loss: 2.5427\n",
      "Epoch: 8, Index: 383, Loss: 2.4568\n",
      "Epoch: 8, Index: 384, Loss: 0.5497\n",
      "Epoch: 8, Index: 385, Loss: 0.1213\n",
      "Epoch: 8, Index: 386, Loss: 0.1653\n",
      "Epoch: 8, Index: 387, Loss: 3.5791\n",
      "Epoch: 8, Index: 388, Loss: 5.6702\n",
      "Epoch: 8, Index: 389, Loss: 2.4278\n",
      "Epoch: 8, Index: 390, Loss: 0.3248\n",
      "Epoch: 8, Index: 391, Loss: 0.2052\n",
      "Epoch: 8, Index: 392, Loss: 0.4224\n",
      "Epoch: 8, Index: 393, Loss: 1.3554\n",
      "Epoch: 8, Index: 394, Loss: 1.2154\n",
      "Epoch: 8, Index: 395, Loss: 0.9524\n",
      "Epoch: 8, Index: 396, Loss: 0.6476\n",
      "Epoch: 8, Index: 397, Loss: 2.6635\n",
      "Epoch: 8, Index: 398, Loss: 0.3516\n",
      "Epoch: 8, Index: 399, Loss: 3.6077\n",
      "Epoch: 8, Index: 400, Loss: 0.1770\n",
      "Epoch: 8, Index: 401, Loss: 0.3695\n",
      "Epoch: 8, Index: 402, Loss: 0.8849\n",
      "Epoch: 8, Index: 403, Loss: 1.0501\n",
      "Epoch: 8, Index: 404, Loss: 0.2150\n",
      "Epoch: 8, Index: 405, Loss: 13.2385\n",
      "Epoch: 8, Index: 406, Loss: 1.9790\n",
      "Epoch: 8, Index: 407, Loss: 2.6867\n",
      "Epoch: 8, Index: 408, Loss: 1.5180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8dca3eb8efc47f7a0c28c7a15ff5d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Index: 0, Loss: 1.2438\n",
      "Epoch: 9, Index: 1, Loss: 0.1521\n",
      "Epoch: 9, Index: 2, Loss: 0.1582\n",
      "Epoch: 9, Index: 3, Loss: 0.5169\n",
      "Epoch: 9, Index: 4, Loss: 0.7004\n",
      "Epoch: 9, Index: 5, Loss: 0.8168\n",
      "Epoch: 9, Index: 6, Loss: 0.2688\n",
      "Epoch: 9, Index: 7, Loss: 0.7731\n",
      "Epoch: 9, Index: 8, Loss: 4.1635\n",
      "Epoch: 9, Index: 9, Loss: 0.4054\n",
      "Epoch: 9, Index: 10, Loss: 0.0431\n",
      "Epoch: 9, Index: 11, Loss: 1.5973\n",
      "Epoch: 9, Index: 12, Loss: 0.0464\n",
      "Epoch: 9, Index: 13, Loss: 1.0424\n",
      "Epoch: 9, Index: 14, Loss: 0.5450\n",
      "Epoch: 9, Index: 15, Loss: 0.5974\n",
      "Epoch: 9, Index: 16, Loss: 2.1969\n",
      "Epoch: 9, Index: 17, Loss: 4.9353\n",
      "Epoch: 9, Index: 18, Loss: 0.0341\n",
      "Epoch: 9, Index: 19, Loss: 3.4100\n",
      "Epoch: 9, Index: 20, Loss: 3.0471\n",
      "Epoch: 9, Index: 21, Loss: 0.3580\n",
      "Epoch: 9, Index: 22, Loss: 0.2161\n",
      "Epoch: 9, Index: 23, Loss: 2.1848\n",
      "Epoch: 9, Index: 24, Loss: 6.3685\n",
      "Epoch: 9, Index: 25, Loss: 0.7562\n",
      "Epoch: 9, Index: 26, Loss: 0.9233\n",
      "Epoch: 9, Index: 27, Loss: 4.5487\n",
      "Epoch: 9, Index: 28, Loss: 2.6180\n",
      "Epoch: 9, Index: 29, Loss: 3.0079\n",
      "Epoch: 9, Index: 30, Loss: 2.3486\n",
      "Epoch: 9, Index: 31, Loss: 0.5719\n",
      "Epoch: 9, Index: 32, Loss: 0.2590\n",
      "Epoch: 9, Index: 33, Loss: 0.0449\n",
      "Epoch: 9, Index: 34, Loss: 0.7647\n",
      "Epoch: 9, Index: 35, Loss: 0.1909\n",
      "Epoch: 9, Index: 36, Loss: 2.7410\n",
      "Epoch: 9, Index: 37, Loss: 3.2147\n",
      "Epoch: 9, Index: 38, Loss: 0.9823\n",
      "Epoch: 9, Index: 39, Loss: 0.4923\n",
      "Epoch: 9, Index: 40, Loss: 1.2990\n",
      "Epoch: 9, Index: 41, Loss: 1.5217\n",
      "Epoch: 9, Index: 42, Loss: 1.8009\n",
      "Epoch: 9, Index: 43, Loss: 4.0744\n",
      "Epoch: 9, Index: 44, Loss: 0.4696\n",
      "Epoch: 9, Index: 45, Loss: 1.1532\n",
      "Epoch: 9, Index: 46, Loss: 0.5279\n",
      "Epoch: 9, Index: 47, Loss: 1.9858\n",
      "Epoch: 9, Index: 48, Loss: 3.7677\n",
      "Epoch: 9, Index: 49, Loss: 0.8731\n",
      "Epoch: 9, Index: 50, Loss: 0.0678\n",
      "Epoch: 9, Index: 51, Loss: 5.0806\n",
      "Epoch: 9, Index: 52, Loss: 0.4068\n",
      "Epoch: 9, Index: 53, Loss: 1.0890\n",
      "Epoch: 9, Index: 54, Loss: 0.1168\n",
      "Epoch: 9, Index: 55, Loss: 2.6404\n",
      "Epoch: 9, Index: 56, Loss: 0.5146\n",
      "Epoch: 9, Index: 57, Loss: 1.5053\n",
      "Epoch: 9, Index: 58, Loss: 1.7309\n",
      "Epoch: 9, Index: 59, Loss: 6.4277\n",
      "Epoch: 9, Index: 60, Loss: 2.2708\n",
      "Epoch: 9, Index: 61, Loss: 1.8668\n",
      "Epoch: 9, Index: 62, Loss: 4.3749\n",
      "Epoch: 9, Index: 63, Loss: 5.0932\n",
      "Epoch: 9, Index: 64, Loss: 0.1738\n",
      "Epoch: 9, Index: 65, Loss: 2.1135\n",
      "Epoch: 9, Index: 66, Loss: 0.9380\n",
      "Epoch: 9, Index: 67, Loss: 0.6185\n",
      "Epoch: 9, Index: 68, Loss: 3.4178\n",
      "Epoch: 9, Index: 69, Loss: 0.0878\n",
      "Epoch: 9, Index: 70, Loss: 0.0985\n",
      "Epoch: 9, Index: 71, Loss: 0.9525\n",
      "Epoch: 9, Index: 72, Loss: 0.7643\n",
      "Epoch: 9, Index: 73, Loss: 2.5391\n",
      "Epoch: 9, Index: 74, Loss: 1.2797\n",
      "Epoch: 9, Index: 75, Loss: 4.5602\n",
      "Epoch: 9, Index: 76, Loss: 5.2208\n",
      "Epoch: 9, Index: 77, Loss: 1.8406\n",
      "Epoch: 9, Index: 78, Loss: 2.9824\n",
      "Epoch: 9, Index: 79, Loss: 3.0991\n",
      "Epoch: 9, Index: 80, Loss: 3.0187\n",
      "Epoch: 9, Index: 81, Loss: 1.4611\n",
      "Epoch: 9, Index: 82, Loss: 0.3723\n",
      "Epoch: 9, Index: 83, Loss: 0.6084\n",
      "Epoch: 9, Index: 84, Loss: 0.8030\n",
      "Epoch: 9, Index: 85, Loss: 0.9691\n",
      "Epoch: 9, Index: 86, Loss: 1.1785\n",
      "Epoch: 9, Index: 87, Loss: 3.0191\n",
      "Epoch: 9, Index: 88, Loss: 2.0502\n",
      "Epoch: 9, Index: 89, Loss: 1.0429\n",
      "Epoch: 9, Index: 90, Loss: 3.2832\n",
      "Epoch: 9, Index: 91, Loss: 2.6313\n",
      "Epoch: 9, Index: 92, Loss: 1.1916\n",
      "Epoch: 9, Index: 93, Loss: 0.8176\n",
      "Epoch: 9, Index: 94, Loss: 0.8651\n",
      "Epoch: 9, Index: 95, Loss: 1.6533\n",
      "Epoch: 9, Index: 96, Loss: 8.4103\n",
      "Epoch: 9, Index: 97, Loss: 2.1747\n",
      "Epoch: 9, Index: 98, Loss: 0.3680\n",
      "Epoch: 9, Index: 99, Loss: 0.6569\n",
      "Epoch: 9, Index: 100, Loss: 3.6012\n",
      "Epoch: 9, Index: 101, Loss: 0.9463\n",
      "Epoch: 9, Index: 102, Loss: 0.9036\n",
      "Epoch: 9, Index: 103, Loss: 0.9854\n",
      "Epoch: 9, Index: 104, Loss: 0.8971\n",
      "Epoch: 9, Index: 105, Loss: 1.6130\n",
      "Epoch: 9, Index: 106, Loss: 1.2104\n",
      "Epoch: 9, Index: 107, Loss: 0.4568\n",
      "Epoch: 9, Index: 108, Loss: 0.4276\n",
      "Epoch: 9, Index: 109, Loss: 1.2830\n",
      "Epoch: 9, Index: 110, Loss: 0.0022\n",
      "Epoch: 9, Index: 111, Loss: 0.1585\n",
      "Epoch: 9, Index: 112, Loss: 1.0343\n",
      "Epoch: 9, Index: 113, Loss: 3.4061\n",
      "Epoch: 9, Index: 114, Loss: 0.4094\n",
      "Epoch: 9, Index: 115, Loss: 1.9415\n",
      "Epoch: 9, Index: 116, Loss: 0.6363\n",
      "Epoch: 9, Index: 117, Loss: 2.4031\n",
      "Epoch: 9, Index: 118, Loss: 1.2258\n",
      "Epoch: 9, Index: 119, Loss: 1.1761\n",
      "Epoch: 9, Index: 120, Loss: 1.6171\n",
      "Epoch: 9, Index: 121, Loss: 0.3610\n",
      "Epoch: 9, Index: 122, Loss: 0.3329\n",
      "Epoch: 9, Index: 123, Loss: 1.1432\n",
      "Epoch: 9, Index: 124, Loss: 2.1296\n",
      "Epoch: 9, Index: 125, Loss: 3.7340\n",
      "Epoch: 9, Index: 126, Loss: 1.4219\n",
      "Epoch: 9, Index: 127, Loss: 2.0861\n",
      "Epoch: 9, Index: 128, Loss: 0.5759\n",
      "Epoch: 9, Index: 129, Loss: 1.2873\n",
      "Epoch: 9, Index: 130, Loss: 0.1918\n",
      "Epoch: 9, Index: 131, Loss: 17.3811\n",
      "Epoch: 9, Index: 132, Loss: 5.0914\n",
      "Epoch: 9, Index: 133, Loss: 0.0924\n",
      "Epoch: 9, Index: 134, Loss: 2.0833\n",
      "Epoch: 9, Index: 135, Loss: 1.2947\n",
      "Epoch: 9, Index: 136, Loss: 0.3333\n",
      "Epoch: 9, Index: 137, Loss: 5.1423\n",
      "Epoch: 9, Index: 138, Loss: 1.0878\n",
      "Epoch: 9, Index: 139, Loss: 0.0571\n",
      "Epoch: 9, Index: 140, Loss: 1.6772\n",
      "Epoch: 9, Index: 141, Loss: 0.5299\n",
      "Epoch: 9, Index: 142, Loss: 0.0752\n",
      "Epoch: 9, Index: 143, Loss: 3.9128\n",
      "Epoch: 9, Index: 144, Loss: 1.9865\n",
      "Epoch: 9, Index: 145, Loss: 5.2932\n",
      "Epoch: 9, Index: 146, Loss: 0.9204\n",
      "Epoch: 9, Index: 147, Loss: 2.0987\n",
      "Epoch: 9, Index: 148, Loss: 1.5518\n",
      "Epoch: 9, Index: 149, Loss: 1.5821\n",
      "Epoch: 9, Index: 150, Loss: 2.5410\n",
      "Epoch: 9, Index: 151, Loss: 1.3711\n",
      "Epoch: 9, Index: 152, Loss: 2.1818\n",
      "Epoch: 9, Index: 153, Loss: 0.6352\n",
      "Epoch: 9, Index: 154, Loss: 2.0961\n",
      "Epoch: 9, Index: 155, Loss: 4.2494\n",
      "Epoch: 9, Index: 156, Loss: 0.2217\n",
      "Epoch: 9, Index: 157, Loss: 2.1982\n",
      "Epoch: 9, Index: 158, Loss: 1.6251\n",
      "Epoch: 9, Index: 159, Loss: 4.3093\n",
      "Epoch: 9, Index: 160, Loss: 0.0722\n",
      "Epoch: 9, Index: 161, Loss: 0.2960\n",
      "Epoch: 9, Index: 162, Loss: 2.4604\n",
      "Epoch: 9, Index: 163, Loss: 0.3636\n",
      "Epoch: 9, Index: 164, Loss: 0.2138\n",
      "Epoch: 9, Index: 165, Loss: 4.7517\n",
      "Epoch: 9, Index: 166, Loss: 1.6217\n",
      "Epoch: 9, Index: 167, Loss: 1.2843\n",
      "Epoch: 9, Index: 168, Loss: 1.1659\n",
      "Epoch: 9, Index: 169, Loss: 3.1503\n",
      "Epoch: 9, Index: 170, Loss: 0.0439\n",
      "Epoch: 9, Index: 171, Loss: 0.7762\n",
      "Epoch: 9, Index: 172, Loss: 0.8556\n",
      "Epoch: 9, Index: 173, Loss: 2.3969\n",
      "Epoch: 9, Index: 174, Loss: 0.2789\n",
      "Epoch: 9, Index: 175, Loss: 1.3465\n",
      "Epoch: 9, Index: 176, Loss: 0.2033\n",
      "Epoch: 9, Index: 177, Loss: 5.7163\n",
      "Epoch: 9, Index: 178, Loss: 0.3195\n",
      "Epoch: 9, Index: 179, Loss: 1.7578\n",
      "Epoch: 9, Index: 180, Loss: 1.2240\n",
      "Epoch: 9, Index: 181, Loss: 3.4334\n",
      "Epoch: 9, Index: 182, Loss: 0.1072\n",
      "Epoch: 9, Index: 183, Loss: 1.1529\n",
      "Epoch: 9, Index: 184, Loss: 1.0651\n",
      "Epoch: 9, Index: 185, Loss: 1.2186\n",
      "Epoch: 9, Index: 186, Loss: 0.8576\n",
      "Epoch: 9, Index: 187, Loss: 4.1862\n",
      "Epoch: 9, Index: 188, Loss: 4.3041\n",
      "Epoch: 9, Index: 189, Loss: 0.9436\n",
      "Epoch: 9, Index: 190, Loss: 4.9387\n",
      "Epoch: 9, Index: 191, Loss: 2.3024\n",
      "Epoch: 9, Index: 192, Loss: 2.3305\n",
      "Epoch: 9, Index: 193, Loss: 2.2869\n",
      "Epoch: 9, Index: 194, Loss: 7.2333\n",
      "Epoch: 9, Index: 195, Loss: 1.4466\n",
      "Epoch: 9, Index: 196, Loss: 1.3478\n",
      "Epoch: 9, Index: 197, Loss: 1.4431\n",
      "Epoch: 9, Index: 198, Loss: 1.1260\n",
      "Epoch: 9, Index: 199, Loss: 2.1128\n",
      "Epoch: 9, Index: 200, Loss: 3.0530\n",
      "Epoch: 9, Index: 201, Loss: 0.4273\n",
      "Epoch: 9, Index: 202, Loss: 0.0893\n",
      "Epoch: 9, Index: 203, Loss: 3.1012\n",
      "Epoch: 9, Index: 204, Loss: 0.9485\n",
      "Epoch: 9, Index: 205, Loss: 2.7912\n",
      "Epoch: 9, Index: 206, Loss: 0.0192\n",
      "Epoch: 9, Index: 207, Loss: 2.6995\n",
      "Epoch: 9, Index: 208, Loss: 2.2197\n",
      "Epoch: 9, Index: 209, Loss: 0.8618\n",
      "Epoch: 9, Index: 210, Loss: 0.0825\n",
      "Epoch: 9, Index: 211, Loss: 2.3866\n",
      "Epoch: 9, Index: 212, Loss: 2.4971\n",
      "Epoch: 9, Index: 213, Loss: 3.5831\n",
      "Epoch: 9, Index: 214, Loss: 0.8353\n",
      "Epoch: 9, Index: 215, Loss: 0.1592\n",
      "Epoch: 9, Index: 216, Loss: 0.3813\n",
      "Epoch: 9, Index: 217, Loss: 0.6449\n",
      "Epoch: 9, Index: 218, Loss: 0.6729\n",
      "Epoch: 9, Index: 219, Loss: 0.7890\n",
      "Epoch: 9, Index: 220, Loss: 1.5495\n",
      "Epoch: 9, Index: 221, Loss: 2.4427\n",
      "Epoch: 9, Index: 222, Loss: 0.8419\n",
      "Epoch: 9, Index: 223, Loss: 0.6532\n",
      "Epoch: 9, Index: 224, Loss: 1.4022\n",
      "Epoch: 9, Index: 225, Loss: 2.1588\n",
      "Epoch: 9, Index: 226, Loss: 1.8641\n",
      "Epoch: 9, Index: 227, Loss: 2.4221\n",
      "Epoch: 9, Index: 228, Loss: 0.9827\n",
      "Epoch: 9, Index: 229, Loss: 1.2605\n",
      "Epoch: 9, Index: 230, Loss: 0.3484\n",
      "Epoch: 9, Index: 231, Loss: 3.4327\n",
      "Epoch: 9, Index: 232, Loss: 1.0977\n",
      "Epoch: 9, Index: 233, Loss: 2.1703\n",
      "Epoch: 9, Index: 234, Loss: 0.5451\n",
      "Epoch: 9, Index: 235, Loss: 0.6322\n",
      "Epoch: 9, Index: 236, Loss: 0.9028\n",
      "Epoch: 9, Index: 237, Loss: 0.0846\n",
      "Epoch: 9, Index: 238, Loss: 2.6935\n",
      "Epoch: 9, Index: 239, Loss: 1.4789\n",
      "Epoch: 9, Index: 240, Loss: 2.0711\n",
      "Epoch: 9, Index: 241, Loss: 1.2113\n",
      "Epoch: 9, Index: 242, Loss: 1.1570\n",
      "Epoch: 9, Index: 243, Loss: 0.5483\n",
      "Epoch: 9, Index: 244, Loss: 1.3855\n",
      "Epoch: 9, Index: 245, Loss: 1.5647\n",
      "Epoch: 9, Index: 246, Loss: 2.6698\n",
      "Epoch: 9, Index: 247, Loss: 0.8187\n",
      "Epoch: 9, Index: 248, Loss: 2.8224\n",
      "Epoch: 9, Index: 249, Loss: 1.3778\n",
      "Epoch: 9, Index: 250, Loss: 2.3016\n",
      "Epoch: 9, Index: 251, Loss: 0.0813\n",
      "Epoch: 9, Index: 252, Loss: 0.3555\n",
      "Epoch: 9, Index: 253, Loss: 1.5606\n",
      "Epoch: 9, Index: 254, Loss: 2.2663\n",
      "Epoch: 9, Index: 255, Loss: 0.1647\n",
      "Epoch: 9, Index: 256, Loss: 1.4097\n",
      "Epoch: 9, Index: 257, Loss: 4.0442\n",
      "Epoch: 9, Index: 258, Loss: 2.6039\n",
      "Epoch: 9, Index: 259, Loss: 2.2067\n",
      "Epoch: 9, Index: 260, Loss: 0.6098\n",
      "Epoch: 9, Index: 261, Loss: 0.5099\n",
      "Epoch: 9, Index: 262, Loss: 0.9830\n",
      "Epoch: 9, Index: 263, Loss: 0.1186\n",
      "Epoch: 9, Index: 264, Loss: 1.3469\n",
      "Epoch: 9, Index: 265, Loss: 4.1610\n",
      "Epoch: 9, Index: 266, Loss: 1.6047\n",
      "Epoch: 9, Index: 267, Loss: 0.8590\n",
      "Epoch: 9, Index: 268, Loss: 1.7564\n",
      "Epoch: 9, Index: 269, Loss: 1.3091\n",
      "Epoch: 9, Index: 270, Loss: 0.2255\n",
      "Epoch: 9, Index: 271, Loss: 0.2117\n",
      "Epoch: 9, Index: 272, Loss: 5.1931\n",
      "Epoch: 9, Index: 273, Loss: 0.3357\n",
      "Epoch: 9, Index: 274, Loss: 2.0338\n",
      "Epoch: 9, Index: 275, Loss: 0.5694\n",
      "Epoch: 9, Index: 276, Loss: 7.9625\n",
      "Epoch: 9, Index: 277, Loss: 2.5962\n",
      "Epoch: 9, Index: 278, Loss: 0.5206\n",
      "Epoch: 9, Index: 279, Loss: 0.8964\n",
      "Epoch: 9, Index: 280, Loss: 1.7269\n",
      "Epoch: 9, Index: 281, Loss: 2.5531\n",
      "Epoch: 9, Index: 282, Loss: 2.8214\n",
      "Epoch: 9, Index: 283, Loss: 1.1693\n",
      "Epoch: 9, Index: 284, Loss: 7.0902\n",
      "Epoch: 9, Index: 285, Loss: 3.7658\n",
      "Epoch: 9, Index: 286, Loss: 4.1277\n",
      "Epoch: 9, Index: 287, Loss: 2.3353\n",
      "Epoch: 9, Index: 288, Loss: 1.4626\n",
      "Epoch: 9, Index: 289, Loss: 3.1293\n",
      "Epoch: 9, Index: 290, Loss: 0.0960\n",
      "Epoch: 9, Index: 291, Loss: 1.6632\n",
      "Epoch: 9, Index: 292, Loss: 3.3247\n",
      "Epoch: 9, Index: 293, Loss: 0.8436\n",
      "Epoch: 9, Index: 294, Loss: 0.0635\n",
      "Epoch: 9, Index: 295, Loss: 0.1932\n",
      "Epoch: 9, Index: 296, Loss: 0.5275\n",
      "Epoch: 9, Index: 297, Loss: 0.4379\n",
      "Epoch: 9, Index: 298, Loss: 5.5913\n",
      "Epoch: 9, Index: 299, Loss: 1.4145\n",
      "Epoch: 9, Index: 300, Loss: 0.7199\n",
      "Epoch: 9, Index: 301, Loss: 0.3779\n",
      "Epoch: 9, Index: 302, Loss: 0.1049\n",
      "Epoch: 9, Index: 303, Loss: 0.6350\n",
      "Epoch: 9, Index: 304, Loss: 0.7294\n",
      "Epoch: 9, Index: 305, Loss: 1.2386\n",
      "Epoch: 9, Index: 306, Loss: 1.8794\n",
      "Epoch: 9, Index: 307, Loss: 1.5559\n",
      "Epoch: 9, Index: 308, Loss: 1.1816\n",
      "Epoch: 9, Index: 309, Loss: 0.9689\n",
      "Epoch: 9, Index: 310, Loss: 2.2407\n",
      "Epoch: 9, Index: 311, Loss: 2.2426\n",
      "Epoch: 9, Index: 312, Loss: 0.1703\n",
      "Epoch: 9, Index: 313, Loss: 4.2422\n",
      "Epoch: 9, Index: 314, Loss: 0.8944\n",
      "Epoch: 9, Index: 315, Loss: 3.7645\n",
      "Epoch: 9, Index: 316, Loss: 4.6844\n",
      "Epoch: 9, Index: 317, Loss: 0.7053\n",
      "Epoch: 9, Index: 318, Loss: 1.0875\n",
      "Epoch: 9, Index: 319, Loss: 0.2097\n",
      "Epoch: 9, Index: 320, Loss: 0.3271\n",
      "Epoch: 9, Index: 321, Loss: 0.0069\n",
      "Epoch: 9, Index: 322, Loss: 0.3756\n",
      "Epoch: 9, Index: 323, Loss: 0.0571\n",
      "Epoch: 9, Index: 324, Loss: 3.0533\n",
      "Epoch: 9, Index: 325, Loss: 1.6690\n",
      "Epoch: 9, Index: 326, Loss: 0.3030\n",
      "Epoch: 9, Index: 327, Loss: 2.9411\n",
      "Epoch: 9, Index: 328, Loss: 1.3914\n",
      "Epoch: 9, Index: 329, Loss: 0.0732\n",
      "Epoch: 9, Index: 330, Loss: 2.6528\n",
      "Epoch: 9, Index: 331, Loss: 6.4852\n",
      "Epoch: 9, Index: 332, Loss: 1.5375\n",
      "Epoch: 9, Index: 333, Loss: 0.9655\n",
      "Epoch: 9, Index: 334, Loss: 0.0146\n",
      "Epoch: 9, Index: 335, Loss: 7.6513\n",
      "Epoch: 9, Index: 336, Loss: 0.8326\n",
      "Epoch: 9, Index: 337, Loss: 0.3272\n",
      "Epoch: 9, Index: 338, Loss: 0.2158\n",
      "Epoch: 9, Index: 339, Loss: 0.9121\n",
      "Epoch: 9, Index: 340, Loss: 1.5227\n",
      "Epoch: 9, Index: 341, Loss: 2.9808\n",
      "Epoch: 9, Index: 342, Loss: 0.0095\n",
      "Epoch: 9, Index: 343, Loss: 2.3013\n",
      "Epoch: 9, Index: 344, Loss: 0.1685\n",
      "Epoch: 9, Index: 345, Loss: 2.7894\n",
      "Epoch: 9, Index: 346, Loss: 1.6176\n",
      "Epoch: 9, Index: 347, Loss: 1.5956\n",
      "Epoch: 9, Index: 348, Loss: 1.2333\n",
      "Epoch: 9, Index: 349, Loss: 0.5559\n",
      "Epoch: 9, Index: 350, Loss: 7.6343\n",
      "Epoch: 9, Index: 351, Loss: 1.0968\n",
      "Epoch: 9, Index: 352, Loss: 0.7460\n",
      "Epoch: 9, Index: 353, Loss: 0.4205\n",
      "Epoch: 9, Index: 354, Loss: 2.1908\n",
      "Epoch: 9, Index: 355, Loss: 1.7705\n",
      "Epoch: 9, Index: 356, Loss: 2.8988\n",
      "Epoch: 9, Index: 357, Loss: 0.2869\n",
      "Epoch: 9, Index: 358, Loss: 5.0645\n",
      "Epoch: 9, Index: 359, Loss: 0.6085\n",
      "Epoch: 9, Index: 360, Loss: 0.3448\n",
      "Epoch: 9, Index: 361, Loss: 0.1321\n",
      "Epoch: 9, Index: 362, Loss: 2.3525\n",
      "Epoch: 9, Index: 363, Loss: 2.3623\n",
      "Epoch: 9, Index: 364, Loss: 1.3910\n",
      "Epoch: 9, Index: 365, Loss: 0.1562\n",
      "Epoch: 9, Index: 366, Loss: 3.2382\n",
      "Epoch: 9, Index: 367, Loss: 0.2426\n",
      "Epoch: 9, Index: 368, Loss: 1.8217\n",
      "Epoch: 9, Index: 369, Loss: 3.8516\n",
      "Epoch: 9, Index: 370, Loss: 0.9961\n",
      "Epoch: 9, Index: 371, Loss: 0.4588\n",
      "Epoch: 9, Index: 372, Loss: 2.9627\n",
      "Epoch: 9, Index: 373, Loss: 0.1452\n",
      "Epoch: 9, Index: 374, Loss: 1.3930\n",
      "Epoch: 9, Index: 375, Loss: 1.6866\n",
      "Epoch: 9, Index: 376, Loss: 0.3557\n",
      "Epoch: 9, Index: 377, Loss: 1.5491\n",
      "Epoch: 9, Index: 378, Loss: 0.4835\n",
      "Epoch: 9, Index: 379, Loss: 2.0790\n",
      "Epoch: 9, Index: 380, Loss: 0.7969\n",
      "Epoch: 9, Index: 381, Loss: 0.9697\n",
      "Epoch: 9, Index: 382, Loss: 2.4992\n",
      "Epoch: 9, Index: 383, Loss: 2.9636\n",
      "Epoch: 9, Index: 384, Loss: 0.0770\n",
      "Epoch: 9, Index: 385, Loss: 0.8014\n",
      "Epoch: 9, Index: 386, Loss: 0.5389\n",
      "Epoch: 9, Index: 387, Loss: 5.0712\n",
      "Epoch: 9, Index: 388, Loss: 0.3699\n",
      "Epoch: 9, Index: 389, Loss: 5.6549\n",
      "Epoch: 9, Index: 390, Loss: 0.1485\n",
      "Epoch: 9, Index: 391, Loss: 2.3669\n",
      "Epoch: 9, Index: 392, Loss: 1.5113\n",
      "Epoch: 9, Index: 393, Loss: 2.5379\n",
      "Epoch: 9, Index: 394, Loss: 2.4589\n",
      "Epoch: 9, Index: 395, Loss: 0.7180\n",
      "Epoch: 9, Index: 396, Loss: 1.8567\n",
      "Epoch: 9, Index: 397, Loss: 1.8335\n",
      "Epoch: 9, Index: 398, Loss: 0.8043\n",
      "Epoch: 9, Index: 399, Loss: 0.9178\n",
      "Epoch: 9, Index: 400, Loss: 1.7906\n",
      "Epoch: 9, Index: 401, Loss: 0.1379\n",
      "Epoch: 9, Index: 402, Loss: 0.8000\n",
      "Epoch: 9, Index: 403, Loss: 1.6839\n",
      "Epoch: 9, Index: 404, Loss: 1.1168\n",
      "Epoch: 9, Index: 405, Loss: 4.5621\n",
      "Epoch: 9, Index: 406, Loss: 16.3576\n",
      "Epoch: 9, Index: 407, Loss: 3.5495\n",
      "Epoch: 9, Index: 408, Loss: 1.4460\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0ed3c87be74d5688e3b020b2631319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Index: 0, Loss: 0.6437\n",
      "Epoch: 10, Index: 1, Loss: 1.6022\n",
      "Epoch: 10, Index: 2, Loss: 1.1699\n",
      "Epoch: 10, Index: 3, Loss: 0.9233\n",
      "Epoch: 10, Index: 4, Loss: 0.5122\n",
      "Epoch: 10, Index: 5, Loss: 9.4308\n",
      "Epoch: 10, Index: 6, Loss: 1.2377\n",
      "Epoch: 10, Index: 7, Loss: 1.8238\n",
      "Epoch: 10, Index: 8, Loss: 0.5047\n",
      "Epoch: 10, Index: 9, Loss: 0.4350\n",
      "Epoch: 10, Index: 10, Loss: 0.0196\n",
      "Epoch: 10, Index: 11, Loss: 2.5124\n",
      "Epoch: 10, Index: 12, Loss: 1.9912\n",
      "Epoch: 10, Index: 13, Loss: 0.5743\n",
      "Epoch: 10, Index: 14, Loss: 2.5685\n",
      "Epoch: 10, Index: 15, Loss: 1.2542\n",
      "Epoch: 10, Index: 16, Loss: 1.1349\n",
      "Epoch: 10, Index: 17, Loss: 2.7350\n",
      "Epoch: 10, Index: 18, Loss: 0.3351\n",
      "Epoch: 10, Index: 19, Loss: 3.9334\n",
      "Epoch: 10, Index: 20, Loss: 0.2849\n",
      "Epoch: 10, Index: 21, Loss: 4.4394\n",
      "Epoch: 10, Index: 22, Loss: 1.1393\n",
      "Epoch: 10, Index: 23, Loss: 0.9992\n",
      "Epoch: 10, Index: 24, Loss: 2.2018\n",
      "Epoch: 10, Index: 25, Loss: 2.4848\n",
      "Epoch: 10, Index: 26, Loss: 1.4901\n",
      "Epoch: 10, Index: 27, Loss: 5.7103\n",
      "Epoch: 10, Index: 28, Loss: 1.1040\n",
      "Epoch: 10, Index: 29, Loss: 3.9967\n",
      "Epoch: 10, Index: 30, Loss: 1.1030\n",
      "Epoch: 10, Index: 31, Loss: 0.1722\n",
      "Epoch: 10, Index: 32, Loss: 0.6484\n",
      "Epoch: 10, Index: 33, Loss: 0.1440\n",
      "Epoch: 10, Index: 34, Loss: 0.6626\n",
      "Epoch: 10, Index: 35, Loss: 0.7155\n",
      "Epoch: 10, Index: 36, Loss: 0.6804\n",
      "Epoch: 10, Index: 37, Loss: 1.7434\n",
      "Epoch: 10, Index: 38, Loss: 0.2040\n",
      "Epoch: 10, Index: 39, Loss: 1.1676\n",
      "Epoch: 10, Index: 40, Loss: 0.5542\n",
      "Epoch: 10, Index: 41, Loss: 0.5625\n",
      "Epoch: 10, Index: 42, Loss: 1.2835\n",
      "Epoch: 10, Index: 43, Loss: 1.6761\n",
      "Epoch: 10, Index: 44, Loss: 0.0707\n",
      "Epoch: 10, Index: 45, Loss: 0.8871\n",
      "Epoch: 10, Index: 46, Loss: 2.8885\n",
      "Epoch: 10, Index: 47, Loss: 3.7845\n",
      "Epoch: 10, Index: 48, Loss: 1.5020\n",
      "Epoch: 10, Index: 49, Loss: 1.5900\n",
      "Epoch: 10, Index: 50, Loss: 0.9617\n",
      "Epoch: 10, Index: 51, Loss: 0.1865\n",
      "Epoch: 10, Index: 52, Loss: 1.1418\n",
      "Epoch: 10, Index: 53, Loss: 1.5573\n",
      "Epoch: 10, Index: 54, Loss: 1.2534\n",
      "Epoch: 10, Index: 55, Loss: 0.0062\n",
      "Epoch: 10, Index: 56, Loss: 0.9233\n",
      "Epoch: 10, Index: 57, Loss: 0.2732\n",
      "Epoch: 10, Index: 58, Loss: 0.9014\n",
      "Epoch: 10, Index: 59, Loss: 0.3124\n",
      "Epoch: 10, Index: 60, Loss: 0.1216\n",
      "Epoch: 10, Index: 61, Loss: 0.6049\n",
      "Epoch: 10, Index: 62, Loss: 1.2104\n",
      "Epoch: 10, Index: 63, Loss: 2.0759\n",
      "Epoch: 10, Index: 64, Loss: 1.3791\n",
      "Epoch: 10, Index: 65, Loss: 0.8877\n",
      "Epoch: 10, Index: 66, Loss: 0.8228\n",
      "Epoch: 10, Index: 67, Loss: 0.5111\n",
      "Epoch: 10, Index: 68, Loss: 2.0786\n",
      "Epoch: 10, Index: 69, Loss: 4.2012\n",
      "Epoch: 10, Index: 70, Loss: 4.6200\n",
      "Epoch: 10, Index: 71, Loss: 1.5298\n",
      "Epoch: 10, Index: 72, Loss: 2.9986\n",
      "Epoch: 10, Index: 73, Loss: 0.2028\n",
      "Epoch: 10, Index: 74, Loss: 1.2863\n",
      "Epoch: 10, Index: 75, Loss: 3.8748\n",
      "Epoch: 10, Index: 76, Loss: 7.1182\n",
      "Epoch: 10, Index: 77, Loss: 1.1796\n",
      "Epoch: 10, Index: 78, Loss: 1.9037\n",
      "Epoch: 10, Index: 79, Loss: 1.4772\n",
      "Epoch: 10, Index: 80, Loss: 2.8927\n",
      "Epoch: 10, Index: 81, Loss: 2.9175\n",
      "Epoch: 10, Index: 82, Loss: 1.2920\n",
      "Epoch: 10, Index: 83, Loss: 6.2517\n",
      "Epoch: 10, Index: 84, Loss: 2.1984\n",
      "Epoch: 10, Index: 85, Loss: 1.1398\n",
      "Epoch: 10, Index: 86, Loss: 0.9072\n",
      "Epoch: 10, Index: 87, Loss: 2.5975\n",
      "Epoch: 10, Index: 88, Loss: 0.0331\n",
      "Epoch: 10, Index: 89, Loss: 0.1515\n",
      "Epoch: 10, Index: 90, Loss: 0.3594\n",
      "Epoch: 10, Index: 91, Loss: 0.5718\n",
      "Epoch: 10, Index: 92, Loss: 1.0637\n",
      "Epoch: 10, Index: 93, Loss: 0.6389\n",
      "Epoch: 10, Index: 94, Loss: 0.5682\n",
      "Epoch: 10, Index: 95, Loss: 2.1282\n",
      "Epoch: 10, Index: 96, Loss: 3.9404\n",
      "Epoch: 10, Index: 97, Loss: 10.5353\n",
      "Epoch: 10, Index: 98, Loss: 0.7419\n",
      "Epoch: 10, Index: 99, Loss: 3.1503\n",
      "Epoch: 10, Index: 100, Loss: 0.1174\n",
      "Epoch: 10, Index: 101, Loss: 0.1509\n",
      "Epoch: 10, Index: 102, Loss: 1.9158\n",
      "Epoch: 10, Index: 103, Loss: 2.2993\n",
      "Epoch: 10, Index: 104, Loss: 2.2787\n",
      "Epoch: 10, Index: 105, Loss: 1.4561\n",
      "Epoch: 10, Index: 106, Loss: 1.4531\n",
      "Epoch: 10, Index: 107, Loss: 1.2080\n",
      "Epoch: 10, Index: 108, Loss: 1.5344\n",
      "Epoch: 10, Index: 109, Loss: 0.8435\n",
      "Epoch: 10, Index: 110, Loss: 0.7446\n",
      "Epoch: 10, Index: 111, Loss: 1.1413\n",
      "Epoch: 10, Index: 112, Loss: 0.7085\n",
      "Epoch: 10, Index: 113, Loss: 1.4371\n",
      "Epoch: 10, Index: 114, Loss: 1.6112\n",
      "Epoch: 10, Index: 115, Loss: 0.0949\n",
      "Epoch: 10, Index: 116, Loss: 0.9014\n",
      "Epoch: 10, Index: 117, Loss: 0.3722\n",
      "Epoch: 10, Index: 118, Loss: 1.2388\n",
      "Epoch: 10, Index: 119, Loss: 2.4073\n",
      "Epoch: 10, Index: 120, Loss: 0.4083\n",
      "Epoch: 10, Index: 121, Loss: 1.5326\n",
      "Epoch: 10, Index: 122, Loss: 1.6870\n",
      "Epoch: 10, Index: 123, Loss: 2.0709\n",
      "Epoch: 10, Index: 124, Loss: 2.0570\n",
      "Epoch: 10, Index: 125, Loss: 0.4977\n",
      "Epoch: 10, Index: 126, Loss: 0.6557\n",
      "Epoch: 10, Index: 127, Loss: 0.8918\n",
      "Epoch: 10, Index: 128, Loss: 5.0468\n",
      "Epoch: 10, Index: 129, Loss: 4.5999\n",
      "Epoch: 10, Index: 130, Loss: 2.3391\n",
      "Epoch: 10, Index: 131, Loss: 2.1699\n",
      "Epoch: 10, Index: 132, Loss: 1.0728\n",
      "Epoch: 10, Index: 133, Loss: 0.9437\n",
      "Epoch: 10, Index: 134, Loss: 4.0079\n",
      "Epoch: 10, Index: 135, Loss: 0.8211\n",
      "Epoch: 10, Index: 136, Loss: 0.1986\n",
      "Epoch: 10, Index: 137, Loss: 0.8148\n",
      "Epoch: 10, Index: 138, Loss: 0.4244\n",
      "Epoch: 10, Index: 139, Loss: 4.5723\n",
      "Epoch: 10, Index: 140, Loss: 3.1887\n",
      "Epoch: 10, Index: 141, Loss: 4.9157\n",
      "Epoch: 10, Index: 142, Loss: 4.2355\n",
      "Epoch: 10, Index: 143, Loss: 2.7496\n",
      "Epoch: 10, Index: 144, Loss: 0.1802\n",
      "Epoch: 10, Index: 145, Loss: 4.9641\n",
      "Epoch: 10, Index: 146, Loss: 7.2267\n",
      "Epoch: 10, Index: 147, Loss: 3.5936\n",
      "Epoch: 10, Index: 148, Loss: 1.4957\n",
      "Epoch: 10, Index: 149, Loss: 4.1191\n",
      "Epoch: 10, Index: 150, Loss: 0.2898\n",
      "Epoch: 10, Index: 151, Loss: 4.4634\n",
      "Epoch: 10, Index: 152, Loss: 0.3671\n",
      "Epoch: 10, Index: 153, Loss: 2.3627\n",
      "Epoch: 10, Index: 154, Loss: 1.6841\n",
      "Epoch: 10, Index: 155, Loss: 0.3643\n",
      "Epoch: 10, Index: 156, Loss: 0.0522\n",
      "Epoch: 10, Index: 157, Loss: 1.1498\n",
      "Epoch: 10, Index: 158, Loss: 4.5296\n",
      "Epoch: 10, Index: 159, Loss: 2.1294\n",
      "Epoch: 10, Index: 160, Loss: 5.3127\n",
      "Epoch: 10, Index: 161, Loss: 0.5532\n",
      "Epoch: 10, Index: 162, Loss: 1.6145\n",
      "Epoch: 10, Index: 163, Loss: 0.2763\n",
      "Epoch: 10, Index: 164, Loss: 0.0088\n",
      "Epoch: 10, Index: 165, Loss: 4.1993\n",
      "Epoch: 10, Index: 166, Loss: 1.2320\n",
      "Epoch: 10, Index: 167, Loss: 3.6987\n",
      "Epoch: 10, Index: 168, Loss: 0.1910\n",
      "Epoch: 10, Index: 169, Loss: 2.1685\n",
      "Epoch: 10, Index: 170, Loss: 4.7288\n",
      "Epoch: 10, Index: 171, Loss: 4.4376\n",
      "Epoch: 10, Index: 172, Loss: 4.4631\n",
      "Epoch: 10, Index: 173, Loss: 1.0840\n",
      "Epoch: 10, Index: 174, Loss: 5.0581\n",
      "Epoch: 10, Index: 175, Loss: 2.8045\n",
      "Epoch: 10, Index: 176, Loss: 1.7844\n",
      "Epoch: 10, Index: 177, Loss: 1.3053\n",
      "Epoch: 10, Index: 178, Loss: 1.0303\n",
      "Epoch: 10, Index: 179, Loss: 2.4067\n",
      "Epoch: 10, Index: 180, Loss: 7.6477\n",
      "Epoch: 10, Index: 181, Loss: 1.6373\n",
      "Epoch: 10, Index: 182, Loss: 3.0014\n",
      "Epoch: 10, Index: 183, Loss: 2.1856\n",
      "Epoch: 10, Index: 184, Loss: 3.7574\n",
      "Epoch: 10, Index: 185, Loss: 0.6897\n",
      "Epoch: 10, Index: 186, Loss: 0.4294\n",
      "Epoch: 10, Index: 187, Loss: 1.5026\n",
      "Epoch: 10, Index: 188, Loss: 0.8217\n",
      "Epoch: 10, Index: 189, Loss: 3.6078\n",
      "Epoch: 10, Index: 190, Loss: 0.6125\n",
      "Epoch: 10, Index: 191, Loss: 0.0968\n",
      "Epoch: 10, Index: 192, Loss: 0.7765\n",
      "Epoch: 10, Index: 193, Loss: 0.2612\n",
      "Epoch: 10, Index: 194, Loss: 0.0010\n",
      "Epoch: 10, Index: 195, Loss: 0.8799\n",
      "Epoch: 10, Index: 196, Loss: 0.6141\n",
      "Epoch: 10, Index: 197, Loss: 2.5557\n",
      "Epoch: 10, Index: 198, Loss: 1.6329\n",
      "Epoch: 10, Index: 199, Loss: 1.5581\n",
      "Epoch: 10, Index: 200, Loss: 1.2298\n",
      "Epoch: 10, Index: 201, Loss: 0.7856\n",
      "Epoch: 10, Index: 202, Loss: 0.5390\n",
      "Epoch: 10, Index: 203, Loss: 1.9386\n",
      "Epoch: 10, Index: 204, Loss: 0.0355\n",
      "Epoch: 10, Index: 205, Loss: 0.7656\n",
      "Epoch: 10, Index: 206, Loss: 0.2476\n",
      "Epoch: 10, Index: 207, Loss: 17.9858\n",
      "Epoch: 10, Index: 208, Loss: 3.1159\n",
      "Epoch: 10, Index: 209, Loss: 0.6367\n",
      "Epoch: 10, Index: 210, Loss: 0.7788\n",
      "Epoch: 10, Index: 211, Loss: 4.0574\n",
      "Epoch: 10, Index: 212, Loss: 1.9017\n",
      "Epoch: 10, Index: 213, Loss: 1.3337\n",
      "Epoch: 10, Index: 214, Loss: 3.8731\n",
      "Epoch: 10, Index: 215, Loss: 0.4391\n",
      "Epoch: 10, Index: 216, Loss: 0.2931\n",
      "Epoch: 10, Index: 217, Loss: 0.6603\n",
      "Epoch: 10, Index: 218, Loss: 1.7560\n",
      "Epoch: 10, Index: 219, Loss: 3.5683\n",
      "Epoch: 10, Index: 220, Loss: 0.3423\n",
      "Epoch: 10, Index: 221, Loss: 2.8045\n",
      "Epoch: 10, Index: 222, Loss: 1.4860\n",
      "Epoch: 10, Index: 223, Loss: 1.4202\n",
      "Epoch: 10, Index: 224, Loss: 0.0718\n",
      "Epoch: 10, Index: 225, Loss: 0.2539\n",
      "Epoch: 10, Index: 226, Loss: 3.4299\n",
      "Epoch: 10, Index: 227, Loss: 0.5052\n",
      "Epoch: 10, Index: 228, Loss: 2.1348\n",
      "Epoch: 10, Index: 229, Loss: 0.5647\n",
      "Epoch: 10, Index: 230, Loss: 1.0744\n",
      "Epoch: 10, Index: 231, Loss: 4.6848\n",
      "Epoch: 10, Index: 232, Loss: 1.5405\n",
      "Epoch: 10, Index: 233, Loss: 1.2686\n",
      "Epoch: 10, Index: 234, Loss: 0.6681\n",
      "Epoch: 10, Index: 235, Loss: 0.8091\n",
      "Epoch: 10, Index: 236, Loss: 1.0369\n",
      "Epoch: 10, Index: 237, Loss: 0.1305\n",
      "Epoch: 10, Index: 238, Loss: 0.1652\n",
      "Epoch: 10, Index: 239, Loss: 6.5110\n",
      "Epoch: 10, Index: 240, Loss: 8.4584\n",
      "Epoch: 10, Index: 241, Loss: 0.9329\n",
      "Epoch: 10, Index: 242, Loss: 3.0984\n",
      "Epoch: 10, Index: 243, Loss: 0.8099\n",
      "Epoch: 10, Index: 244, Loss: 2.2130\n",
      "Epoch: 10, Index: 245, Loss: 0.3857\n",
      "Epoch: 10, Index: 246, Loss: 1.7350\n",
      "Epoch: 10, Index: 247, Loss: 2.3383\n",
      "Epoch: 10, Index: 248, Loss: 0.7343\n",
      "Epoch: 10, Index: 249, Loss: 2.5473\n",
      "Epoch: 10, Index: 250, Loss: 0.8116\n",
      "Epoch: 10, Index: 251, Loss: 0.4490\n",
      "Epoch: 10, Index: 252, Loss: 0.3925\n",
      "Epoch: 10, Index: 253, Loss: 0.2180\n",
      "Epoch: 10, Index: 254, Loss: 0.5816\n",
      "Epoch: 10, Index: 255, Loss: 3.1009\n",
      "Epoch: 10, Index: 256, Loss: 2.1294\n",
      "Epoch: 10, Index: 257, Loss: 0.0439\n",
      "Epoch: 10, Index: 258, Loss: 1.4648\n",
      "Epoch: 10, Index: 259, Loss: 3.6247\n",
      "Epoch: 10, Index: 260, Loss: 4.2089\n",
      "Epoch: 10, Index: 261, Loss: 4.3015\n",
      "Epoch: 10, Index: 262, Loss: 3.8276\n",
      "Epoch: 10, Index: 263, Loss: 2.6776\n",
      "Epoch: 10, Index: 264, Loss: 2.2979\n",
      "Epoch: 10, Index: 265, Loss: 2.1118\n",
      "Epoch: 10, Index: 266, Loss: 0.3320\n",
      "Epoch: 10, Index: 267, Loss: 0.4115\n",
      "Epoch: 10, Index: 268, Loss: 0.8481\n",
      "Epoch: 10, Index: 269, Loss: 0.6753\n",
      "Epoch: 10, Index: 270, Loss: 0.1290\n",
      "Epoch: 10, Index: 271, Loss: 1.5682\n",
      "Epoch: 10, Index: 272, Loss: 5.9978\n",
      "Epoch: 10, Index: 273, Loss: 1.0028\n",
      "Epoch: 10, Index: 274, Loss: 0.1436\n",
      "Epoch: 10, Index: 275, Loss: 1.0573\n",
      "Epoch: 10, Index: 276, Loss: 1.9083\n",
      "Epoch: 10, Index: 277, Loss: 1.8078\n",
      "Epoch: 10, Index: 278, Loss: 0.6858\n",
      "Epoch: 10, Index: 279, Loss: 2.7955\n",
      "Epoch: 10, Index: 280, Loss: 1.6453\n",
      "Epoch: 10, Index: 281, Loss: 7.1821\n",
      "Epoch: 10, Index: 282, Loss: 0.6351\n",
      "Epoch: 10, Index: 283, Loss: 0.8010\n",
      "Epoch: 10, Index: 284, Loss: 0.3535\n",
      "Epoch: 10, Index: 285, Loss: 1.1000\n",
      "Epoch: 10, Index: 286, Loss: 1.8627\n",
      "Epoch: 10, Index: 287, Loss: 3.4871\n",
      "Epoch: 10, Index: 288, Loss: 0.8148\n",
      "Epoch: 10, Index: 289, Loss: 1.0414\n",
      "Epoch: 10, Index: 290, Loss: 0.1017\n",
      "Epoch: 10, Index: 291, Loss: 2.7583\n",
      "Epoch: 10, Index: 292, Loss: 2.1522\n",
      "Epoch: 10, Index: 293, Loss: 0.0573\n",
      "Epoch: 10, Index: 294, Loss: 1.5929\n",
      "Epoch: 10, Index: 295, Loss: 0.3392\n",
      "Epoch: 10, Index: 296, Loss: 4.8607\n",
      "Epoch: 10, Index: 297, Loss: 1.0823\n",
      "Epoch: 10, Index: 298, Loss: 0.0313\n",
      "Epoch: 10, Index: 299, Loss: 3.6774\n",
      "Epoch: 10, Index: 300, Loss: 0.1909\n",
      "Epoch: 10, Index: 301, Loss: 0.6484\n",
      "Epoch: 10, Index: 302, Loss: 1.2525\n",
      "Epoch: 10, Index: 303, Loss: 3.0305\n",
      "Epoch: 10, Index: 304, Loss: 1.2684\n",
      "Epoch: 10, Index: 305, Loss: 1.6443\n",
      "Epoch: 10, Index: 306, Loss: 3.2999\n",
      "Epoch: 10, Index: 307, Loss: 2.4080\n",
      "Epoch: 10, Index: 308, Loss: 0.3495\n",
      "Epoch: 10, Index: 309, Loss: 0.0114\n",
      "Epoch: 10, Index: 310, Loss: 0.4524\n",
      "Epoch: 10, Index: 311, Loss: 0.8247\n",
      "Epoch: 10, Index: 312, Loss: 0.7938\n",
      "Epoch: 10, Index: 313, Loss: 0.4458\n",
      "Epoch: 10, Index: 314, Loss: 1.4479\n",
      "Epoch: 10, Index: 315, Loss: 5.2942\n",
      "Epoch: 10, Index: 316, Loss: 0.2384\n",
      "Epoch: 10, Index: 317, Loss: 0.1539\n",
      "Epoch: 10, Index: 318, Loss: 2.3517\n",
      "Epoch: 10, Index: 319, Loss: 1.4757\n",
      "Epoch: 10, Index: 320, Loss: 3.1449\n",
      "Epoch: 10, Index: 321, Loss: 13.4151\n",
      "Epoch: 10, Index: 322, Loss: 0.7471\n",
      "Epoch: 10, Index: 323, Loss: 2.6660\n",
      "Epoch: 10, Index: 324, Loss: 4.9220\n",
      "Epoch: 10, Index: 325, Loss: 2.1941\n",
      "Epoch: 10, Index: 326, Loss: 0.4996\n",
      "Epoch: 10, Index: 327, Loss: 7.8535\n",
      "Epoch: 10, Index: 328, Loss: 4.4249\n",
      "Epoch: 10, Index: 329, Loss: 0.6333\n",
      "Epoch: 10, Index: 330, Loss: 0.2737\n",
      "Epoch: 10, Index: 331, Loss: 2.2072\n",
      "Epoch: 10, Index: 332, Loss: 1.2187\n",
      "Epoch: 10, Index: 333, Loss: 1.9038\n",
      "Epoch: 10, Index: 334, Loss: 2.7965\n",
      "Epoch: 10, Index: 335, Loss: 0.5947\n",
      "Epoch: 10, Index: 336, Loss: 1.4122\n",
      "Epoch: 10, Index: 337, Loss: 0.0108\n",
      "Epoch: 10, Index: 338, Loss: 0.6519\n",
      "Epoch: 10, Index: 339, Loss: 1.3407\n",
      "Epoch: 10, Index: 340, Loss: 1.7743\n",
      "Epoch: 10, Index: 341, Loss: 0.2855\n",
      "Epoch: 10, Index: 342, Loss: 2.5444\n",
      "Epoch: 10, Index: 343, Loss: 0.1000\n",
      "Epoch: 10, Index: 344, Loss: 0.1305\n",
      "Epoch: 10, Index: 345, Loss: 2.2179\n",
      "Epoch: 10, Index: 346, Loss: 1.8591\n",
      "Epoch: 10, Index: 347, Loss: 4.7355\n",
      "Epoch: 10, Index: 348, Loss: 0.2658\n",
      "Epoch: 10, Index: 349, Loss: 1.5798\n",
      "Epoch: 10, Index: 350, Loss: 0.6773\n",
      "Epoch: 10, Index: 351, Loss: 1.8808\n",
      "Epoch: 10, Index: 352, Loss: 0.5377\n",
      "Epoch: 10, Index: 353, Loss: 0.0313\n",
      "Epoch: 10, Index: 354, Loss: 0.8810\n",
      "Epoch: 10, Index: 355, Loss: 0.3884\n",
      "Epoch: 10, Index: 356, Loss: 1.8731\n",
      "Epoch: 10, Index: 357, Loss: 0.1738\n",
      "Epoch: 10, Index: 358, Loss: 0.2691\n",
      "Epoch: 10, Index: 359, Loss: 0.7441\n",
      "Epoch: 10, Index: 360, Loss: 0.2476\n",
      "Epoch: 10, Index: 361, Loss: 1.3318\n",
      "Epoch: 10, Index: 362, Loss: 0.9087\n",
      "Epoch: 10, Index: 363, Loss: 0.0591\n",
      "Epoch: 10, Index: 364, Loss: 2.2302\n",
      "Epoch: 10, Index: 365, Loss: 1.6021\n",
      "Epoch: 10, Index: 366, Loss: 1.3028\n",
      "Epoch: 10, Index: 367, Loss: 0.0143\n",
      "Epoch: 10, Index: 368, Loss: 4.9656\n",
      "Epoch: 10, Index: 369, Loss: 1.9820\n",
      "Epoch: 10, Index: 370, Loss: 0.8891\n",
      "Epoch: 10, Index: 371, Loss: 1.3546\n",
      "Epoch: 10, Index: 372, Loss: 0.0869\n",
      "Epoch: 10, Index: 373, Loss: 4.1917\n",
      "Epoch: 10, Index: 374, Loss: 6.6485\n",
      "Epoch: 10, Index: 375, Loss: 0.6723\n",
      "Epoch: 10, Index: 376, Loss: 2.1736\n",
      "Epoch: 10, Index: 377, Loss: 2.5440\n",
      "Epoch: 10, Index: 378, Loss: 0.6470\n",
      "Epoch: 10, Index: 379, Loss: 1.5247\n",
      "Epoch: 10, Index: 380, Loss: 2.2979\n",
      "Epoch: 10, Index: 381, Loss: 0.3412\n",
      "Epoch: 10, Index: 382, Loss: 0.1413\n",
      "Epoch: 10, Index: 383, Loss: 1.4026\n",
      "Epoch: 10, Index: 384, Loss: 10.0532\n",
      "Epoch: 10, Index: 385, Loss: 1.7241\n",
      "Epoch: 10, Index: 386, Loss: 12.0383\n",
      "Epoch: 10, Index: 387, Loss: 1.0418\n",
      "Epoch: 10, Index: 388, Loss: 0.7144\n",
      "Epoch: 10, Index: 389, Loss: 0.7621\n",
      "Epoch: 10, Index: 390, Loss: 0.0963\n",
      "Epoch: 10, Index: 391, Loss: 7.2708\n",
      "Epoch: 10, Index: 392, Loss: 1.2635\n",
      "Epoch: 10, Index: 393, Loss: 0.4205\n",
      "Epoch: 10, Index: 394, Loss: 1.7193\n",
      "Epoch: 10, Index: 395, Loss: 0.6818\n",
      "Epoch: 10, Index: 396, Loss: 1.3077\n",
      "Epoch: 10, Index: 397, Loss: 1.9973\n",
      "Epoch: 10, Index: 398, Loss: 0.5054\n",
      "Epoch: 10, Index: 399, Loss: 1.5640\n",
      "Epoch: 10, Index: 400, Loss: 0.0938\n",
      "Epoch: 10, Index: 401, Loss: 2.7693\n",
      "Epoch: 10, Index: 402, Loss: 1.4422\n",
      "Epoch: 10, Index: 403, Loss: 0.1934\n",
      "Epoch: 10, Index: 404, Loss: 1.6892\n",
      "Epoch: 10, Index: 405, Loss: 1.6243\n",
      "Epoch: 10, Index: 406, Loss: 0.8581\n",
      "Epoch: 10, Index: 407, Loss: 0.1234\n",
      "Epoch: 10, Index: 408, Loss: 2.0330\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56309cfc31e42d0a1f67aa45f5a1af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Index: 0, Loss: 0.7388\n",
      "Epoch: 11, Index: 1, Loss: 2.1114\n",
      "Epoch: 11, Index: 2, Loss: 0.0263\n",
      "Epoch: 11, Index: 3, Loss: 3.1289\n",
      "Epoch: 11, Index: 4, Loss: 11.0486\n",
      "Epoch: 11, Index: 5, Loss: 2.6320\n",
      "Epoch: 11, Index: 6, Loss: 0.9381\n",
      "Epoch: 11, Index: 7, Loss: 0.0400\n",
      "Epoch: 11, Index: 8, Loss: 0.3307\n",
      "Epoch: 11, Index: 9, Loss: 0.5817\n",
      "Epoch: 11, Index: 10, Loss: 0.0860\n",
      "Epoch: 11, Index: 11, Loss: 1.4366\n",
      "Epoch: 11, Index: 12, Loss: 0.1685\n",
      "Epoch: 11, Index: 13, Loss: 0.3660\n",
      "Epoch: 11, Index: 14, Loss: 2.1806\n",
      "Epoch: 11, Index: 15, Loss: 0.5217\n",
      "Epoch: 11, Index: 16, Loss: 1.7169\n",
      "Epoch: 11, Index: 17, Loss: 3.7946\n",
      "Epoch: 11, Index: 18, Loss: 2.8523\n",
      "Epoch: 11, Index: 19, Loss: 0.1303\n",
      "Epoch: 11, Index: 20, Loss: 4.3154\n",
      "Epoch: 11, Index: 21, Loss: 0.6838\n",
      "Epoch: 11, Index: 22, Loss: 0.1995\n",
      "Epoch: 11, Index: 23, Loss: 0.8409\n",
      "Epoch: 11, Index: 24, Loss: 2.6730\n",
      "Epoch: 11, Index: 25, Loss: 1.4854\n",
      "Epoch: 11, Index: 26, Loss: 1.5910\n",
      "Epoch: 11, Index: 27, Loss: 1.7466\n",
      "Epoch: 11, Index: 28, Loss: 0.7979\n",
      "Epoch: 11, Index: 29, Loss: 0.4099\n",
      "Epoch: 11, Index: 30, Loss: 0.8253\n",
      "Epoch: 11, Index: 31, Loss: 4.1137\n",
      "Epoch: 11, Index: 32, Loss: 0.9537\n",
      "Epoch: 11, Index: 33, Loss: 3.4775\n",
      "Epoch: 11, Index: 34, Loss: 0.1755\n",
      "Epoch: 11, Index: 35, Loss: 1.1016\n",
      "Epoch: 11, Index: 36, Loss: 2.7305\n",
      "Epoch: 11, Index: 37, Loss: 2.2109\n",
      "Epoch: 11, Index: 38, Loss: 0.1844\n",
      "Epoch: 11, Index: 39, Loss: 0.7434\n",
      "Epoch: 11, Index: 40, Loss: 1.6081\n",
      "Epoch: 11, Index: 41, Loss: 9.5381\n",
      "Epoch: 11, Index: 42, Loss: 3.2073\n",
      "Epoch: 11, Index: 43, Loss: 1.7198\n",
      "Epoch: 11, Index: 44, Loss: 4.7081\n",
      "Epoch: 11, Index: 45, Loss: 0.3495\n",
      "Epoch: 11, Index: 46, Loss: 2.9295\n",
      "Epoch: 11, Index: 47, Loss: 0.0897\n",
      "Epoch: 11, Index: 48, Loss: 1.0591\n",
      "Epoch: 11, Index: 49, Loss: 0.2979\n",
      "Epoch: 11, Index: 50, Loss: 2.2612\n",
      "Epoch: 11, Index: 51, Loss: 1.5368\n",
      "Epoch: 11, Index: 52, Loss: 1.1513\n",
      "Epoch: 11, Index: 53, Loss: 0.2045\n",
      "Epoch: 11, Index: 54, Loss: 3.9727\n",
      "Epoch: 11, Index: 55, Loss: 0.7506\n",
      "Epoch: 11, Index: 56, Loss: 0.7818\n",
      "Epoch: 11, Index: 57, Loss: 5.4977\n",
      "Epoch: 11, Index: 58, Loss: 0.1043\n",
      "Epoch: 11, Index: 59, Loss: 0.7348\n",
      "Epoch: 11, Index: 60, Loss: 0.9102\n",
      "Epoch: 11, Index: 61, Loss: 0.2832\n",
      "Epoch: 11, Index: 62, Loss: 0.2992\n",
      "Epoch: 11, Index: 63, Loss: 0.1511\n",
      "Epoch: 11, Index: 64, Loss: 1.0452\n",
      "Epoch: 11, Index: 65, Loss: 0.1208\n",
      "Epoch: 11, Index: 66, Loss: 0.0256\n",
      "Epoch: 11, Index: 67, Loss: 1.0919\n",
      "Epoch: 11, Index: 68, Loss: 0.0298\n",
      "Epoch: 11, Index: 69, Loss: 1.9694\n",
      "Epoch: 11, Index: 70, Loss: 0.3310\n",
      "Epoch: 11, Index: 71, Loss: 0.1227\n",
      "Epoch: 11, Index: 72, Loss: 8.7096\n",
      "Epoch: 11, Index: 73, Loss: 1.1371\n",
      "Epoch: 11, Index: 74, Loss: 2.4508\n",
      "Epoch: 11, Index: 75, Loss: 1.4145\n",
      "Epoch: 11, Index: 76, Loss: 0.6039\n",
      "Epoch: 11, Index: 77, Loss: 0.5504\n",
      "Epoch: 11, Index: 78, Loss: 0.2569\n",
      "Epoch: 11, Index: 79, Loss: 4.2594\n",
      "Epoch: 11, Index: 80, Loss: 0.5792\n",
      "Epoch: 11, Index: 81, Loss: 0.6956\n",
      "Epoch: 11, Index: 82, Loss: 1.5868\n",
      "Epoch: 11, Index: 83, Loss: 2.3619\n",
      "Epoch: 11, Index: 84, Loss: 1.2193\n",
      "Epoch: 11, Index: 85, Loss: 1.1456\n",
      "Epoch: 11, Index: 86, Loss: 1.0206\n",
      "Epoch: 11, Index: 87, Loss: 1.5399\n",
      "Epoch: 11, Index: 88, Loss: 1.6187\n",
      "Epoch: 11, Index: 89, Loss: 1.3188\n",
      "Epoch: 11, Index: 90, Loss: 1.5894\n",
      "Epoch: 11, Index: 91, Loss: 0.0492\n",
      "Epoch: 11, Index: 92, Loss: 1.8714\n",
      "Epoch: 11, Index: 93, Loss: 1.3543\n",
      "Epoch: 11, Index: 94, Loss: 0.4896\n",
      "Epoch: 11, Index: 95, Loss: 15.7231\n",
      "Epoch: 11, Index: 96, Loss: 2.8686\n",
      "Epoch: 11, Index: 97, Loss: 0.5871\n",
      "Epoch: 11, Index: 98, Loss: 2.1209\n",
      "Epoch: 11, Index: 99, Loss: 0.4743\n",
      "Epoch: 11, Index: 100, Loss: 1.1744\n",
      "Epoch: 11, Index: 101, Loss: 0.0298\n",
      "Epoch: 11, Index: 102, Loss: 3.0135\n",
      "Epoch: 11, Index: 103, Loss: 0.4743\n",
      "Epoch: 11, Index: 104, Loss: 0.3896\n",
      "Epoch: 11, Index: 105, Loss: 0.1195\n",
      "Epoch: 11, Index: 106, Loss: 2.1651\n",
      "Epoch: 11, Index: 107, Loss: 3.4331\n",
      "Epoch: 11, Index: 108, Loss: 1.4848\n",
      "Epoch: 11, Index: 109, Loss: 1.6057\n",
      "Epoch: 11, Index: 110, Loss: 0.1213\n",
      "Epoch: 11, Index: 111, Loss: 1.4588\n",
      "Epoch: 11, Index: 112, Loss: 0.7576\n",
      "Epoch: 11, Index: 113, Loss: 3.0228\n",
      "Epoch: 11, Index: 114, Loss: 0.7334\n",
      "Epoch: 11, Index: 115, Loss: 2.2136\n",
      "Epoch: 11, Index: 116, Loss: 2.1412\n",
      "Epoch: 11, Index: 117, Loss: 2.1774\n",
      "Epoch: 11, Index: 118, Loss: 4.1177\n",
      "Epoch: 11, Index: 119, Loss: 0.7179\n",
      "Epoch: 11, Index: 120, Loss: 0.2832\n",
      "Epoch: 11, Index: 121, Loss: 1.9049\n",
      "Epoch: 11, Index: 122, Loss: 0.5799\n",
      "Epoch: 11, Index: 123, Loss: 1.1138\n",
      "Epoch: 11, Index: 124, Loss: 0.4283\n",
      "Epoch: 11, Index: 125, Loss: 0.9190\n",
      "Epoch: 11, Index: 126, Loss: 2.9964\n",
      "Epoch: 11, Index: 127, Loss: 0.5499\n",
      "Epoch: 11, Index: 128, Loss: 0.4076\n",
      "Epoch: 11, Index: 129, Loss: 2.4490\n",
      "Epoch: 11, Index: 130, Loss: 2.6661\n",
      "Epoch: 11, Index: 131, Loss: 0.9775\n",
      "Epoch: 11, Index: 132, Loss: 0.5874\n",
      "Epoch: 11, Index: 133, Loss: 3.6567\n",
      "Epoch: 11, Index: 134, Loss: 1.9523\n",
      "Epoch: 11, Index: 135, Loss: 0.4773\n",
      "Epoch: 11, Index: 136, Loss: 2.4843\n",
      "Epoch: 11, Index: 137, Loss: 1.3597\n",
      "Epoch: 11, Index: 138, Loss: 0.8648\n",
      "Epoch: 11, Index: 139, Loss: 0.8887\n",
      "Epoch: 11, Index: 140, Loss: 0.0806\n",
      "Epoch: 11, Index: 141, Loss: 2.1003\n",
      "Epoch: 11, Index: 142, Loss: 0.1321\n",
      "Epoch: 11, Index: 143, Loss: 0.3961\n",
      "Epoch: 11, Index: 144, Loss: 1.6747\n",
      "Epoch: 11, Index: 145, Loss: 0.5440\n",
      "Epoch: 11, Index: 146, Loss: 0.8611\n",
      "Epoch: 11, Index: 147, Loss: 6.0033\n",
      "Epoch: 11, Index: 148, Loss: 2.1684\n",
      "Epoch: 11, Index: 149, Loss: 1.0747\n",
      "Epoch: 11, Index: 150, Loss: 3.9123\n",
      "Epoch: 11, Index: 151, Loss: 0.8309\n",
      "Epoch: 11, Index: 152, Loss: 0.0106\n",
      "Epoch: 11, Index: 153, Loss: 2.0229\n",
      "Epoch: 11, Index: 154, Loss: 1.6393\n",
      "Epoch: 11, Index: 155, Loss: 0.9395\n",
      "Epoch: 11, Index: 156, Loss: 2.6560\n",
      "Epoch: 11, Index: 157, Loss: 0.4361\n",
      "Epoch: 11, Index: 158, Loss: 6.3685\n",
      "Epoch: 11, Index: 159, Loss: 0.0321\n",
      "Epoch: 11, Index: 160, Loss: 1.3524\n",
      "Epoch: 11, Index: 161, Loss: 1.5130\n",
      "Epoch: 11, Index: 162, Loss: 4.5053\n",
      "Epoch: 11, Index: 163, Loss: 4.0692\n",
      "Epoch: 11, Index: 164, Loss: 4.7563\n",
      "Epoch: 11, Index: 165, Loss: 3.3294\n",
      "Epoch: 11, Index: 166, Loss: 1.1008\n",
      "Epoch: 11, Index: 167, Loss: 0.4704\n",
      "Epoch: 11, Index: 168, Loss: 1.0227\n",
      "Epoch: 11, Index: 169, Loss: 0.6938\n",
      "Epoch: 11, Index: 170, Loss: 0.9062\n",
      "Epoch: 11, Index: 171, Loss: 3.5213\n",
      "Epoch: 11, Index: 172, Loss: 3.7925\n",
      "Epoch: 11, Index: 173, Loss: 0.6329\n",
      "Epoch: 11, Index: 174, Loss: 1.2769\n",
      "Epoch: 11, Index: 175, Loss: 0.4728\n",
      "Epoch: 11, Index: 176, Loss: 0.1031\n",
      "Epoch: 11, Index: 177, Loss: 1.9757\n",
      "Epoch: 11, Index: 178, Loss: 0.2234\n",
      "Epoch: 11, Index: 179, Loss: 0.3647\n",
      "Epoch: 11, Index: 180, Loss: 5.6299\n",
      "Epoch: 11, Index: 181, Loss: 0.5135\n",
      "Epoch: 11, Index: 182, Loss: 5.1907\n",
      "Epoch: 11, Index: 183, Loss: 0.6026\n",
      "Epoch: 11, Index: 184, Loss: 1.6037\n",
      "Epoch: 11, Index: 185, Loss: 3.1277\n",
      "Epoch: 11, Index: 186, Loss: 1.9574\n",
      "Epoch: 11, Index: 187, Loss: 4.9402\n",
      "Epoch: 11, Index: 188, Loss: 2.8452\n",
      "Epoch: 11, Index: 189, Loss: 3.2063\n",
      "Epoch: 11, Index: 190, Loss: 2.8296\n",
      "Epoch: 11, Index: 191, Loss: 3.4460\n",
      "Epoch: 11, Index: 192, Loss: 2.3792\n",
      "Epoch: 11, Index: 193, Loss: 3.6110\n",
      "Epoch: 11, Index: 194, Loss: 1.4885\n",
      "Epoch: 11, Index: 195, Loss: 0.5727\n",
      "Epoch: 11, Index: 196, Loss: 4.2858\n",
      "Epoch: 11, Index: 197, Loss: 2.0570\n",
      "Epoch: 11, Index: 198, Loss: 1.9694\n",
      "Epoch: 11, Index: 199, Loss: 2.5667\n",
      "Epoch: 11, Index: 200, Loss: 2.0156\n",
      "Epoch: 11, Index: 201, Loss: 0.3284\n",
      "Epoch: 11, Index: 202, Loss: 1.2412\n",
      "Epoch: 11, Index: 203, Loss: 1.5479\n",
      "Epoch: 11, Index: 204, Loss: 0.3209\n",
      "Epoch: 11, Index: 205, Loss: 2.6023\n",
      "Epoch: 11, Index: 206, Loss: 3.2697\n",
      "Epoch: 11, Index: 207, Loss: 2.3609\n",
      "Epoch: 11, Index: 208, Loss: 0.1346\n",
      "Epoch: 11, Index: 209, Loss: 0.9192\n",
      "Epoch: 11, Index: 210, Loss: 0.6603\n",
      "Epoch: 11, Index: 211, Loss: 0.2525\n",
      "Epoch: 11, Index: 212, Loss: 0.0849\n",
      "Epoch: 11, Index: 213, Loss: 4.4828\n",
      "Epoch: 11, Index: 214, Loss: 0.9059\n",
      "Epoch: 11, Index: 215, Loss: 1.1494\n",
      "Epoch: 11, Index: 216, Loss: 0.3314\n",
      "Epoch: 11, Index: 217, Loss: 0.3649\n",
      "Epoch: 11, Index: 218, Loss: 4.3607\n",
      "Epoch: 11, Index: 219, Loss: 2.7022\n",
      "Epoch: 11, Index: 220, Loss: 1.0292\n",
      "Epoch: 11, Index: 221, Loss: 0.0950\n",
      "Epoch: 11, Index: 222, Loss: 0.3656\n",
      "Epoch: 11, Index: 223, Loss: 4.3702\n",
      "Epoch: 11, Index: 224, Loss: 6.3240\n",
      "Epoch: 11, Index: 225, Loss: 0.2347\n",
      "Epoch: 11, Index: 226, Loss: 0.6716\n",
      "Epoch: 11, Index: 227, Loss: 0.2210\n",
      "Epoch: 11, Index: 228, Loss: 0.0224\n",
      "Epoch: 11, Index: 229, Loss: 6.1649\n",
      "Epoch: 11, Index: 230, Loss: 9.5667\n",
      "Epoch: 11, Index: 231, Loss: 3.4321\n",
      "Epoch: 11, Index: 232, Loss: 2.4836\n",
      "Epoch: 11, Index: 233, Loss: 0.1826\n",
      "Epoch: 11, Index: 234, Loss: 0.7725\n",
      "Epoch: 11, Index: 235, Loss: 0.1531\n",
      "Epoch: 11, Index: 236, Loss: 0.4706\n",
      "Epoch: 11, Index: 237, Loss: 1.5772\n",
      "Epoch: 11, Index: 238, Loss: 0.9558\n",
      "Epoch: 11, Index: 239, Loss: 2.0568\n",
      "Epoch: 11, Index: 240, Loss: 0.3442\n",
      "Epoch: 11, Index: 241, Loss: 1.9676\n",
      "Epoch: 11, Index: 242, Loss: 1.5030\n",
      "Epoch: 11, Index: 243, Loss: 0.0623\n",
      "Epoch: 11, Index: 244, Loss: 6.1075\n",
      "Epoch: 11, Index: 245, Loss: 2.7640\n",
      "Epoch: 11, Index: 246, Loss: 0.5225\n",
      "Epoch: 11, Index: 247, Loss: 0.3302\n",
      "Epoch: 11, Index: 248, Loss: 1.8037\n",
      "Epoch: 11, Index: 249, Loss: 1.6173\n",
      "Epoch: 11, Index: 250, Loss: 1.6213\n",
      "Epoch: 11, Index: 251, Loss: 3.2498\n",
      "Epoch: 11, Index: 252, Loss: 1.5128\n",
      "Epoch: 11, Index: 253, Loss: 0.0460\n",
      "Epoch: 11, Index: 254, Loss: 1.4621\n",
      "Epoch: 11, Index: 255, Loss: 0.7570\n",
      "Epoch: 11, Index: 256, Loss: 0.3332\n",
      "Epoch: 11, Index: 257, Loss: 0.0722\n",
      "Epoch: 11, Index: 258, Loss: 0.6122\n",
      "Epoch: 11, Index: 259, Loss: 1.0476\n",
      "Epoch: 11, Index: 260, Loss: 2.8930\n",
      "Epoch: 11, Index: 261, Loss: 2.3359\n",
      "Epoch: 11, Index: 262, Loss: 1.1465\n",
      "Epoch: 11, Index: 263, Loss: 3.4538\n",
      "Epoch: 11, Index: 264, Loss: 3.4326\n",
      "Epoch: 11, Index: 265, Loss: 1.8213\n",
      "Epoch: 11, Index: 266, Loss: 2.3236\n",
      "Epoch: 11, Index: 267, Loss: 1.3409\n",
      "Epoch: 11, Index: 268, Loss: 6.8903\n",
      "Epoch: 11, Index: 269, Loss: 1.9179\n",
      "Epoch: 11, Index: 270, Loss: 0.4612\n",
      "Epoch: 11, Index: 271, Loss: 0.0831\n",
      "Epoch: 11, Index: 272, Loss: 0.2334\n",
      "Epoch: 11, Index: 273, Loss: 0.4515\n",
      "Epoch: 11, Index: 274, Loss: 3.5452\n",
      "Epoch: 11, Index: 275, Loss: 0.6197\n",
      "Epoch: 11, Index: 276, Loss: 1.2500\n",
      "Epoch: 11, Index: 277, Loss: 1.4083\n",
      "Epoch: 11, Index: 278, Loss: 6.4979\n",
      "Epoch: 11, Index: 279, Loss: 1.3794\n",
      "Epoch: 11, Index: 280, Loss: 0.7257\n",
      "Epoch: 11, Index: 281, Loss: 1.6717\n",
      "Epoch: 11, Index: 282, Loss: 0.1329\n",
      "Epoch: 11, Index: 283, Loss: 1.0698\n",
      "Epoch: 11, Index: 284, Loss: 1.5240\n",
      "Epoch: 11, Index: 285, Loss: 0.1834\n",
      "Epoch: 11, Index: 286, Loss: 2.4896\n",
      "Epoch: 11, Index: 287, Loss: 0.6222\n",
      "Epoch: 11, Index: 288, Loss: 0.6072\n",
      "Epoch: 11, Index: 289, Loss: 3.9714\n",
      "Epoch: 11, Index: 290, Loss: 0.3215\n",
      "Epoch: 11, Index: 291, Loss: 0.7053\n",
      "Epoch: 11, Index: 292, Loss: 0.6088\n",
      "Epoch: 11, Index: 293, Loss: 4.6175\n",
      "Epoch: 11, Index: 294, Loss: 1.9215\n",
      "Epoch: 11, Index: 295, Loss: 2.1639\n",
      "Epoch: 11, Index: 296, Loss: 16.0840\n",
      "Epoch: 11, Index: 297, Loss: 2.8597\n",
      "Epoch: 11, Index: 298, Loss: 1.8140\n",
      "Epoch: 11, Index: 299, Loss: 0.8658\n",
      "Epoch: 11, Index: 300, Loss: 1.0143\n",
      "Epoch: 11, Index: 301, Loss: 3.4220\n",
      "Epoch: 11, Index: 302, Loss: 0.2099\n",
      "Epoch: 11, Index: 303, Loss: 0.7389\n",
      "Epoch: 11, Index: 304, Loss: 3.6427\n",
      "Epoch: 11, Index: 305, Loss: 0.9640\n",
      "Epoch: 11, Index: 306, Loss: 1.5084\n",
      "Epoch: 11, Index: 307, Loss: 3.2293\n",
      "Epoch: 11, Index: 308, Loss: 2.2603\n",
      "Epoch: 11, Index: 309, Loss: 2.0651\n",
      "Epoch: 11, Index: 310, Loss: 5.0127\n",
      "Epoch: 11, Index: 311, Loss: 0.9596\n",
      "Epoch: 11, Index: 312, Loss: 1.7734\n",
      "Epoch: 11, Index: 313, Loss: 1.8913\n",
      "Epoch: 11, Index: 314, Loss: 0.2181\n",
      "Epoch: 11, Index: 315, Loss: 3.2200\n",
      "Epoch: 11, Index: 316, Loss: 7.0749\n",
      "Epoch: 11, Index: 317, Loss: 1.1344\n",
      "Epoch: 11, Index: 318, Loss: 0.2575\n",
      "Epoch: 11, Index: 319, Loss: 1.5837\n",
      "Epoch: 11, Index: 320, Loss: 0.8791\n",
      "Epoch: 11, Index: 321, Loss: 2.8819\n",
      "Epoch: 11, Index: 322, Loss: 10.4572\n",
      "Epoch: 11, Index: 323, Loss: 1.2077\n",
      "Epoch: 11, Index: 324, Loss: 0.4717\n",
      "Epoch: 11, Index: 325, Loss: 1.1192\n",
      "Epoch: 11, Index: 326, Loss: 3.1822\n",
      "Epoch: 11, Index: 327, Loss: 0.0911\n",
      "Epoch: 11, Index: 328, Loss: 0.5816\n",
      "Epoch: 11, Index: 329, Loss: 5.2923\n",
      "Epoch: 11, Index: 330, Loss: 0.5163\n",
      "Epoch: 11, Index: 331, Loss: 1.4869\n",
      "Epoch: 11, Index: 332, Loss: 2.9258\n",
      "Epoch: 11, Index: 333, Loss: 0.8940\n",
      "Epoch: 11, Index: 334, Loss: 1.7083\n",
      "Epoch: 11, Index: 335, Loss: 0.2328\n",
      "Epoch: 11, Index: 336, Loss: 1.1963\n",
      "Epoch: 11, Index: 337, Loss: 0.5523\n",
      "Epoch: 11, Index: 338, Loss: 0.8712\n",
      "Epoch: 11, Index: 339, Loss: 0.8893\n",
      "Epoch: 11, Index: 340, Loss: 2.2245\n",
      "Epoch: 11, Index: 341, Loss: 3.8096\n",
      "Epoch: 11, Index: 342, Loss: 0.6527\n",
      "Epoch: 11, Index: 343, Loss: 0.6018\n",
      "Epoch: 11, Index: 344, Loss: 11.3562\n",
      "Epoch: 11, Index: 345, Loss: 0.4731\n",
      "Epoch: 11, Index: 346, Loss: 1.1389\n",
      "Epoch: 11, Index: 347, Loss: 1.0203\n",
      "Epoch: 11, Index: 348, Loss: 0.1484\n",
      "Epoch: 11, Index: 349, Loss: 0.2854\n",
      "Epoch: 11, Index: 350, Loss: 0.7365\n",
      "Epoch: 11, Index: 351, Loss: 0.8406\n",
      "Epoch: 11, Index: 352, Loss: 2.2535\n",
      "Epoch: 11, Index: 353, Loss: 0.6910\n",
      "Epoch: 11, Index: 354, Loss: 0.7991\n",
      "Epoch: 11, Index: 355, Loss: 1.7728\n",
      "Epoch: 11, Index: 356, Loss: 0.1917\n",
      "Epoch: 11, Index: 357, Loss: 2.0183\n",
      "Epoch: 11, Index: 358, Loss: 0.6314\n",
      "Epoch: 11, Index: 359, Loss: 2.4374\n",
      "Epoch: 11, Index: 360, Loss: 1.3255\n",
      "Epoch: 11, Index: 361, Loss: 0.5185\n",
      "Epoch: 11, Index: 362, Loss: 0.3342\n",
      "Epoch: 11, Index: 363, Loss: 2.7106\n",
      "Epoch: 11, Index: 364, Loss: 0.2194\n",
      "Epoch: 11, Index: 365, Loss: 1.7907\n",
      "Epoch: 11, Index: 366, Loss: 1.0045\n",
      "Epoch: 11, Index: 367, Loss: 0.9668\n",
      "Epoch: 11, Index: 368, Loss: 0.6626\n",
      "Epoch: 11, Index: 369, Loss: 1.0079\n",
      "Epoch: 11, Index: 370, Loss: 0.9196\n",
      "Epoch: 11, Index: 371, Loss: 0.4872\n",
      "Epoch: 11, Index: 372, Loss: 0.3950\n",
      "Epoch: 11, Index: 373, Loss: 0.9497\n",
      "Epoch: 11, Index: 374, Loss: 1.9487\n",
      "Epoch: 11, Index: 375, Loss: 3.0531\n",
      "Epoch: 11, Index: 376, Loss: 1.0614\n",
      "Epoch: 11, Index: 377, Loss: 2.0055\n",
      "Epoch: 11, Index: 378, Loss: 0.2058\n",
      "Epoch: 11, Index: 379, Loss: 2.2164\n",
      "Epoch: 11, Index: 380, Loss: 0.4534\n",
      "Epoch: 11, Index: 381, Loss: 3.9513\n",
      "Epoch: 11, Index: 382, Loss: 0.1675\n",
      "Epoch: 11, Index: 383, Loss: 1.5051\n",
      "Epoch: 11, Index: 384, Loss: 0.1439\n",
      "Epoch: 11, Index: 385, Loss: 0.4363\n",
      "Epoch: 11, Index: 386, Loss: 0.9542\n",
      "Epoch: 11, Index: 387, Loss: 1.7226\n",
      "Epoch: 11, Index: 388, Loss: 3.0167\n",
      "Epoch: 11, Index: 389, Loss: 0.8063\n",
      "Epoch: 11, Index: 390, Loss: 0.2060\n",
      "Epoch: 11, Index: 391, Loss: 2.2815\n",
      "Epoch: 11, Index: 392, Loss: 5.7513\n",
      "Epoch: 11, Index: 393, Loss: 1.1466\n",
      "Epoch: 11, Index: 394, Loss: 3.3491\n",
      "Epoch: 11, Index: 395, Loss: 0.3014\n",
      "Epoch: 11, Index: 396, Loss: 1.8678\n",
      "Epoch: 11, Index: 397, Loss: 0.2170\n",
      "Epoch: 11, Index: 398, Loss: 1.0909\n",
      "Epoch: 11, Index: 399, Loss: 1.0121\n",
      "Epoch: 11, Index: 400, Loss: 4.3696\n",
      "Epoch: 11, Index: 401, Loss: 3.3198\n",
      "Epoch: 11, Index: 402, Loss: 1.2333\n",
      "Epoch: 11, Index: 403, Loss: 0.3735\n",
      "Epoch: 11, Index: 404, Loss: 0.0302\n",
      "Epoch: 11, Index: 405, Loss: 5.8777\n",
      "Epoch: 11, Index: 406, Loss: 1.1350\n",
      "Epoch: 11, Index: 407, Loss: 6.4849\n",
      "Epoch: 11, Index: 408, Loss: 1.0062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a62d6e8f5ab489abd759002ac908559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Index: 0, Loss: 2.9007\n",
      "Epoch: 12, Index: 1, Loss: 2.7060\n",
      "Epoch: 12, Index: 2, Loss: 1.2688\n",
      "Epoch: 12, Index: 3, Loss: 1.8345\n",
      "Epoch: 12, Index: 4, Loss: 0.1466\n",
      "Epoch: 12, Index: 5, Loss: 0.8876\n",
      "Epoch: 12, Index: 6, Loss: 2.3543\n",
      "Epoch: 12, Index: 7, Loss: 2.2506\n",
      "Epoch: 12, Index: 8, Loss: 1.4581\n",
      "Epoch: 12, Index: 9, Loss: 3.6345\n",
      "Epoch: 12, Index: 10, Loss: 0.2460\n",
      "Epoch: 12, Index: 11, Loss: 2.3444\n",
      "Epoch: 12, Index: 12, Loss: 1.0721\n",
      "Epoch: 12, Index: 13, Loss: 0.2698\n",
      "Epoch: 12, Index: 14, Loss: 0.5265\n",
      "Epoch: 12, Index: 15, Loss: 0.0495\n",
      "Epoch: 12, Index: 16, Loss: 3.9670\n",
      "Epoch: 12, Index: 17, Loss: 1.0480\n",
      "Epoch: 12, Index: 18, Loss: 1.4953\n",
      "Epoch: 12, Index: 19, Loss: 1.1632\n",
      "Epoch: 12, Index: 20, Loss: 0.5624\n",
      "Epoch: 12, Index: 21, Loss: 0.0761\n",
      "Epoch: 12, Index: 22, Loss: 1.0875\n",
      "Epoch: 12, Index: 23, Loss: 1.3543\n",
      "Epoch: 12, Index: 24, Loss: 1.3745\n",
      "Epoch: 12, Index: 25, Loss: 1.3561\n",
      "Epoch: 12, Index: 26, Loss: 0.5059\n",
      "Epoch: 12, Index: 27, Loss: 1.0322\n",
      "Epoch: 12, Index: 28, Loss: 0.8950\n",
      "Epoch: 12, Index: 29, Loss: 1.7583\n",
      "Epoch: 12, Index: 30, Loss: 0.2187\n",
      "Epoch: 12, Index: 31, Loss: 0.2387\n",
      "Epoch: 12, Index: 32, Loss: 1.6290\n",
      "Epoch: 12, Index: 33, Loss: 4.4573\n",
      "Epoch: 12, Index: 34, Loss: 2.0752\n",
      "Epoch: 12, Index: 35, Loss: 0.4166\n",
      "Epoch: 12, Index: 36, Loss: 1.0940\n",
      "Epoch: 12, Index: 37, Loss: 0.9571\n",
      "Epoch: 12, Index: 38, Loss: 0.9175\n",
      "Epoch: 12, Index: 39, Loss: 2.3537\n",
      "Epoch: 12, Index: 40, Loss: 1.0205\n",
      "Epoch: 12, Index: 41, Loss: 1.4150\n",
      "Epoch: 12, Index: 42, Loss: 0.1736\n",
      "Epoch: 12, Index: 43, Loss: 1.7842\n",
      "Epoch: 12, Index: 44, Loss: 6.5602\n",
      "Epoch: 12, Index: 45, Loss: 0.1301\n",
      "Epoch: 12, Index: 46, Loss: 0.4918\n",
      "Epoch: 12, Index: 47, Loss: 0.8346\n",
      "Epoch: 12, Index: 48, Loss: 2.2054\n",
      "Epoch: 12, Index: 49, Loss: 1.5044\n",
      "Epoch: 12, Index: 50, Loss: 2.7010\n",
      "Epoch: 12, Index: 51, Loss: 0.8475\n",
      "Epoch: 12, Index: 52, Loss: 0.6299\n",
      "Epoch: 12, Index: 53, Loss: 0.8485\n",
      "Epoch: 12, Index: 54, Loss: 0.4715\n",
      "Epoch: 12, Index: 55, Loss: 1.8516\n",
      "Epoch: 12, Index: 56, Loss: 3.8554\n",
      "Epoch: 12, Index: 57, Loss: 1.7246\n",
      "Epoch: 12, Index: 58, Loss: 0.0040\n",
      "Epoch: 12, Index: 59, Loss: 2.7275\n",
      "Epoch: 12, Index: 60, Loss: 1.1251\n",
      "Epoch: 12, Index: 61, Loss: 1.2538\n",
      "Epoch: 12, Index: 62, Loss: 0.0297\n",
      "Epoch: 12, Index: 63, Loss: 1.2278\n",
      "Epoch: 12, Index: 64, Loss: 2.3963\n",
      "Epoch: 12, Index: 65, Loss: 1.1883\n",
      "Epoch: 12, Index: 66, Loss: 0.2304\n",
      "Epoch: 12, Index: 67, Loss: 0.3384\n",
      "Epoch: 12, Index: 68, Loss: 4.9308\n",
      "Epoch: 12, Index: 69, Loss: 1.8902\n",
      "Epoch: 12, Index: 70, Loss: 6.3773\n",
      "Epoch: 12, Index: 71, Loss: 1.9009\n",
      "Epoch: 12, Index: 72, Loss: 2.0080\n",
      "Epoch: 12, Index: 73, Loss: 0.8749\n",
      "Epoch: 12, Index: 74, Loss: 0.3175\n",
      "Epoch: 12, Index: 75, Loss: 4.6297\n",
      "Epoch: 12, Index: 76, Loss: 5.7373\n",
      "Epoch: 12, Index: 77, Loss: 4.6314\n",
      "Epoch: 12, Index: 78, Loss: 0.5763\n",
      "Epoch: 12, Index: 79, Loss: 0.7940\n",
      "Epoch: 12, Index: 80, Loss: 0.0329\n",
      "Epoch: 12, Index: 81, Loss: 3.0531\n",
      "Epoch: 12, Index: 82, Loss: 0.7446\n",
      "Epoch: 12, Index: 83, Loss: 0.9424\n",
      "Epoch: 12, Index: 84, Loss: 1.7578\n",
      "Epoch: 12, Index: 85, Loss: 2.7108\n",
      "Epoch: 12, Index: 86, Loss: 1.8104\n",
      "Epoch: 12, Index: 87, Loss: 1.5764\n",
      "Epoch: 12, Index: 88, Loss: 2.7708\n",
      "Epoch: 12, Index: 89, Loss: 1.3278\n",
      "Epoch: 12, Index: 90, Loss: 5.8999\n",
      "Epoch: 12, Index: 91, Loss: 1.8727\n",
      "Epoch: 12, Index: 92, Loss: 3.1435\n",
      "Epoch: 12, Index: 93, Loss: 3.6884\n",
      "Epoch: 12, Index: 94, Loss: 1.3397\n",
      "Epoch: 12, Index: 95, Loss: 3.1393\n",
      "Epoch: 12, Index: 96, Loss: 0.0306\n",
      "Epoch: 12, Index: 97, Loss: 0.4616\n",
      "Epoch: 12, Index: 98, Loss: 0.0019\n",
      "Epoch: 12, Index: 99, Loss: 1.5418\n",
      "Epoch: 12, Index: 100, Loss: 0.0081\n",
      "Epoch: 12, Index: 101, Loss: 3.2897\n",
      "Epoch: 12, Index: 102, Loss: 0.3887\n",
      "Epoch: 12, Index: 103, Loss: 0.0281\n",
      "Epoch: 12, Index: 104, Loss: 1.3926\n",
      "Epoch: 12, Index: 105, Loss: 0.5910\n",
      "Epoch: 12, Index: 106, Loss: 0.0561\n",
      "Epoch: 12, Index: 107, Loss: 0.2248\n",
      "Epoch: 12, Index: 108, Loss: 6.5209\n",
      "Epoch: 12, Index: 109, Loss: 0.2670\n",
      "Epoch: 12, Index: 110, Loss: 0.6134\n",
      "Epoch: 12, Index: 111, Loss: 1.0602\n",
      "Epoch: 12, Index: 112, Loss: 1.7942\n",
      "Epoch: 12, Index: 113, Loss: 0.5647\n",
      "Epoch: 12, Index: 114, Loss: 3.2816\n",
      "Epoch: 12, Index: 115, Loss: 2.5285\n",
      "Epoch: 12, Index: 116, Loss: 0.6206\n",
      "Epoch: 12, Index: 117, Loss: 1.2994\n",
      "Epoch: 12, Index: 118, Loss: 1.8488\n",
      "Epoch: 12, Index: 119, Loss: 0.0542\n",
      "Epoch: 12, Index: 120, Loss: 5.6158\n",
      "Epoch: 12, Index: 121, Loss: 1.4348\n",
      "Epoch: 12, Index: 122, Loss: 2.7807\n",
      "Epoch: 12, Index: 123, Loss: 5.5171\n",
      "Epoch: 12, Index: 124, Loss: 0.4266\n",
      "Epoch: 12, Index: 125, Loss: 2.4378\n",
      "Epoch: 12, Index: 126, Loss: 2.7185\n",
      "Epoch: 12, Index: 127, Loss: 0.2466\n",
      "Epoch: 12, Index: 128, Loss: 0.2525\n",
      "Epoch: 12, Index: 129, Loss: 0.2170\n",
      "Epoch: 12, Index: 130, Loss: 2.0084\n",
      "Epoch: 12, Index: 131, Loss: 3.0060\n",
      "Epoch: 12, Index: 132, Loss: 0.7023\n",
      "Epoch: 12, Index: 133, Loss: 0.1686\n",
      "Epoch: 12, Index: 134, Loss: 2.6465\n",
      "Epoch: 12, Index: 135, Loss: 2.1741\n",
      "Epoch: 12, Index: 136, Loss: 0.8644\n",
      "Epoch: 12, Index: 137, Loss: 4.7206\n",
      "Epoch: 12, Index: 138, Loss: 3.3972\n",
      "Epoch: 12, Index: 139, Loss: 0.1924\n",
      "Epoch: 12, Index: 140, Loss: 0.2060\n",
      "Epoch: 12, Index: 141, Loss: 5.8839\n",
      "Epoch: 12, Index: 142, Loss: 0.9986\n",
      "Epoch: 12, Index: 143, Loss: 0.1226\n",
      "Epoch: 12, Index: 144, Loss: 0.8281\n",
      "Epoch: 12, Index: 145, Loss: 4.2683\n",
      "Epoch: 12, Index: 146, Loss: 0.0128\n",
      "Epoch: 12, Index: 147, Loss: 1.6475\n",
      "Epoch: 12, Index: 148, Loss: 11.2936\n",
      "Epoch: 12, Index: 149, Loss: 4.5954\n",
      "Epoch: 12, Index: 150, Loss: 0.2357\n",
      "Epoch: 12, Index: 151, Loss: 1.1827\n",
      "Epoch: 12, Index: 152, Loss: 3.0902\n",
      "Epoch: 12, Index: 153, Loss: 2.1577\n",
      "Epoch: 12, Index: 154, Loss: 0.0336\n",
      "Epoch: 12, Index: 155, Loss: 1.0676\n",
      "Epoch: 12, Index: 156, Loss: 1.3342\n",
      "Epoch: 12, Index: 157, Loss: 2.3943\n",
      "Epoch: 12, Index: 158, Loss: 1.5530\n",
      "Epoch: 12, Index: 159, Loss: 2.3660\n",
      "Epoch: 12, Index: 160, Loss: 5.3845\n",
      "Epoch: 12, Index: 161, Loss: 0.0938\n",
      "Epoch: 12, Index: 162, Loss: 0.2370\n",
      "Epoch: 12, Index: 163, Loss: 5.7799\n",
      "Epoch: 12, Index: 164, Loss: 3.1973\n",
      "Epoch: 12, Index: 165, Loss: 0.2478\n",
      "Epoch: 12, Index: 166, Loss: 0.4749\n",
      "Epoch: 12, Index: 167, Loss: 3.7672\n",
      "Epoch: 12, Index: 168, Loss: 2.1968\n",
      "Epoch: 12, Index: 169, Loss: 3.1089\n",
      "Epoch: 12, Index: 170, Loss: 1.2047\n",
      "Epoch: 12, Index: 171, Loss: 2.5198\n",
      "Epoch: 12, Index: 172, Loss: 0.7488\n",
      "Epoch: 12, Index: 173, Loss: 0.7913\n",
      "Epoch: 12, Index: 174, Loss: 1.3899\n",
      "Epoch: 12, Index: 175, Loss: 0.0462\n",
      "Epoch: 12, Index: 176, Loss: 1.5595\n",
      "Epoch: 12, Index: 177, Loss: 5.5799\n",
      "Epoch: 12, Index: 178, Loss: 0.3457\n",
      "Epoch: 12, Index: 179, Loss: 0.4164\n",
      "Epoch: 12, Index: 180, Loss: 1.3403\n",
      "Epoch: 12, Index: 181, Loss: 0.0101\n",
      "Epoch: 12, Index: 182, Loss: 1.5875\n",
      "Epoch: 12, Index: 183, Loss: 0.5812\n",
      "Epoch: 12, Index: 184, Loss: 0.3267\n",
      "Epoch: 12, Index: 185, Loss: 0.3060\n",
      "Epoch: 12, Index: 186, Loss: 3.8293\n",
      "Epoch: 12, Index: 187, Loss: 0.4350\n",
      "Epoch: 12, Index: 188, Loss: 3.1250\n",
      "Epoch: 12, Index: 189, Loss: 6.0617\n",
      "Epoch: 12, Index: 190, Loss: 0.8746\n",
      "Epoch: 12, Index: 191, Loss: 1.5381\n",
      "Epoch: 12, Index: 192, Loss: 0.2194\n",
      "Epoch: 12, Index: 193, Loss: 2.8424\n",
      "Epoch: 12, Index: 194, Loss: 7.7713\n",
      "Epoch: 12, Index: 195, Loss: 7.8537\n",
      "Epoch: 12, Index: 196, Loss: 1.5359\n",
      "Epoch: 12, Index: 197, Loss: 2.8019\n",
      "Epoch: 12, Index: 198, Loss: 1.7689\n",
      "Epoch: 12, Index: 199, Loss: 2.1573\n",
      "Epoch: 12, Index: 200, Loss: 0.3017\n",
      "Epoch: 12, Index: 201, Loss: 0.4294\n",
      "Epoch: 12, Index: 202, Loss: 2.9684\n",
      "Epoch: 12, Index: 203, Loss: 3.3922\n",
      "Epoch: 12, Index: 204, Loss: 0.4497\n",
      "Epoch: 12, Index: 205, Loss: 1.1690\n",
      "Epoch: 12, Index: 206, Loss: 3.9449\n",
      "Epoch: 12, Index: 207, Loss: 0.9338\n",
      "Epoch: 12, Index: 208, Loss: 2.4661\n",
      "Epoch: 12, Index: 209, Loss: 0.9672\n",
      "Epoch: 12, Index: 210, Loss: 0.8949\n",
      "Epoch: 12, Index: 211, Loss: 0.2295\n",
      "Epoch: 12, Index: 212, Loss: 0.5521\n",
      "Epoch: 12, Index: 213, Loss: 0.2409\n",
      "Epoch: 12, Index: 214, Loss: 0.0366\n",
      "Epoch: 12, Index: 215, Loss: 0.5129\n",
      "Epoch: 12, Index: 216, Loss: 0.5170\n",
      "Epoch: 12, Index: 217, Loss: 0.3353\n",
      "Epoch: 12, Index: 218, Loss: 0.3628\n",
      "Epoch: 12, Index: 219, Loss: 1.8561\n",
      "Epoch: 12, Index: 220, Loss: 0.4364\n",
      "Epoch: 12, Index: 221, Loss: 0.0637\n",
      "Epoch: 12, Index: 222, Loss: 8.5378\n",
      "Epoch: 12, Index: 223, Loss: 3.8338\n",
      "Epoch: 12, Index: 224, Loss: 1.7689\n",
      "Epoch: 12, Index: 225, Loss: 1.4026\n",
      "Epoch: 12, Index: 226, Loss: 1.2874\n",
      "Epoch: 12, Index: 227, Loss: 0.2515\n",
      "Epoch: 12, Index: 228, Loss: 0.1380\n",
      "Epoch: 12, Index: 229, Loss: 0.0412\n",
      "Epoch: 12, Index: 230, Loss: 4.9472\n",
      "Epoch: 12, Index: 231, Loss: 0.0653\n",
      "Epoch: 12, Index: 232, Loss: 1.8639\n",
      "Epoch: 12, Index: 233, Loss: 0.3770\n",
      "Epoch: 12, Index: 234, Loss: 1.2926\n",
      "Epoch: 12, Index: 235, Loss: 0.2947\n",
      "Epoch: 12, Index: 236, Loss: 1.3588\n",
      "Epoch: 12, Index: 237, Loss: 0.0889\n",
      "Epoch: 12, Index: 238, Loss: 1.9985\n",
      "Epoch: 12, Index: 239, Loss: 2.4234\n",
      "Epoch: 12, Index: 240, Loss: 0.8758\n",
      "Epoch: 12, Index: 241, Loss: 0.4619\n",
      "Epoch: 12, Index: 242, Loss: 0.0768\n",
      "Epoch: 12, Index: 243, Loss: 1.9836\n",
      "Epoch: 12, Index: 244, Loss: 2.0419\n",
      "Epoch: 12, Index: 245, Loss: 8.1123\n",
      "Epoch: 12, Index: 246, Loss: 0.6124\n",
      "Epoch: 12, Index: 247, Loss: 2.2278\n",
      "Epoch: 12, Index: 248, Loss: 0.8850\n",
      "Epoch: 12, Index: 249, Loss: 0.6919\n",
      "Epoch: 12, Index: 250, Loss: 0.6722\n",
      "Epoch: 12, Index: 251, Loss: 1.0176\n",
      "Epoch: 12, Index: 252, Loss: 1.0832\n",
      "Epoch: 12, Index: 253, Loss: 2.4977\n",
      "Epoch: 12, Index: 254, Loss: 3.5079\n",
      "Epoch: 12, Index: 255, Loss: 0.7085\n",
      "Epoch: 12, Index: 256, Loss: 1.2567\n",
      "Epoch: 12, Index: 257, Loss: 0.1937\n",
      "Epoch: 12, Index: 258, Loss: 2.7281\n",
      "Epoch: 12, Index: 259, Loss: 1.3245\n",
      "Epoch: 12, Index: 260, Loss: 0.3061\n",
      "Epoch: 12, Index: 261, Loss: 1.4505\n",
      "Epoch: 12, Index: 262, Loss: 1.0373\n",
      "Epoch: 12, Index: 263, Loss: 4.2798\n",
      "Epoch: 12, Index: 264, Loss: 0.7911\n",
      "Epoch: 12, Index: 265, Loss: 9.1250\n",
      "Epoch: 12, Index: 266, Loss: 0.9470\n",
      "Epoch: 12, Index: 267, Loss: 0.0992\n",
      "Epoch: 12, Index: 268, Loss: 2.1343\n",
      "Epoch: 12, Index: 269, Loss: 1.6266\n",
      "Epoch: 12, Index: 270, Loss: 0.8864\n",
      "Epoch: 12, Index: 271, Loss: 1.3263\n",
      "Epoch: 12, Index: 272, Loss: 5.1892\n",
      "Epoch: 12, Index: 273, Loss: 0.1748\n",
      "Epoch: 12, Index: 274, Loss: 4.0062\n",
      "Epoch: 12, Index: 275, Loss: 3.1567\n",
      "Epoch: 12, Index: 276, Loss: 0.2620\n",
      "Epoch: 12, Index: 277, Loss: 1.1871\n",
      "Epoch: 12, Index: 278, Loss: 1.0144\n",
      "Epoch: 12, Index: 279, Loss: 0.4649\n",
      "Epoch: 12, Index: 280, Loss: 1.2069\n",
      "Epoch: 12, Index: 281, Loss: 0.3489\n",
      "Epoch: 12, Index: 282, Loss: 2.5410\n",
      "Epoch: 12, Index: 283, Loss: 1.9541\n",
      "Epoch: 12, Index: 284, Loss: 2.4096\n",
      "Epoch: 12, Index: 285, Loss: 0.5789\n",
      "Epoch: 12, Index: 286, Loss: 0.9642\n",
      "Epoch: 12, Index: 287, Loss: 0.5667\n",
      "Epoch: 12, Index: 288, Loss: 10.0006\n",
      "Epoch: 12, Index: 289, Loss: 5.1335\n",
      "Epoch: 12, Index: 290, Loss: 0.6638\n",
      "Epoch: 12, Index: 291, Loss: 0.0949\n",
      "Epoch: 12, Index: 292, Loss: 3.6912\n",
      "Epoch: 12, Index: 293, Loss: 1.3357\n",
      "Epoch: 12, Index: 294, Loss: 0.3110\n",
      "Epoch: 12, Index: 295, Loss: 1.8361\n",
      "Epoch: 12, Index: 296, Loss: 4.1857\n",
      "Epoch: 12, Index: 297, Loss: 1.7437\n",
      "Epoch: 12, Index: 298, Loss: 0.3243\n",
      "Epoch: 12, Index: 299, Loss: 1.7033\n",
      "Epoch: 12, Index: 300, Loss: 1.7659\n",
      "Epoch: 12, Index: 301, Loss: 1.5175\n",
      "Epoch: 12, Index: 302, Loss: 1.1219\n",
      "Epoch: 12, Index: 303, Loss: 2.8574\n",
      "Epoch: 12, Index: 304, Loss: 1.0861\n",
      "Epoch: 12, Index: 305, Loss: 2.6372\n",
      "Epoch: 12, Index: 306, Loss: 1.1216\n",
      "Epoch: 12, Index: 307, Loss: 0.5324\n",
      "Epoch: 12, Index: 308, Loss: 0.8115\n",
      "Epoch: 12, Index: 309, Loss: 0.1301\n",
      "Epoch: 12, Index: 310, Loss: 8.9548\n",
      "Epoch: 12, Index: 311, Loss: 0.9289\n",
      "Epoch: 12, Index: 312, Loss: 0.8150\n",
      "Epoch: 12, Index: 313, Loss: 1.2498\n",
      "Epoch: 12, Index: 314, Loss: 2.3999\n",
      "Epoch: 12, Index: 315, Loss: 0.2506\n",
      "Epoch: 12, Index: 316, Loss: 0.2869\n",
      "Epoch: 12, Index: 317, Loss: 1.0334\n",
      "Epoch: 12, Index: 318, Loss: 0.1077\n",
      "Epoch: 12, Index: 319, Loss: 1.6592\n",
      "Epoch: 12, Index: 320, Loss: 2.6637\n",
      "Epoch: 12, Index: 321, Loss: 0.9293\n",
      "Epoch: 12, Index: 322, Loss: 1.2482\n",
      "Epoch: 12, Index: 323, Loss: 1.2194\n",
      "Epoch: 12, Index: 324, Loss: 4.3024\n",
      "Epoch: 12, Index: 325, Loss: 0.5348\n",
      "Epoch: 12, Index: 326, Loss: 1.3533\n",
      "Epoch: 12, Index: 327, Loss: 1.6671\n",
      "Epoch: 12, Index: 328, Loss: 0.2936\n",
      "Epoch: 12, Index: 329, Loss: 7.7349\n",
      "Epoch: 12, Index: 330, Loss: 16.6867\n",
      "Epoch: 12, Index: 331, Loss: 0.3428\n",
      "Epoch: 12, Index: 332, Loss: 1.3073\n",
      "Epoch: 12, Index: 333, Loss: 0.7859\n",
      "Epoch: 12, Index: 334, Loss: 4.0714\n",
      "Epoch: 12, Index: 335, Loss: 0.8224\n",
      "Epoch: 12, Index: 336, Loss: 0.3756\n",
      "Epoch: 12, Index: 337, Loss: 3.4175\n",
      "Epoch: 12, Index: 338, Loss: 0.3859\n",
      "Epoch: 12, Index: 339, Loss: 1.5520\n",
      "Epoch: 12, Index: 340, Loss: 1.1924\n",
      "Epoch: 12, Index: 341, Loss: 2.2615\n",
      "Epoch: 12, Index: 342, Loss: 1.5312\n",
      "Epoch: 12, Index: 343, Loss: 1.0334\n",
      "Epoch: 12, Index: 344, Loss: 0.9928\n",
      "Epoch: 12, Index: 345, Loss: 0.3460\n",
      "Epoch: 12, Index: 346, Loss: 0.2648\n",
      "Epoch: 12, Index: 347, Loss: 1.6543\n",
      "Epoch: 12, Index: 348, Loss: 0.0969\n",
      "Epoch: 12, Index: 349, Loss: 1.6767\n",
      "Epoch: 12, Index: 350, Loss: 2.5817\n",
      "Epoch: 12, Index: 351, Loss: 0.4772\n",
      "Epoch: 12, Index: 352, Loss: 1.1766\n",
      "Epoch: 12, Index: 353, Loss: 4.5879\n",
      "Epoch: 12, Index: 354, Loss: 1.0941\n",
      "Epoch: 12, Index: 355, Loss: 4.5016\n",
      "Epoch: 12, Index: 356, Loss: 0.5197\n",
      "Epoch: 12, Index: 357, Loss: 1.3746\n",
      "Epoch: 12, Index: 358, Loss: 1.0480\n",
      "Epoch: 12, Index: 359, Loss: 1.5028\n",
      "Epoch: 12, Index: 360, Loss: 5.0815\n",
      "Epoch: 12, Index: 361, Loss: 1.2262\n",
      "Epoch: 12, Index: 362, Loss: 2.3348\n",
      "Epoch: 12, Index: 363, Loss: 2.2501\n",
      "Epoch: 12, Index: 364, Loss: 0.7285\n",
      "Epoch: 12, Index: 365, Loss: 2.9860\n",
      "Epoch: 12, Index: 366, Loss: 1.4401\n",
      "Epoch: 12, Index: 367, Loss: 1.1862\n",
      "Epoch: 12, Index: 368, Loss: 3.3507\n",
      "Epoch: 12, Index: 369, Loss: 2.7929\n",
      "Epoch: 12, Index: 370, Loss: 1.2517\n",
      "Epoch: 12, Index: 371, Loss: 3.1338\n",
      "Epoch: 12, Index: 372, Loss: 4.6906\n",
      "Epoch: 12, Index: 373, Loss: 1.0975\n",
      "Epoch: 12, Index: 374, Loss: 0.6919\n",
      "Epoch: 12, Index: 375, Loss: 2.3535\n",
      "Epoch: 12, Index: 376, Loss: 3.4057\n",
      "Epoch: 12, Index: 377, Loss: 1.0933\n",
      "Epoch: 12, Index: 378, Loss: 0.9928\n",
      "Epoch: 12, Index: 379, Loss: 3.5740\n",
      "Epoch: 12, Index: 380, Loss: 1.6860\n",
      "Epoch: 12, Index: 381, Loss: 0.7650\n",
      "Epoch: 12, Index: 382, Loss: 1.2036\n",
      "Epoch: 12, Index: 383, Loss: 0.2992\n",
      "Epoch: 12, Index: 384, Loss: 0.9427\n",
      "Epoch: 12, Index: 385, Loss: 0.3284\n",
      "Epoch: 12, Index: 386, Loss: 0.1431\n",
      "Epoch: 12, Index: 387, Loss: 1.5178\n",
      "Epoch: 12, Index: 388, Loss: 0.7119\n",
      "Epoch: 12, Index: 389, Loss: 2.2307\n",
      "Epoch: 12, Index: 390, Loss: 4.0815\n",
      "Epoch: 12, Index: 391, Loss: 0.3765\n",
      "Epoch: 12, Index: 392, Loss: 0.1412\n",
      "Epoch: 12, Index: 393, Loss: 3.1861\n",
      "Epoch: 12, Index: 394, Loss: 0.9601\n",
      "Epoch: 12, Index: 395, Loss: 0.7179\n",
      "Epoch: 12, Index: 396, Loss: 7.1156\n",
      "Epoch: 12, Index: 397, Loss: 0.1808\n",
      "Epoch: 12, Index: 398, Loss: 6.2941\n",
      "Epoch: 12, Index: 399, Loss: 1.7898\n",
      "Epoch: 12, Index: 400, Loss: 2.1358\n",
      "Epoch: 12, Index: 401, Loss: 2.3785\n",
      "Epoch: 12, Index: 402, Loss: 1.3400\n",
      "Epoch: 12, Index: 403, Loss: 0.4201\n",
      "Epoch: 12, Index: 404, Loss: 0.3308\n",
      "Epoch: 12, Index: 405, Loss: 2.0484\n",
      "Epoch: 12, Index: 406, Loss: 0.2916\n",
      "Epoch: 12, Index: 407, Loss: 1.8338\n",
      "Epoch: 12, Index: 408, Loss: 4.0304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f278279c494fc6a3876fd9a2eb2c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Index: 0, Loss: 0.8268\n",
      "Epoch: 13, Index: 1, Loss: 2.0012\n",
      "Epoch: 13, Index: 2, Loss: 0.8355\n",
      "Epoch: 13, Index: 3, Loss: 3.2744\n",
      "Epoch: 13, Index: 4, Loss: 4.5046\n",
      "Epoch: 13, Index: 5, Loss: 11.6774\n",
      "Epoch: 13, Index: 6, Loss: 6.1306\n",
      "Epoch: 13, Index: 7, Loss: 0.0403\n",
      "Epoch: 13, Index: 8, Loss: 0.2046\n",
      "Epoch: 13, Index: 9, Loss: 0.0470\n",
      "Epoch: 13, Index: 10, Loss: 0.5352\n",
      "Epoch: 13, Index: 11, Loss: 2.9980\n",
      "Epoch: 13, Index: 12, Loss: 0.8600\n",
      "Epoch: 13, Index: 13, Loss: 2.9244\n",
      "Epoch: 13, Index: 14, Loss: 2.4113\n",
      "Epoch: 13, Index: 15, Loss: 1.4143\n",
      "Epoch: 13, Index: 16, Loss: 0.9042\n",
      "Epoch: 13, Index: 17, Loss: 0.2454\n",
      "Epoch: 13, Index: 18, Loss: 2.3548\n",
      "Epoch: 13, Index: 19, Loss: 1.0797\n",
      "Epoch: 13, Index: 20, Loss: 1.7898\n",
      "Epoch: 13, Index: 21, Loss: 0.9633\n",
      "Epoch: 13, Index: 22, Loss: 4.2393\n",
      "Epoch: 13, Index: 23, Loss: 2.2105\n",
      "Epoch: 13, Index: 24, Loss: 2.6049\n",
      "Epoch: 13, Index: 25, Loss: 4.2642\n",
      "Epoch: 13, Index: 26, Loss: 0.2441\n",
      "Epoch: 13, Index: 27, Loss: 0.8553\n",
      "Epoch: 13, Index: 28, Loss: 2.0571\n",
      "Epoch: 13, Index: 29, Loss: 4.7450\n",
      "Epoch: 13, Index: 30, Loss: 1.6216\n",
      "Epoch: 13, Index: 31, Loss: 0.4117\n",
      "Epoch: 13, Index: 32, Loss: 2.3102\n",
      "Epoch: 13, Index: 33, Loss: 1.1248\n",
      "Epoch: 13, Index: 34, Loss: 3.8278\n",
      "Epoch: 13, Index: 35, Loss: 2.2938\n",
      "Epoch: 13, Index: 36, Loss: 0.8226\n",
      "Epoch: 13, Index: 37, Loss: 1.8175\n",
      "Epoch: 13, Index: 38, Loss: 4.9885\n",
      "Epoch: 13, Index: 39, Loss: 1.6121\n",
      "Epoch: 13, Index: 40, Loss: 7.0335\n",
      "Epoch: 13, Index: 41, Loss: 1.1311\n",
      "Epoch: 13, Index: 42, Loss: 0.7120\n",
      "Epoch: 13, Index: 43, Loss: 0.7725\n",
      "Epoch: 13, Index: 44, Loss: 0.8512\n",
      "Epoch: 13, Index: 45, Loss: 0.5646\n",
      "Epoch: 13, Index: 46, Loss: 3.0435\n",
      "Epoch: 13, Index: 47, Loss: 4.6007\n",
      "Epoch: 13, Index: 48, Loss: 1.8760\n",
      "Epoch: 13, Index: 49, Loss: 1.1622\n",
      "Epoch: 13, Index: 50, Loss: 0.1871\n",
      "Epoch: 13, Index: 51, Loss: 1.2120\n",
      "Epoch: 13, Index: 52, Loss: 0.2382\n",
      "Epoch: 13, Index: 53, Loss: 0.2870\n",
      "Epoch: 13, Index: 54, Loss: 1.6672\n",
      "Epoch: 13, Index: 55, Loss: 0.6610\n",
      "Epoch: 13, Index: 56, Loss: 1.2608\n",
      "Epoch: 13, Index: 57, Loss: 0.9608\n",
      "Epoch: 13, Index: 58, Loss: 0.1142\n",
      "Epoch: 13, Index: 59, Loss: 0.3563\n",
      "Epoch: 13, Index: 60, Loss: 1.4335\n",
      "Epoch: 13, Index: 61, Loss: 7.9554\n",
      "Epoch: 13, Index: 62, Loss: 0.5377\n",
      "Epoch: 13, Index: 63, Loss: 1.0051\n",
      "Epoch: 13, Index: 64, Loss: 0.0525\n",
      "Epoch: 13, Index: 65, Loss: 0.0900\n",
      "Epoch: 13, Index: 66, Loss: 2.6912\n",
      "Epoch: 13, Index: 67, Loss: 2.9558\n",
      "Epoch: 13, Index: 68, Loss: 2.3687\n",
      "Epoch: 13, Index: 69, Loss: 4.9992\n",
      "Epoch: 13, Index: 70, Loss: 4.6975\n",
      "Epoch: 13, Index: 71, Loss: 0.0291\n",
      "Epoch: 13, Index: 72, Loss: 0.6282\n",
      "Epoch: 13, Index: 73, Loss: 0.4949\n",
      "Epoch: 13, Index: 74, Loss: 0.6568\n",
      "Epoch: 13, Index: 75, Loss: 0.1603\n",
      "Epoch: 13, Index: 76, Loss: 0.6062\n",
      "Epoch: 13, Index: 77, Loss: 1.3247\n",
      "Epoch: 13, Index: 78, Loss: 1.2705\n",
      "Epoch: 13, Index: 79, Loss: 1.0464\n",
      "Epoch: 13, Index: 80, Loss: 3.7068\n",
      "Epoch: 13, Index: 81, Loss: 0.6759\n",
      "Epoch: 13, Index: 82, Loss: 2.1935\n",
      "Epoch: 13, Index: 83, Loss: 1.7595\n",
      "Epoch: 13, Index: 84, Loss: 1.4353\n",
      "Epoch: 13, Index: 85, Loss: 0.1957\n",
      "Epoch: 13, Index: 86, Loss: 0.6735\n",
      "Epoch: 13, Index: 87, Loss: 3.4680\n",
      "Epoch: 13, Index: 88, Loss: 0.7165\n",
      "Epoch: 13, Index: 89, Loss: 0.6121\n",
      "Epoch: 13, Index: 90, Loss: 0.1338\n",
      "Epoch: 13, Index: 91, Loss: 0.5379\n",
      "Epoch: 13, Index: 92, Loss: 3.5174\n",
      "Epoch: 13, Index: 93, Loss: 2.0717\n",
      "Epoch: 13, Index: 94, Loss: 0.5157\n",
      "Epoch: 13, Index: 95, Loss: 0.4858\n",
      "Epoch: 13, Index: 96, Loss: 1.7194\n",
      "Epoch: 13, Index: 97, Loss: 3.3188\n",
      "Epoch: 13, Index: 98, Loss: 0.4306\n",
      "Epoch: 13, Index: 99, Loss: 3.8651\n",
      "Epoch: 13, Index: 100, Loss: 0.6215\n",
      "Epoch: 13, Index: 101, Loss: 0.3956\n",
      "Epoch: 13, Index: 102, Loss: 1.7529\n",
      "Epoch: 13, Index: 103, Loss: 2.3189\n",
      "Epoch: 13, Index: 104, Loss: 1.0083\n",
      "Epoch: 13, Index: 105, Loss: 4.4613\n",
      "Epoch: 13, Index: 106, Loss: 3.8985\n",
      "Epoch: 13, Index: 107, Loss: 0.0036\n",
      "Epoch: 13, Index: 108, Loss: 0.5984\n",
      "Epoch: 13, Index: 109, Loss: 0.3579\n",
      "Epoch: 13, Index: 110, Loss: 1.3776\n",
      "Epoch: 13, Index: 111, Loss: 1.1408\n",
      "Epoch: 13, Index: 112, Loss: 1.0147\n",
      "Epoch: 13, Index: 113, Loss: 1.2197\n",
      "Epoch: 13, Index: 114, Loss: 1.9620\n",
      "Epoch: 13, Index: 115, Loss: 1.0205\n",
      "Epoch: 13, Index: 116, Loss: 0.1720\n",
      "Epoch: 13, Index: 117, Loss: 0.3940\n",
      "Epoch: 13, Index: 118, Loss: 0.8380\n",
      "Epoch: 13, Index: 119, Loss: 7.6264\n",
      "Epoch: 13, Index: 120, Loss: 0.6408\n",
      "Epoch: 13, Index: 121, Loss: 5.6283\n",
      "Epoch: 13, Index: 122, Loss: 0.1390\n",
      "Epoch: 13, Index: 123, Loss: 1.3316\n",
      "Epoch: 13, Index: 124, Loss: 1.3673\n",
      "Epoch: 13, Index: 125, Loss: 0.1011\n",
      "Epoch: 13, Index: 126, Loss: 1.5547\n",
      "Epoch: 13, Index: 127, Loss: 1.8279\n",
      "Epoch: 13, Index: 128, Loss: 3.6358\n",
      "Epoch: 13, Index: 129, Loss: 0.8793\n",
      "Epoch: 13, Index: 130, Loss: 1.1187\n",
      "Epoch: 13, Index: 131, Loss: 4.3049\n",
      "Epoch: 13, Index: 132, Loss: 1.0317\n",
      "Epoch: 13, Index: 133, Loss: 1.4063\n",
      "Epoch: 13, Index: 134, Loss: 0.0073\n",
      "Epoch: 13, Index: 135, Loss: 1.2024\n",
      "Epoch: 13, Index: 136, Loss: 2.7703\n",
      "Epoch: 13, Index: 137, Loss: 1.2314\n",
      "Epoch: 13, Index: 138, Loss: 5.2248\n",
      "Epoch: 13, Index: 139, Loss: 0.1955\n",
      "Epoch: 13, Index: 140, Loss: 1.8075\n",
      "Epoch: 13, Index: 141, Loss: 0.0939\n",
      "Epoch: 13, Index: 142, Loss: 0.6497\n",
      "Epoch: 13, Index: 143, Loss: 2.3733\n",
      "Epoch: 13, Index: 144, Loss: 0.8719\n",
      "Epoch: 13, Index: 145, Loss: 1.3843\n",
      "Epoch: 13, Index: 146, Loss: 7.5190\n",
      "Epoch: 13, Index: 147, Loss: 0.3087\n",
      "Epoch: 13, Index: 148, Loss: 1.7207\n",
      "Epoch: 13, Index: 149, Loss: 0.4927\n",
      "Epoch: 13, Index: 150, Loss: 0.4568\n",
      "Epoch: 13, Index: 151, Loss: 0.4621\n",
      "Epoch: 13, Index: 152, Loss: 0.8893\n",
      "Epoch: 13, Index: 153, Loss: 3.1159\n",
      "Epoch: 13, Index: 154, Loss: 3.4209\n",
      "Epoch: 13, Index: 155, Loss: 0.4856\n",
      "Epoch: 13, Index: 156, Loss: 0.4015\n",
      "Epoch: 13, Index: 157, Loss: 2.9367\n",
      "Epoch: 13, Index: 158, Loss: 0.2860\n",
      "Epoch: 13, Index: 159, Loss: 1.4127\n",
      "Epoch: 13, Index: 160, Loss: 5.6719\n",
      "Epoch: 13, Index: 161, Loss: 0.5363\n",
      "Epoch: 13, Index: 162, Loss: 1.5095\n",
      "Epoch: 13, Index: 163, Loss: 1.1808\n",
      "Epoch: 13, Index: 164, Loss: 1.6145\n",
      "Epoch: 13, Index: 165, Loss: 7.1214\n",
      "Epoch: 13, Index: 166, Loss: 0.6014\n",
      "Epoch: 13, Index: 167, Loss: 3.2662\n",
      "Epoch: 13, Index: 168, Loss: 2.6038\n",
      "Epoch: 13, Index: 169, Loss: 0.4975\n",
      "Epoch: 13, Index: 170, Loss: 0.2181\n",
      "Epoch: 13, Index: 171, Loss: 0.6391\n",
      "Epoch: 13, Index: 172, Loss: 2.8606\n",
      "Epoch: 13, Index: 173, Loss: 0.3412\n",
      "Epoch: 13, Index: 174, Loss: 2.6901\n",
      "Epoch: 13, Index: 175, Loss: 4.4418\n",
      "Epoch: 13, Index: 176, Loss: 2.6801\n",
      "Epoch: 13, Index: 177, Loss: 3.6798\n",
      "Epoch: 13, Index: 178, Loss: 0.0924\n",
      "Epoch: 13, Index: 179, Loss: 3.4846\n",
      "Epoch: 13, Index: 180, Loss: 0.0095\n",
      "Epoch: 13, Index: 181, Loss: 1.9485\n",
      "Epoch: 13, Index: 182, Loss: 3.4101\n",
      "Epoch: 13, Index: 183, Loss: 0.6668\n",
      "Epoch: 13, Index: 184, Loss: 0.2724\n",
      "Epoch: 13, Index: 185, Loss: 0.6182\n",
      "Epoch: 13, Index: 186, Loss: 0.0075\n",
      "Epoch: 13, Index: 187, Loss: 1.9432\n",
      "Epoch: 13, Index: 188, Loss: 1.0561\n",
      "Epoch: 13, Index: 189, Loss: 0.1738\n",
      "Epoch: 13, Index: 190, Loss: 0.1677\n",
      "Epoch: 13, Index: 191, Loss: 0.6363\n",
      "Epoch: 13, Index: 192, Loss: 2.7965\n",
      "Epoch: 13, Index: 193, Loss: 0.6698\n",
      "Epoch: 13, Index: 194, Loss: 0.4668\n",
      "Epoch: 13, Index: 195, Loss: 0.2785\n",
      "Epoch: 13, Index: 196, Loss: 5.4376\n",
      "Epoch: 13, Index: 197, Loss: 0.5963\n",
      "Epoch: 13, Index: 198, Loss: 0.4832\n",
      "Epoch: 13, Index: 199, Loss: 2.0455\n",
      "Epoch: 13, Index: 200, Loss: 1.3827\n",
      "Epoch: 13, Index: 201, Loss: 0.7969\n",
      "Epoch: 13, Index: 202, Loss: 2.1475\n",
      "Epoch: 13, Index: 203, Loss: 2.1011\n",
      "Epoch: 13, Index: 204, Loss: 0.0268\n",
      "Epoch: 13, Index: 205, Loss: 0.0418\n",
      "Epoch: 13, Index: 206, Loss: 3.0516\n",
      "Epoch: 13, Index: 207, Loss: 18.1324\n",
      "Epoch: 13, Index: 208, Loss: 0.8500\n",
      "Epoch: 13, Index: 209, Loss: 0.0256\n",
      "Epoch: 13, Index: 210, Loss: 0.5091\n",
      "Epoch: 13, Index: 211, Loss: 2.0295\n",
      "Epoch: 13, Index: 212, Loss: 0.8180\n",
      "Epoch: 13, Index: 213, Loss: 1.4558\n",
      "Epoch: 13, Index: 214, Loss: 1.6004\n",
      "Epoch: 13, Index: 215, Loss: 0.4607\n",
      "Epoch: 13, Index: 216, Loss: 0.1971\n",
      "Epoch: 13, Index: 217, Loss: 4.7454\n",
      "Epoch: 13, Index: 218, Loss: 2.1797\n",
      "Epoch: 13, Index: 219, Loss: 1.5421\n",
      "Epoch: 13, Index: 220, Loss: 1.3180\n",
      "Epoch: 13, Index: 221, Loss: 0.2258\n",
      "Epoch: 13, Index: 222, Loss: 0.0494\n",
      "Epoch: 13, Index: 223, Loss: 1.8870\n",
      "Epoch: 13, Index: 224, Loss: 0.7574\n",
      "Epoch: 13, Index: 225, Loss: 2.0822\n",
      "Epoch: 13, Index: 226, Loss: 0.0878\n",
      "Epoch: 13, Index: 227, Loss: 1.8449\n",
      "Epoch: 13, Index: 228, Loss: 2.0604\n",
      "Epoch: 13, Index: 229, Loss: 1.1051\n",
      "Epoch: 13, Index: 230, Loss: 0.8175\n",
      "Epoch: 13, Index: 231, Loss: 1.4606\n",
      "Epoch: 13, Index: 232, Loss: 1.4854\n",
      "Epoch: 13, Index: 233, Loss: 1.5595\n",
      "Epoch: 13, Index: 234, Loss: 1.1715\n",
      "Epoch: 13, Index: 235, Loss: 0.0865\n",
      "Epoch: 13, Index: 236, Loss: 0.9703\n",
      "Epoch: 13, Index: 237, Loss: 0.0213\n",
      "Epoch: 13, Index: 238, Loss: 3.8644\n",
      "Epoch: 13, Index: 239, Loss: 0.6555\n",
      "Epoch: 13, Index: 240, Loss: 0.9592\n",
      "Epoch: 13, Index: 241, Loss: 1.8558\n",
      "Epoch: 13, Index: 242, Loss: 0.8114\n",
      "Epoch: 13, Index: 243, Loss: 0.2327\n",
      "Epoch: 13, Index: 244, Loss: 2.6187\n",
      "Epoch: 13, Index: 245, Loss: 0.2926\n",
      "Epoch: 13, Index: 246, Loss: 2.3183\n",
      "Epoch: 13, Index: 247, Loss: 0.0766\n",
      "Epoch: 13, Index: 248, Loss: 1.4103\n",
      "Epoch: 13, Index: 249, Loss: 1.4201\n",
      "Epoch: 13, Index: 250, Loss: 0.4343\n",
      "Epoch: 13, Index: 251, Loss: 1.6132\n",
      "Epoch: 13, Index: 252, Loss: 2.5625\n",
      "Epoch: 13, Index: 253, Loss: 1.6918\n",
      "Epoch: 13, Index: 254, Loss: 2.2940\n",
      "Epoch: 13, Index: 255, Loss: 2.0331\n",
      "Epoch: 13, Index: 256, Loss: 1.1554\n",
      "Epoch: 13, Index: 257, Loss: 0.9160\n",
      "Epoch: 13, Index: 258, Loss: 4.7139\n",
      "Epoch: 13, Index: 259, Loss: 1.0641\n",
      "Epoch: 13, Index: 260, Loss: 2.2814\n",
      "Epoch: 13, Index: 261, Loss: 6.1998\n",
      "Epoch: 13, Index: 262, Loss: 0.4715\n",
      "Epoch: 13, Index: 263, Loss: 0.1877\n",
      "Epoch: 13, Index: 264, Loss: 1.2725\n",
      "Epoch: 13, Index: 265, Loss: 2.3852\n",
      "Epoch: 13, Index: 266, Loss: 1.8401\n",
      "Epoch: 13, Index: 267, Loss: 1.3703\n",
      "Epoch: 13, Index: 268, Loss: 0.0935\n",
      "Epoch: 13, Index: 269, Loss: 1.5413\n",
      "Epoch: 13, Index: 270, Loss: 0.5808\n",
      "Epoch: 13, Index: 271, Loss: 0.6232\n",
      "Epoch: 13, Index: 272, Loss: 0.9718\n",
      "Epoch: 13, Index: 273, Loss: 0.1790\n",
      "Epoch: 13, Index: 274, Loss: 1.3413\n",
      "Epoch: 13, Index: 275, Loss: 0.5185\n",
      "Epoch: 13, Index: 276, Loss: 3.4484\n",
      "Epoch: 13, Index: 277, Loss: 0.4574\n",
      "Epoch: 13, Index: 278, Loss: 1.0438\n",
      "Epoch: 13, Index: 279, Loss: 2.6632\n",
      "Epoch: 13, Index: 280, Loss: 0.6248\n",
      "Epoch: 13, Index: 281, Loss: 3.9834\n",
      "Epoch: 13, Index: 282, Loss: 1.0372\n",
      "Epoch: 13, Index: 283, Loss: 0.3911\n",
      "Epoch: 13, Index: 284, Loss: 4.0515\n",
      "Epoch: 13, Index: 285, Loss: 1.8525\n",
      "Epoch: 13, Index: 286, Loss: 0.8875\n",
      "Epoch: 13, Index: 287, Loss: 0.2561\n",
      "Epoch: 13, Index: 288, Loss: 0.4365\n",
      "Epoch: 13, Index: 289, Loss: 0.0873\n",
      "Epoch: 13, Index: 290, Loss: 0.5114\n",
      "Epoch: 13, Index: 291, Loss: 0.1378\n",
      "Epoch: 13, Index: 292, Loss: 2.0361\n",
      "Epoch: 13, Index: 293, Loss: 1.2333\n",
      "Epoch: 13, Index: 294, Loss: 0.8740\n",
      "Epoch: 13, Index: 295, Loss: 4.1519\n",
      "Epoch: 13, Index: 296, Loss: 0.6966\n",
      "Epoch: 13, Index: 297, Loss: 0.5781\n",
      "Epoch: 13, Index: 298, Loss: 1.9137\n",
      "Epoch: 13, Index: 299, Loss: 2.7228\n",
      "Epoch: 13, Index: 300, Loss: 0.8957\n",
      "Epoch: 13, Index: 301, Loss: 1.4697\n",
      "Epoch: 13, Index: 302, Loss: 0.5036\n",
      "Epoch: 13, Index: 303, Loss: 2.2522\n",
      "Epoch: 13, Index: 304, Loss: 0.8577\n",
      "Epoch: 13, Index: 305, Loss: 1.2848\n",
      "Epoch: 13, Index: 306, Loss: 1.4901\n",
      "Epoch: 13, Index: 307, Loss: 1.4008\n",
      "Epoch: 13, Index: 308, Loss: 2.8104\n",
      "Epoch: 13, Index: 309, Loss: 0.0966\n",
      "Epoch: 13, Index: 310, Loss: 3.5117\n",
      "Epoch: 13, Index: 311, Loss: 1.5260\n",
      "Epoch: 13, Index: 312, Loss: 1.7895\n",
      "Epoch: 13, Index: 313, Loss: 0.4692\n",
      "Epoch: 13, Index: 314, Loss: 0.9531\n",
      "Epoch: 13, Index: 315, Loss: 0.9314\n",
      "Epoch: 13, Index: 316, Loss: 0.0637\n",
      "Epoch: 13, Index: 317, Loss: 0.1526\n",
      "Epoch: 13, Index: 318, Loss: 7.2508\n",
      "Epoch: 13, Index: 319, Loss: 0.0690\n",
      "Epoch: 13, Index: 320, Loss: 1.9247\n",
      "Epoch: 13, Index: 321, Loss: 3.0229\n",
      "Epoch: 13, Index: 322, Loss: 0.2991\n",
      "Epoch: 13, Index: 323, Loss: 8.2649\n",
      "Epoch: 13, Index: 324, Loss: 1.9051\n",
      "Epoch: 13, Index: 325, Loss: 2.5988\n",
      "Epoch: 13, Index: 326, Loss: 0.0053\n",
      "Epoch: 13, Index: 327, Loss: 2.1626\n",
      "Epoch: 13, Index: 328, Loss: 0.5211\n",
      "Epoch: 13, Index: 329, Loss: 1.0570\n",
      "Epoch: 13, Index: 330, Loss: 1.0073\n",
      "Epoch: 13, Index: 331, Loss: 0.3957\n",
      "Epoch: 13, Index: 332, Loss: 0.2257\n",
      "Epoch: 13, Index: 333, Loss: 0.2619\n",
      "Epoch: 13, Index: 334, Loss: 1.7682\n",
      "Epoch: 13, Index: 335, Loss: 1.5060\n",
      "Epoch: 13, Index: 336, Loss: 1.1399\n",
      "Epoch: 13, Index: 337, Loss: 0.1009\n",
      "Epoch: 13, Index: 338, Loss: 3.0371\n",
      "Epoch: 13, Index: 339, Loss: 4.4094\n",
      "Epoch: 13, Index: 340, Loss: 3.6547\n",
      "Epoch: 13, Index: 341, Loss: 0.6547\n",
      "Epoch: 13, Index: 342, Loss: 3.8839\n",
      "Epoch: 13, Index: 343, Loss: 2.6321\n",
      "Epoch: 13, Index: 344, Loss: 0.3288\n",
      "Epoch: 13, Index: 345, Loss: 3.2782\n",
      "Epoch: 13, Index: 346, Loss: 0.7919\n",
      "Epoch: 13, Index: 347, Loss: 6.9782\n",
      "Epoch: 13, Index: 348, Loss: 8.9797\n",
      "Epoch: 13, Index: 349, Loss: 3.7412\n",
      "Epoch: 13, Index: 350, Loss: 8.1938\n",
      "Epoch: 13, Index: 351, Loss: 1.7617\n",
      "Epoch: 13, Index: 352, Loss: 0.2789\n",
      "Epoch: 13, Index: 353, Loss: 1.7293\n",
      "Epoch: 13, Index: 354, Loss: 1.6339\n",
      "Epoch: 13, Index: 355, Loss: 3.2517\n",
      "Epoch: 13, Index: 356, Loss: 2.4536\n",
      "Epoch: 13, Index: 357, Loss: 6.5241\n",
      "Epoch: 13, Index: 358, Loss: 2.6757\n",
      "Epoch: 13, Index: 359, Loss: 1.7660\n",
      "Epoch: 13, Index: 360, Loss: 3.2702\n",
      "Epoch: 13, Index: 361, Loss: 2.3070\n",
      "Epoch: 13, Index: 362, Loss: 2.6956\n",
      "Epoch: 13, Index: 363, Loss: 1.1010\n",
      "Epoch: 13, Index: 364, Loss: 3.6932\n",
      "Epoch: 13, Index: 365, Loss: 3.0699\n",
      "Epoch: 13, Index: 366, Loss: 0.8148\n",
      "Epoch: 13, Index: 367, Loss: 0.0860\n",
      "Epoch: 13, Index: 368, Loss: 2.0656\n",
      "Epoch: 13, Index: 369, Loss: 0.7570\n",
      "Epoch: 13, Index: 370, Loss: 2.0007\n",
      "Epoch: 13, Index: 371, Loss: 1.0138\n",
      "Epoch: 13, Index: 372, Loss: 1.4133\n",
      "Epoch: 13, Index: 373, Loss: 2.0880\n",
      "Epoch: 13, Index: 374, Loss: 1.4030\n",
      "Epoch: 13, Index: 375, Loss: 1.3287\n",
      "Epoch: 13, Index: 376, Loss: 8.2643\n",
      "Epoch: 13, Index: 377, Loss: 2.8388\n",
      "Epoch: 13, Index: 378, Loss: 15.5706\n",
      "Epoch: 13, Index: 379, Loss: 1.6990\n",
      "Epoch: 13, Index: 380, Loss: 0.6462\n",
      "Epoch: 13, Index: 381, Loss: 0.8636\n",
      "Epoch: 13, Index: 382, Loss: 1.3135\n",
      "Epoch: 13, Index: 383, Loss: 1.4150\n",
      "Epoch: 13, Index: 384, Loss: 1.2808\n",
      "Epoch: 13, Index: 385, Loss: 0.9240\n",
      "Epoch: 13, Index: 386, Loss: 3.4932\n",
      "Epoch: 13, Index: 387, Loss: 0.0232\n",
      "Epoch: 13, Index: 388, Loss: 0.7494\n",
      "Epoch: 13, Index: 389, Loss: 1.7318\n",
      "Epoch: 13, Index: 390, Loss: 0.5349\n",
      "Epoch: 13, Index: 391, Loss: 0.0356\n",
      "Epoch: 13, Index: 392, Loss: 0.9221\n",
      "Epoch: 13, Index: 393, Loss: 0.2644\n",
      "Epoch: 13, Index: 394, Loss: 3.5357\n",
      "Epoch: 13, Index: 395, Loss: 1.5836\n",
      "Epoch: 13, Index: 396, Loss: 0.0778\n",
      "Epoch: 13, Index: 397, Loss: 1.9536\n",
      "Epoch: 13, Index: 398, Loss: 1.3801\n",
      "Epoch: 13, Index: 399, Loss: 0.1289\n",
      "Epoch: 13, Index: 400, Loss: 1.3219\n",
      "Epoch: 13, Index: 401, Loss: 0.1175\n",
      "Epoch: 13, Index: 402, Loss: 4.2374\n",
      "Epoch: 13, Index: 403, Loss: 0.0939\n",
      "Epoch: 13, Index: 404, Loss: 0.2465\n",
      "Epoch: 13, Index: 405, Loss: 0.1059\n",
      "Epoch: 13, Index: 406, Loss: 0.5623\n",
      "Epoch: 13, Index: 407, Loss: 1.6051\n",
      "Epoch: 13, Index: 408, Loss: 0.7745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d596f841284b8da75d16d6976b24c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Index: 0, Loss: 1.0517\n",
      "Epoch: 14, Index: 1, Loss: 0.5169\n",
      "Epoch: 14, Index: 2, Loss: 0.7388\n",
      "Epoch: 14, Index: 3, Loss: 1.4301\n",
      "Epoch: 14, Index: 4, Loss: 2.7177\n",
      "Epoch: 14, Index: 5, Loss: 0.5231\n",
      "Epoch: 14, Index: 6, Loss: 1.5590\n",
      "Epoch: 14, Index: 7, Loss: 2.3403\n",
      "Epoch: 14, Index: 8, Loss: 0.2018\n",
      "Epoch: 14, Index: 9, Loss: 0.0387\n",
      "Epoch: 14, Index: 10, Loss: 2.4709\n",
      "Epoch: 14, Index: 11, Loss: 3.7665\n",
      "Epoch: 14, Index: 12, Loss: 0.5584\n",
      "Epoch: 14, Index: 13, Loss: 1.8105\n",
      "Epoch: 14, Index: 14, Loss: 3.9303\n",
      "Epoch: 14, Index: 15, Loss: 0.3769\n",
      "Epoch: 14, Index: 16, Loss: 1.4920\n",
      "Epoch: 14, Index: 17, Loss: 2.3780\n",
      "Epoch: 14, Index: 18, Loss: 1.0419\n",
      "Epoch: 14, Index: 19, Loss: 1.1517\n",
      "Epoch: 14, Index: 20, Loss: 0.3776\n",
      "Epoch: 14, Index: 21, Loss: 1.5481\n",
      "Epoch: 14, Index: 22, Loss: 0.3395\n",
      "Epoch: 14, Index: 23, Loss: 2.4067\n",
      "Epoch: 14, Index: 24, Loss: 1.8055\n",
      "Epoch: 14, Index: 25, Loss: 1.9869\n",
      "Epoch: 14, Index: 26, Loss: 3.8700\n",
      "Epoch: 14, Index: 27, Loss: 8.2553\n",
      "Epoch: 14, Index: 28, Loss: 7.8613\n",
      "Epoch: 14, Index: 29, Loss: 2.3592\n",
      "Epoch: 14, Index: 30, Loss: 0.6984\n",
      "Epoch: 14, Index: 31, Loss: 1.4026\n",
      "Epoch: 14, Index: 32, Loss: 3.7340\n",
      "Epoch: 14, Index: 33, Loss: 0.4904\n",
      "Epoch: 14, Index: 34, Loss: 2.2362\n",
      "Epoch: 14, Index: 35, Loss: 4.3500\n",
      "Epoch: 14, Index: 36, Loss: 0.4986\n",
      "Epoch: 14, Index: 37, Loss: 0.4366\n",
      "Epoch: 14, Index: 38, Loss: 1.3939\n",
      "Epoch: 14, Index: 39, Loss: 3.9883\n",
      "Epoch: 14, Index: 40, Loss: 2.9112\n",
      "Epoch: 14, Index: 41, Loss: 1.3255\n",
      "Epoch: 14, Index: 42, Loss: 5.0744\n",
      "Epoch: 14, Index: 43, Loss: 1.2466\n",
      "Epoch: 14, Index: 44, Loss: 0.4592\n",
      "Epoch: 14, Index: 45, Loss: 0.5596\n",
      "Epoch: 14, Index: 46, Loss: 2.6882\n",
      "Epoch: 14, Index: 47, Loss: 2.7240\n",
      "Epoch: 14, Index: 48, Loss: 0.1490\n",
      "Epoch: 14, Index: 49, Loss: 1.8549\n",
      "Epoch: 14, Index: 50, Loss: 0.0103\n",
      "Epoch: 14, Index: 51, Loss: 2.7809\n",
      "Epoch: 14, Index: 52, Loss: 3.0995\n",
      "Epoch: 14, Index: 53, Loss: 1.7072\n",
      "Epoch: 14, Index: 54, Loss: 1.0910\n",
      "Epoch: 14, Index: 55, Loss: 2.9021\n",
      "Epoch: 14, Index: 56, Loss: 0.9026\n",
      "Epoch: 14, Index: 57, Loss: 2.6158\n",
      "Epoch: 14, Index: 58, Loss: 1.6087\n",
      "Epoch: 14, Index: 59, Loss: 2.5258\n",
      "Epoch: 14, Index: 60, Loss: 0.2479\n",
      "Epoch: 14, Index: 61, Loss: 0.6476\n",
      "Epoch: 14, Index: 62, Loss: 1.8192\n",
      "Epoch: 14, Index: 63, Loss: 0.7752\n",
      "Epoch: 14, Index: 64, Loss: 0.1621\n",
      "Epoch: 14, Index: 65, Loss: 1.0354\n",
      "Epoch: 14, Index: 66, Loss: 3.3785\n",
      "Epoch: 14, Index: 67, Loss: 0.4150\n",
      "Epoch: 14, Index: 68, Loss: 3.8569\n",
      "Epoch: 14, Index: 69, Loss: 0.0612\n",
      "Epoch: 14, Index: 70, Loss: 7.9008\n",
      "Epoch: 14, Index: 71, Loss: 0.4940\n",
      "Epoch: 14, Index: 72, Loss: 3.6693\n",
      "Epoch: 14, Index: 73, Loss: 1.3138\n",
      "Epoch: 14, Index: 74, Loss: 1.0947\n",
      "Epoch: 14, Index: 75, Loss: 0.2346\n",
      "Epoch: 14, Index: 76, Loss: 3.7748\n",
      "Epoch: 14, Index: 77, Loss: 0.2598\n",
      "Epoch: 14, Index: 78, Loss: 0.9999\n",
      "Epoch: 14, Index: 79, Loss: 1.2201\n",
      "Epoch: 14, Index: 80, Loss: 0.2789\n",
      "Epoch: 14, Index: 81, Loss: 2.9221\n",
      "Epoch: 14, Index: 82, Loss: 0.1736\n",
      "Epoch: 14, Index: 83, Loss: 0.9852\n",
      "Epoch: 14, Index: 84, Loss: 14.1637\n",
      "Epoch: 14, Index: 85, Loss: 2.3419\n",
      "Epoch: 14, Index: 86, Loss: 0.4568\n",
      "Epoch: 14, Index: 87, Loss: 2.3827\n",
      "Epoch: 14, Index: 88, Loss: 0.6859\n",
      "Epoch: 14, Index: 89, Loss: 0.9368\n",
      "Epoch: 14, Index: 90, Loss: 4.3906\n",
      "Epoch: 14, Index: 91, Loss: 4.4812\n",
      "Epoch: 14, Index: 92, Loss: 3.6113\n",
      "Epoch: 14, Index: 93, Loss: 2.8005\n",
      "Epoch: 14, Index: 94, Loss: 1.1433\n",
      "Epoch: 14, Index: 95, Loss: 0.6689\n",
      "Epoch: 14, Index: 96, Loss: 3.4088\n",
      "Epoch: 14, Index: 97, Loss: 0.4209\n",
      "Epoch: 14, Index: 98, Loss: 1.3820\n",
      "Epoch: 14, Index: 99, Loss: 1.2744\n",
      "Epoch: 14, Index: 100, Loss: 4.1039\n",
      "Epoch: 14, Index: 101, Loss: 0.9397\n",
      "Epoch: 14, Index: 102, Loss: 1.7009\n",
      "Epoch: 14, Index: 103, Loss: 2.1309\n",
      "Epoch: 14, Index: 104, Loss: 1.0049\n",
      "Epoch: 14, Index: 105, Loss: 2.4474\n",
      "Epoch: 14, Index: 106, Loss: 2.7380\n",
      "Epoch: 14, Index: 107, Loss: 0.3209\n",
      "Epoch: 14, Index: 108, Loss: 2.1754\n",
      "Epoch: 14, Index: 109, Loss: 0.0048\n",
      "Epoch: 14, Index: 110, Loss: 4.7301\n",
      "Epoch: 14, Index: 111, Loss: 6.8315\n",
      "Epoch: 14, Index: 112, Loss: 1.0795\n",
      "Epoch: 14, Index: 113, Loss: 0.9080\n",
      "Epoch: 14, Index: 114, Loss: 0.6415\n",
      "Epoch: 14, Index: 115, Loss: 0.1988\n",
      "Epoch: 14, Index: 116, Loss: 0.5416\n",
      "Epoch: 14, Index: 117, Loss: 0.9088\n",
      "Epoch: 14, Index: 118, Loss: 4.8835\n",
      "Epoch: 14, Index: 119, Loss: 0.0348\n",
      "Epoch: 14, Index: 120, Loss: 1.7645\n",
      "Epoch: 14, Index: 121, Loss: 0.9455\n",
      "Epoch: 14, Index: 122, Loss: 7.9425\n",
      "Epoch: 14, Index: 123, Loss: 1.3900\n",
      "Epoch: 14, Index: 124, Loss: 2.3419\n",
      "Epoch: 14, Index: 125, Loss: 0.3519\n",
      "Epoch: 14, Index: 126, Loss: 1.6299\n",
      "Epoch: 14, Index: 127, Loss: 0.0364\n",
      "Epoch: 14, Index: 128, Loss: 0.7861\n",
      "Epoch: 14, Index: 129, Loss: 1.9559\n",
      "Epoch: 14, Index: 130, Loss: 0.0409\n",
      "Epoch: 14, Index: 131, Loss: 1.3273\n",
      "Epoch: 14, Index: 132, Loss: 0.6104\n",
      "Epoch: 14, Index: 133, Loss: 19.0383\n",
      "Epoch: 14, Index: 134, Loss: 0.9159\n",
      "Epoch: 14, Index: 135, Loss: 2.3611\n",
      "Epoch: 14, Index: 136, Loss: 0.3870\n",
      "Epoch: 14, Index: 137, Loss: 1.9336\n",
      "Epoch: 14, Index: 138, Loss: 6.8019\n",
      "Epoch: 14, Index: 139, Loss: 0.8760\n",
      "Epoch: 14, Index: 140, Loss: 0.3704\n",
      "Epoch: 14, Index: 141, Loss: 2.2158\n",
      "Epoch: 14, Index: 142, Loss: 0.7558\n",
      "Epoch: 14, Index: 143, Loss: 2.7878\n",
      "Epoch: 14, Index: 144, Loss: 1.9313\n",
      "Epoch: 14, Index: 145, Loss: 3.7854\n",
      "Epoch: 14, Index: 146, Loss: 2.8671\n",
      "Epoch: 14, Index: 147, Loss: 0.8166\n",
      "Epoch: 14, Index: 148, Loss: 1.4033\n",
      "Epoch: 14, Index: 149, Loss: 0.9259\n",
      "Epoch: 14, Index: 150, Loss: 2.5729\n",
      "Epoch: 14, Index: 151, Loss: 1.6418\n",
      "Epoch: 14, Index: 152, Loss: 0.8489\n",
      "Epoch: 14, Index: 153, Loss: 0.2423\n",
      "Epoch: 14, Index: 154, Loss: 0.6030\n",
      "Epoch: 14, Index: 155, Loss: 0.3015\n",
      "Epoch: 14, Index: 156, Loss: 0.0777\n",
      "Epoch: 14, Index: 157, Loss: 0.1454\n",
      "Epoch: 14, Index: 158, Loss: 2.1181\n",
      "Epoch: 14, Index: 159, Loss: 4.6700\n",
      "Epoch: 14, Index: 160, Loss: 1.1158\n",
      "Epoch: 14, Index: 161, Loss: 0.8425\n",
      "Epoch: 14, Index: 162, Loss: 0.0578\n",
      "Epoch: 14, Index: 163, Loss: 9.2749\n",
      "Epoch: 14, Index: 164, Loss: 0.2533\n",
      "Epoch: 14, Index: 165, Loss: 0.3909\n",
      "Epoch: 14, Index: 166, Loss: 5.1395\n",
      "Epoch: 14, Index: 167, Loss: 3.1347\n",
      "Epoch: 14, Index: 168, Loss: 1.3193\n",
      "Epoch: 14, Index: 169, Loss: 0.4785\n",
      "Epoch: 14, Index: 170, Loss: 1.6697\n",
      "Epoch: 14, Index: 171, Loss: 1.7965\n",
      "Epoch: 14, Index: 172, Loss: 1.0413\n",
      "Epoch: 14, Index: 173, Loss: 0.0504\n",
      "Epoch: 14, Index: 174, Loss: 5.9800\n",
      "Epoch: 14, Index: 175, Loss: 8.3745\n",
      "Epoch: 14, Index: 176, Loss: 0.8555\n",
      "Epoch: 14, Index: 177, Loss: 0.0434\n",
      "Epoch: 14, Index: 178, Loss: 4.4651\n",
      "Epoch: 14, Index: 179, Loss: 2.0288\n",
      "Epoch: 14, Index: 180, Loss: 0.6110\n",
      "Epoch: 14, Index: 181, Loss: 0.1466\n",
      "Epoch: 14, Index: 182, Loss: 1.1924\n",
      "Epoch: 14, Index: 183, Loss: 1.1900\n",
      "Epoch: 14, Index: 184, Loss: 0.2424\n",
      "Epoch: 14, Index: 185, Loss: 2.4290\n",
      "Epoch: 14, Index: 186, Loss: 2.7682\n",
      "Epoch: 14, Index: 187, Loss: 1.2344\n",
      "Epoch: 14, Index: 188, Loss: 0.1154\n",
      "Epoch: 14, Index: 189, Loss: 2.1942\n",
      "Epoch: 14, Index: 190, Loss: 10.0383\n",
      "Epoch: 14, Index: 191, Loss: 0.0981\n",
      "Epoch: 14, Index: 192, Loss: 0.8272\n",
      "Epoch: 14, Index: 193, Loss: 1.1584\n",
      "Epoch: 14, Index: 194, Loss: 0.5508\n",
      "Epoch: 14, Index: 195, Loss: 0.0076\n",
      "Epoch: 14, Index: 196, Loss: 1.2872\n",
      "Epoch: 14, Index: 197, Loss: 0.2666\n",
      "Epoch: 14, Index: 198, Loss: 2.0882\n",
      "Epoch: 14, Index: 199, Loss: 0.2093\n",
      "Epoch: 14, Index: 200, Loss: 3.0877\n",
      "Epoch: 14, Index: 201, Loss: 5.5176\n",
      "Epoch: 14, Index: 202, Loss: 7.7118\n",
      "Epoch: 14, Index: 203, Loss: 0.8867\n",
      "Epoch: 14, Index: 204, Loss: 3.4408\n",
      "Epoch: 14, Index: 205, Loss: 1.3607\n",
      "Epoch: 14, Index: 206, Loss: 2.6604\n",
      "Epoch: 14, Index: 207, Loss: 5.9900\n",
      "Epoch: 14, Index: 208, Loss: 6.2573\n",
      "Epoch: 14, Index: 209, Loss: 0.5743\n",
      "Epoch: 14, Index: 210, Loss: 3.4791\n",
      "Epoch: 14, Index: 211, Loss: 2.4790\n",
      "Epoch: 14, Index: 212, Loss: 2.0139\n",
      "Epoch: 14, Index: 213, Loss: 3.6516\n",
      "Epoch: 14, Index: 214, Loss: 0.7623\n",
      "Epoch: 14, Index: 215, Loss: 0.3808\n",
      "Epoch: 14, Index: 216, Loss: 2.0472\n",
      "Epoch: 14, Index: 217, Loss: 0.2545\n",
      "Epoch: 14, Index: 218, Loss: 1.6734\n",
      "Epoch: 14, Index: 219, Loss: 4.1216\n",
      "Epoch: 14, Index: 220, Loss: 1.0773\n",
      "Epoch: 14, Index: 221, Loss: 0.7578\n",
      "Epoch: 14, Index: 222, Loss: 0.4955\n",
      "Epoch: 14, Index: 223, Loss: 1.1761\n",
      "Epoch: 14, Index: 224, Loss: 0.1977\n",
      "Epoch: 14, Index: 225, Loss: 0.3586\n",
      "Epoch: 14, Index: 226, Loss: 0.0669\n",
      "Epoch: 14, Index: 227, Loss: 1.8525\n",
      "Epoch: 14, Index: 228, Loss: 9.0654\n",
      "Epoch: 14, Index: 229, Loss: 2.7634\n",
      "Epoch: 14, Index: 230, Loss: 1.7091\n",
      "Epoch: 14, Index: 231, Loss: 1.8950\n",
      "Epoch: 14, Index: 232, Loss: 1.1741\n",
      "Epoch: 14, Index: 233, Loss: 0.5620\n",
      "Epoch: 14, Index: 234, Loss: 1.5365\n",
      "Epoch: 14, Index: 235, Loss: 3.1952\n",
      "Epoch: 14, Index: 236, Loss: 1.4007\n",
      "Epoch: 14, Index: 237, Loss: 1.0867\n",
      "Epoch: 14, Index: 238, Loss: 2.1888\n",
      "Epoch: 14, Index: 239, Loss: 4.2060\n",
      "Epoch: 14, Index: 240, Loss: 1.9601\n",
      "Epoch: 14, Index: 241, Loss: 1.3141\n",
      "Epoch: 14, Index: 242, Loss: 1.5761\n",
      "Epoch: 14, Index: 243, Loss: 3.2759\n",
      "Epoch: 14, Index: 244, Loss: 1.5671\n",
      "Epoch: 14, Index: 245, Loss: 0.9902\n",
      "Epoch: 14, Index: 246, Loss: 1.4919\n",
      "Epoch: 14, Index: 247, Loss: 0.0800\n",
      "Epoch: 14, Index: 248, Loss: 0.3851\n",
      "Epoch: 14, Index: 249, Loss: 0.2223\n",
      "Epoch: 14, Index: 250, Loss: 2.0709\n",
      "Epoch: 14, Index: 251, Loss: 0.4846\n",
      "Epoch: 14, Index: 252, Loss: 6.1379\n",
      "Epoch: 14, Index: 253, Loss: 1.1184\n",
      "Epoch: 14, Index: 254, Loss: 2.8452\n",
      "Epoch: 14, Index: 255, Loss: 3.6017\n",
      "Epoch: 14, Index: 256, Loss: 2.1213\n",
      "Epoch: 14, Index: 257, Loss: 0.0180\n",
      "Epoch: 14, Index: 258, Loss: 2.1748\n",
      "Epoch: 14, Index: 259, Loss: 0.3980\n",
      "Epoch: 14, Index: 260, Loss: 3.2483\n",
      "Epoch: 14, Index: 261, Loss: 0.1676\n",
      "Epoch: 14, Index: 262, Loss: 2.8851\n",
      "Epoch: 14, Index: 263, Loss: 0.6750\n",
      "Epoch: 14, Index: 264, Loss: 0.4645\n",
      "Epoch: 14, Index: 265, Loss: 1.6162\n",
      "Epoch: 14, Index: 266, Loss: 5.4386\n",
      "Epoch: 14, Index: 267, Loss: 0.7227\n",
      "Epoch: 14, Index: 268, Loss: 1.7650\n",
      "Epoch: 14, Index: 269, Loss: 0.9144\n",
      "Epoch: 14, Index: 270, Loss: 1.5880\n",
      "Epoch: 14, Index: 271, Loss: 0.3907\n",
      "Epoch: 14, Index: 272, Loss: 1.3039\n",
      "Epoch: 14, Index: 273, Loss: 1.7643\n",
      "Epoch: 14, Index: 274, Loss: 0.0702\n",
      "Epoch: 14, Index: 275, Loss: 0.9007\n",
      "Epoch: 14, Index: 276, Loss: 3.5466\n",
      "Epoch: 14, Index: 277, Loss: 0.1868\n",
      "Epoch: 14, Index: 278, Loss: 0.3585\n",
      "Epoch: 14, Index: 279, Loss: 1.0088\n",
      "Epoch: 14, Index: 280, Loss: 0.2918\n",
      "Epoch: 14, Index: 281, Loss: 0.5212\n",
      "Epoch: 14, Index: 282, Loss: 0.6504\n",
      "Epoch: 14, Index: 283, Loss: 0.9928\n",
      "Epoch: 14, Index: 284, Loss: 0.1474\n",
      "Epoch: 14, Index: 285, Loss: 0.9182\n",
      "Epoch: 14, Index: 286, Loss: 1.2119\n",
      "Epoch: 14, Index: 287, Loss: 0.1274\n",
      "Epoch: 14, Index: 288, Loss: 9.2143\n",
      "Epoch: 14, Index: 289, Loss: 1.0032\n",
      "Epoch: 14, Index: 290, Loss: 4.1706\n",
      "Epoch: 14, Index: 291, Loss: 4.6585\n",
      "Epoch: 14, Index: 292, Loss: 0.4556\n",
      "Epoch: 14, Index: 293, Loss: 1.8803\n",
      "Epoch: 14, Index: 294, Loss: 0.2014\n",
      "Epoch: 14, Index: 295, Loss: 0.4408\n",
      "Epoch: 14, Index: 296, Loss: 0.2273\n",
      "Epoch: 14, Index: 297, Loss: 1.2024\n",
      "Epoch: 14, Index: 298, Loss: 0.6347\n",
      "Epoch: 14, Index: 299, Loss: 0.7539\n",
      "Epoch: 14, Index: 300, Loss: 1.7906\n",
      "Epoch: 14, Index: 301, Loss: 0.6115\n",
      "Epoch: 14, Index: 302, Loss: 0.3918\n",
      "Epoch: 14, Index: 303, Loss: 1.2272\n",
      "Epoch: 14, Index: 304, Loss: 1.0018\n",
      "Epoch: 14, Index: 305, Loss: 2.2005\n",
      "Epoch: 14, Index: 306, Loss: 2.4691\n",
      "Epoch: 14, Index: 307, Loss: 2.0392\n",
      "Epoch: 14, Index: 308, Loss: 1.5084\n",
      "Epoch: 14, Index: 309, Loss: 1.1986\n",
      "Epoch: 14, Index: 310, Loss: 2.3633\n",
      "Epoch: 14, Index: 311, Loss: 0.7100\n",
      "Epoch: 14, Index: 312, Loss: 2.7367\n",
      "Epoch: 14, Index: 313, Loss: 0.1869\n",
      "Epoch: 14, Index: 314, Loss: 1.3939\n",
      "Epoch: 14, Index: 315, Loss: 0.3101\n",
      "Epoch: 14, Index: 316, Loss: 0.5271\n",
      "Epoch: 14, Index: 317, Loss: 0.0081\n",
      "Epoch: 14, Index: 318, Loss: 0.9605\n",
      "Epoch: 14, Index: 319, Loss: 3.5782\n",
      "Epoch: 14, Index: 320, Loss: 1.5520\n",
      "Epoch: 14, Index: 321, Loss: 5.3317\n",
      "Epoch: 14, Index: 322, Loss: 1.0361\n",
      "Epoch: 14, Index: 323, Loss: 0.7498\n",
      "Epoch: 14, Index: 324, Loss: 2.0106\n",
      "Epoch: 14, Index: 325, Loss: 5.1642\n",
      "Epoch: 14, Index: 326, Loss: 2.9542\n",
      "Epoch: 14, Index: 327, Loss: 0.4871\n",
      "Epoch: 14, Index: 328, Loss: 0.5519\n",
      "Epoch: 14, Index: 329, Loss: 2.0481\n",
      "Epoch: 14, Index: 330, Loss: 1.4685\n",
      "Epoch: 14, Index: 331, Loss: 1.0488\n",
      "Epoch: 14, Index: 332, Loss: 0.5976\n",
      "Epoch: 14, Index: 333, Loss: 0.1419\n",
      "Epoch: 14, Index: 334, Loss: 1.0842\n",
      "Epoch: 14, Index: 335, Loss: 0.5124\n",
      "Epoch: 14, Index: 336, Loss: 1.2514\n",
      "Epoch: 14, Index: 337, Loss: 0.2302\n",
      "Epoch: 14, Index: 338, Loss: 3.5979\n",
      "Epoch: 14, Index: 339, Loss: 1.7737\n",
      "Epoch: 14, Index: 340, Loss: 0.0867\n",
      "Epoch: 14, Index: 341, Loss: 1.2792\n",
      "Epoch: 14, Index: 342, Loss: 0.8655\n",
      "Epoch: 14, Index: 343, Loss: 0.1038\n",
      "Epoch: 14, Index: 344, Loss: 1.9061\n",
      "Epoch: 14, Index: 345, Loss: 1.4152\n",
      "Epoch: 14, Index: 346, Loss: 0.6729\n",
      "Epoch: 14, Index: 347, Loss: 1.1192\n",
      "Epoch: 14, Index: 348, Loss: 1.3967\n",
      "Epoch: 14, Index: 349, Loss: 0.4251\n",
      "Epoch: 14, Index: 350, Loss: 0.1368\n",
      "Epoch: 14, Index: 351, Loss: 0.2381\n",
      "Epoch: 14, Index: 352, Loss: 2.2125\n",
      "Epoch: 14, Index: 353, Loss: 1.6479\n",
      "Epoch: 14, Index: 354, Loss: 0.0242\n",
      "Epoch: 14, Index: 355, Loss: 0.5606\n",
      "Epoch: 14, Index: 356, Loss: 4.1526\n",
      "Epoch: 14, Index: 357, Loss: 3.6914\n",
      "Epoch: 14, Index: 358, Loss: 1.9271\n",
      "Epoch: 14, Index: 359, Loss: 3.8546\n",
      "Epoch: 14, Index: 360, Loss: 0.5603\n",
      "Epoch: 14, Index: 361, Loss: 1.0592\n",
      "Epoch: 14, Index: 362, Loss: 0.5284\n",
      "Epoch: 14, Index: 363, Loss: 5.0136\n",
      "Epoch: 14, Index: 364, Loss: 1.6131\n",
      "Epoch: 14, Index: 365, Loss: 2.4301\n",
      "Epoch: 14, Index: 366, Loss: 1.8030\n",
      "Epoch: 14, Index: 367, Loss: 2.8473\n",
      "Epoch: 14, Index: 368, Loss: 1.5973\n",
      "Epoch: 14, Index: 369, Loss: 3.8151\n",
      "Epoch: 14, Index: 370, Loss: 2.9313\n",
      "Epoch: 14, Index: 371, Loss: 3.0099\n",
      "Epoch: 14, Index: 372, Loss: 0.6722\n",
      "Epoch: 14, Index: 373, Loss: 1.4967\n",
      "Epoch: 14, Index: 374, Loss: 0.7513\n",
      "Epoch: 14, Index: 375, Loss: 1.2794\n",
      "Epoch: 14, Index: 376, Loss: 1.8312\n",
      "Epoch: 14, Index: 377, Loss: 0.2062\n",
      "Epoch: 14, Index: 378, Loss: 1.6510\n",
      "Epoch: 14, Index: 379, Loss: 0.5359\n",
      "Epoch: 14, Index: 380, Loss: 0.7683\n",
      "Epoch: 14, Index: 381, Loss: 2.9266\n",
      "Epoch: 14, Index: 382, Loss: 0.4836\n",
      "Epoch: 14, Index: 383, Loss: 2.6341\n",
      "Epoch: 14, Index: 384, Loss: 2.3545\n",
      "Epoch: 14, Index: 385, Loss: 3.1340\n",
      "Epoch: 14, Index: 386, Loss: 2.4830\n",
      "Epoch: 14, Index: 387, Loss: 0.2740\n",
      "Epoch: 14, Index: 388, Loss: 0.5206\n",
      "Epoch: 14, Index: 389, Loss: 1.2688\n",
      "Epoch: 14, Index: 390, Loss: 0.8699\n",
      "Epoch: 14, Index: 391, Loss: 1.5080\n",
      "Epoch: 14, Index: 392, Loss: 1.0531\n",
      "Epoch: 14, Index: 393, Loss: 0.7276\n",
      "Epoch: 14, Index: 394, Loss: 0.3255\n",
      "Epoch: 14, Index: 395, Loss: 0.4436\n",
      "Epoch: 14, Index: 396, Loss: 0.3152\n",
      "Epoch: 14, Index: 397, Loss: 1.4790\n",
      "Epoch: 14, Index: 398, Loss: 0.0582\n",
      "Epoch: 14, Index: 399, Loss: 1.5282\n",
      "Epoch: 14, Index: 400, Loss: 1.5548\n",
      "Epoch: 14, Index: 401, Loss: 3.1549\n",
      "Epoch: 14, Index: 402, Loss: 1.5314\n",
      "Epoch: 14, Index: 403, Loss: 0.0099\n",
      "Epoch: 14, Index: 404, Loss: 0.5834\n",
      "Epoch: 14, Index: 405, Loss: 0.3197\n",
      "Epoch: 14, Index: 406, Loss: 0.1765\n",
      "Epoch: 14, Index: 407, Loss: 0.4782\n",
      "Epoch: 14, Index: 408, Loss: 3.3371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e027f9b1d04930aaa2f4da8d92ee91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Index: 0, Loss: 2.0656\n",
      "Epoch: 15, Index: 1, Loss: 1.2056\n",
      "Epoch: 15, Index: 2, Loss: 3.1756\n",
      "Epoch: 15, Index: 3, Loss: 1.6535\n",
      "Epoch: 15, Index: 4, Loss: 1.2012\n",
      "Epoch: 15, Index: 5, Loss: 1.6542\n",
      "Epoch: 15, Index: 6, Loss: 1.7886\n",
      "Epoch: 15, Index: 7, Loss: 0.7446\n",
      "Epoch: 15, Index: 8, Loss: 2.4615\n",
      "Epoch: 15, Index: 9, Loss: 10.1108\n",
      "Epoch: 15, Index: 10, Loss: 0.2817\n",
      "Epoch: 15, Index: 11, Loss: 0.6096\n",
      "Epoch: 15, Index: 12, Loss: 0.4095\n",
      "Epoch: 15, Index: 13, Loss: 1.8825\n",
      "Epoch: 15, Index: 14, Loss: 0.4282\n",
      "Epoch: 15, Index: 15, Loss: 1.0297\n",
      "Epoch: 15, Index: 16, Loss: 0.0854\n",
      "Epoch: 15, Index: 17, Loss: 0.4591\n",
      "Epoch: 15, Index: 18, Loss: 0.6786\n",
      "Epoch: 15, Index: 19, Loss: 0.1533\n",
      "Epoch: 15, Index: 20, Loss: 5.6937\n",
      "Epoch: 15, Index: 21, Loss: 0.5615\n",
      "Epoch: 15, Index: 22, Loss: 1.0569\n",
      "Epoch: 15, Index: 23, Loss: 0.9472\n",
      "Epoch: 15, Index: 24, Loss: 2.0197\n",
      "Epoch: 15, Index: 25, Loss: 1.6437\n",
      "Epoch: 15, Index: 26, Loss: 0.8259\n",
      "Epoch: 15, Index: 27, Loss: 0.6336\n",
      "Epoch: 15, Index: 28, Loss: 0.5254\n",
      "Epoch: 15, Index: 29, Loss: 2.4612\n",
      "Epoch: 15, Index: 30, Loss: 2.6885\n",
      "Epoch: 15, Index: 31, Loss: 0.7056\n",
      "Epoch: 15, Index: 32, Loss: 1.3843\n",
      "Epoch: 15, Index: 33, Loss: 1.2747\n",
      "Epoch: 15, Index: 34, Loss: 0.1646\n",
      "Epoch: 15, Index: 35, Loss: 0.8033\n",
      "Epoch: 15, Index: 36, Loss: 4.4652\n",
      "Epoch: 15, Index: 37, Loss: 3.3745\n",
      "Epoch: 15, Index: 38, Loss: 0.0234\n",
      "Epoch: 15, Index: 39, Loss: 1.2512\n",
      "Epoch: 15, Index: 40, Loss: 1.2760\n",
      "Epoch: 15, Index: 41, Loss: 0.4604\n",
      "Epoch: 15, Index: 42, Loss: 0.1210\n",
      "Epoch: 15, Index: 43, Loss: 2.1511\n",
      "Epoch: 15, Index: 44, Loss: 7.0106\n",
      "Epoch: 15, Index: 45, Loss: 2.9215\n",
      "Epoch: 15, Index: 46, Loss: 3.7577\n",
      "Epoch: 15, Index: 47, Loss: 0.6027\n",
      "Epoch: 15, Index: 48, Loss: 9.0660\n",
      "Epoch: 15, Index: 49, Loss: 0.0860\n",
      "Epoch: 15, Index: 50, Loss: 2.8996\n",
      "Epoch: 15, Index: 51, Loss: 0.3505\n",
      "Epoch: 15, Index: 52, Loss: 1.6309\n",
      "Epoch: 15, Index: 53, Loss: 0.4538\n",
      "Epoch: 15, Index: 54, Loss: 0.1045\n",
      "Epoch: 15, Index: 55, Loss: 1.8523\n",
      "Epoch: 15, Index: 56, Loss: 1.9426\n",
      "Epoch: 15, Index: 57, Loss: 1.8945\n",
      "Epoch: 15, Index: 58, Loss: 3.0111\n",
      "Epoch: 15, Index: 59, Loss: 2.2817\n",
      "Epoch: 15, Index: 60, Loss: 0.5372\n",
      "Epoch: 15, Index: 61, Loss: 0.7218\n",
      "Epoch: 15, Index: 62, Loss: 1.7527\n",
      "Epoch: 15, Index: 63, Loss: 1.1201\n",
      "Epoch: 15, Index: 64, Loss: 0.6589\n",
      "Epoch: 15, Index: 65, Loss: 0.7719\n",
      "Epoch: 15, Index: 66, Loss: 3.9226\n",
      "Epoch: 15, Index: 67, Loss: 1.1962\n",
      "Epoch: 15, Index: 68, Loss: 0.0234\n",
      "Epoch: 15, Index: 69, Loss: 1.0928\n",
      "Epoch: 15, Index: 70, Loss: 0.3052\n",
      "Epoch: 15, Index: 71, Loss: 0.3099\n",
      "Epoch: 15, Index: 72, Loss: 2.8786\n",
      "Epoch: 15, Index: 73, Loss: 0.9605\n",
      "Epoch: 15, Index: 74, Loss: 8.3535\n",
      "Epoch: 15, Index: 75, Loss: 0.1146\n",
      "Epoch: 15, Index: 76, Loss: 6.3715\n",
      "Epoch: 15, Index: 77, Loss: 0.3878\n",
      "Epoch: 15, Index: 78, Loss: 3.8474\n",
      "Epoch: 15, Index: 79, Loss: 1.8953\n",
      "Epoch: 15, Index: 80, Loss: 4.1704\n",
      "Epoch: 15, Index: 81, Loss: 1.8958\n",
      "Epoch: 15, Index: 82, Loss: 0.0460\n",
      "Epoch: 15, Index: 83, Loss: 0.2365\n",
      "Epoch: 15, Index: 84, Loss: 1.3082\n",
      "Epoch: 15, Index: 85, Loss: 1.2659\n",
      "Epoch: 15, Index: 86, Loss: 1.9172\n",
      "Epoch: 15, Index: 87, Loss: 0.7570\n",
      "Epoch: 15, Index: 88, Loss: 5.8652\n",
      "Epoch: 15, Index: 89, Loss: 4.2035\n",
      "Epoch: 15, Index: 90, Loss: 0.2236\n",
      "Epoch: 15, Index: 91, Loss: 1.4182\n",
      "Epoch: 15, Index: 92, Loss: 2.4264\n",
      "Epoch: 15, Index: 93, Loss: 0.0367\n",
      "Epoch: 15, Index: 94, Loss: 3.3430\n",
      "Epoch: 15, Index: 95, Loss: 0.5074\n",
      "Epoch: 15, Index: 96, Loss: 5.0956\n",
      "Epoch: 15, Index: 97, Loss: 1.6092\n",
      "Epoch: 15, Index: 98, Loss: 0.6767\n",
      "Epoch: 15, Index: 99, Loss: 1.9806\n",
      "Epoch: 15, Index: 100, Loss: 1.9694\n",
      "Epoch: 15, Index: 101, Loss: 1.8509\n",
      "Epoch: 15, Index: 102, Loss: 7.7712\n",
      "Epoch: 15, Index: 103, Loss: 0.1591\n",
      "Epoch: 15, Index: 104, Loss: 2.1573\n",
      "Epoch: 15, Index: 105, Loss: 1.1614\n",
      "Epoch: 15, Index: 106, Loss: 8.9887\n",
      "Epoch: 15, Index: 107, Loss: 1.7446\n",
      "Epoch: 15, Index: 108, Loss: 1.0213\n",
      "Epoch: 15, Index: 109, Loss: 3.4837\n",
      "Epoch: 15, Index: 110, Loss: 0.7365\n",
      "Epoch: 15, Index: 111, Loss: 1.2899\n",
      "Epoch: 15, Index: 112, Loss: 1.1247\n",
      "Epoch: 15, Index: 113, Loss: 4.1638\n",
      "Epoch: 15, Index: 114, Loss: 1.5155\n",
      "Epoch: 15, Index: 115, Loss: 2.5764\n",
      "Epoch: 15, Index: 116, Loss: 0.9419\n",
      "Epoch: 15, Index: 117, Loss: 0.6401\n",
      "Epoch: 15, Index: 118, Loss: 2.0924\n",
      "Epoch: 15, Index: 119, Loss: 0.7590\n",
      "Epoch: 15, Index: 120, Loss: 1.8623\n",
      "Epoch: 15, Index: 121, Loss: 1.4804\n",
      "Epoch: 15, Index: 122, Loss: 0.6978\n",
      "Epoch: 15, Index: 123, Loss: 1.8929\n",
      "Epoch: 15, Index: 124, Loss: 0.4426\n",
      "Epoch: 15, Index: 125, Loss: 0.5983\n",
      "Epoch: 15, Index: 126, Loss: 4.5398\n",
      "Epoch: 15, Index: 127, Loss: 0.4072\n",
      "Epoch: 15, Index: 128, Loss: 2.9306\n",
      "Epoch: 15, Index: 129, Loss: 0.6043\n",
      "Epoch: 15, Index: 130, Loss: 0.0323\n",
      "Epoch: 15, Index: 131, Loss: 0.1257\n",
      "Epoch: 15, Index: 132, Loss: 1.8498\n",
      "Epoch: 15, Index: 133, Loss: 3.1325\n",
      "Epoch: 15, Index: 134, Loss: 6.1890\n",
      "Epoch: 15, Index: 135, Loss: 0.3085\n",
      "Epoch: 15, Index: 136, Loss: 1.3746\n",
      "Epoch: 15, Index: 137, Loss: 1.9445\n",
      "Epoch: 15, Index: 138, Loss: 1.0124\n",
      "Epoch: 15, Index: 139, Loss: 0.0264\n",
      "Epoch: 15, Index: 140, Loss: 2.4304\n",
      "Epoch: 15, Index: 141, Loss: 1.7954\n",
      "Epoch: 15, Index: 142, Loss: 2.2399\n",
      "Epoch: 15, Index: 143, Loss: 1.5487\n",
      "Epoch: 15, Index: 144, Loss: 0.3693\n",
      "Epoch: 15, Index: 145, Loss: 0.4612\n",
      "Epoch: 15, Index: 146, Loss: 0.3858\n",
      "Epoch: 15, Index: 147, Loss: 0.8002\n",
      "Epoch: 15, Index: 148, Loss: 1.1606\n",
      "Epoch: 15, Index: 149, Loss: 3.7684\n",
      "Epoch: 15, Index: 150, Loss: 1.4090\n",
      "Epoch: 15, Index: 151, Loss: 0.4696\n",
      "Epoch: 15, Index: 152, Loss: 3.2258\n",
      "Epoch: 15, Index: 153, Loss: 0.3920\n",
      "Epoch: 15, Index: 154, Loss: 1.4801\n",
      "Epoch: 15, Index: 155, Loss: 2.7987\n",
      "Epoch: 15, Index: 156, Loss: 2.1657\n",
      "Epoch: 15, Index: 157, Loss: 0.7198\n",
      "Epoch: 15, Index: 158, Loss: 2.0228\n",
      "Epoch: 15, Index: 159, Loss: 0.4933\n",
      "Epoch: 15, Index: 160, Loss: 4.7752\n",
      "Epoch: 15, Index: 161, Loss: 0.0595\n",
      "Epoch: 15, Index: 162, Loss: 0.7389\n",
      "Epoch: 15, Index: 163, Loss: 3.1177\n",
      "Epoch: 15, Index: 164, Loss: 3.1675\n",
      "Epoch: 15, Index: 165, Loss: 1.3402\n",
      "Epoch: 15, Index: 166, Loss: 0.1540\n",
      "Epoch: 15, Index: 167, Loss: 0.0614\n",
      "Epoch: 15, Index: 168, Loss: 0.4673\n",
      "Epoch: 15, Index: 169, Loss: 0.2561\n",
      "Epoch: 15, Index: 170, Loss: 3.5285\n",
      "Epoch: 15, Index: 171, Loss: 0.1349\n",
      "Epoch: 15, Index: 172, Loss: 5.1532\n",
      "Epoch: 15, Index: 173, Loss: 0.2544\n",
      "Epoch: 15, Index: 174, Loss: 0.5729\n",
      "Epoch: 15, Index: 175, Loss: 3.7338\n",
      "Epoch: 15, Index: 176, Loss: 0.8420\n",
      "Epoch: 15, Index: 177, Loss: 3.0181\n",
      "Epoch: 15, Index: 178, Loss: 0.5875\n",
      "Epoch: 15, Index: 179, Loss: 1.7446\n",
      "Epoch: 15, Index: 180, Loss: 2.0361\n",
      "Epoch: 15, Index: 181, Loss: 2.0959\n",
      "Epoch: 15, Index: 182, Loss: 2.1525\n",
      "Epoch: 15, Index: 183, Loss: 1.3761\n",
      "Epoch: 15, Index: 184, Loss: 4.2902\n",
      "Epoch: 15, Index: 185, Loss: 0.7861\n",
      "Epoch: 15, Index: 186, Loss: 2.2632\n",
      "Epoch: 15, Index: 187, Loss: 1.0846\n",
      "Epoch: 15, Index: 188, Loss: 1.3868\n",
      "Epoch: 15, Index: 189, Loss: 3.8821\n",
      "Epoch: 15, Index: 190, Loss: 0.9137\n",
      "Epoch: 15, Index: 191, Loss: 0.4348\n",
      "Epoch: 15, Index: 192, Loss: 1.4357\n",
      "Epoch: 15, Index: 193, Loss: 2.9113\n",
      "Epoch: 15, Index: 194, Loss: 0.8959\n",
      "Epoch: 15, Index: 195, Loss: 0.6466\n",
      "Epoch: 15, Index: 196, Loss: 2.4637\n",
      "Epoch: 15, Index: 197, Loss: 1.1816\n",
      "Epoch: 15, Index: 198, Loss: 1.6264\n",
      "Epoch: 15, Index: 199, Loss: 0.0042\n",
      "Epoch: 15, Index: 200, Loss: 0.9615\n",
      "Epoch: 15, Index: 201, Loss: 0.2532\n",
      "Epoch: 15, Index: 202, Loss: 0.9671\n",
      "Epoch: 15, Index: 203, Loss: 0.0961\n",
      "Epoch: 15, Index: 204, Loss: 1.0150\n",
      "Epoch: 15, Index: 205, Loss: 1.8066\n",
      "Epoch: 15, Index: 206, Loss: 0.0932\n",
      "Epoch: 15, Index: 207, Loss: 14.7990\n",
      "Epoch: 15, Index: 208, Loss: 0.0808\n",
      "Epoch: 15, Index: 209, Loss: 0.0074\n",
      "Epoch: 15, Index: 210, Loss: 2.2650\n",
      "Epoch: 15, Index: 211, Loss: 0.9046\n",
      "Epoch: 15, Index: 212, Loss: 0.2437\n",
      "Epoch: 15, Index: 213, Loss: 0.0095\n",
      "Epoch: 15, Index: 214, Loss: 2.0287\n",
      "Epoch: 15, Index: 215, Loss: 0.2482\n",
      "Epoch: 15, Index: 216, Loss: 3.2073\n",
      "Epoch: 15, Index: 217, Loss: 0.5254\n",
      "Epoch: 15, Index: 218, Loss: 1.5530\n",
      "Epoch: 15, Index: 219, Loss: 0.9542\n",
      "Epoch: 15, Index: 220, Loss: 1.9693\n",
      "Epoch: 15, Index: 221, Loss: 0.9597\n",
      "Epoch: 15, Index: 222, Loss: 2.6544\n",
      "Epoch: 15, Index: 223, Loss: 2.4436\n",
      "Epoch: 15, Index: 224, Loss: 2.5402\n",
      "Epoch: 15, Index: 225, Loss: 0.7128\n",
      "Epoch: 15, Index: 226, Loss: 7.1183\n",
      "Epoch: 15, Index: 227, Loss: 0.4212\n",
      "Epoch: 15, Index: 228, Loss: 2.5806\n",
      "Epoch: 15, Index: 229, Loss: 0.1972\n",
      "Epoch: 15, Index: 230, Loss: 1.4830\n",
      "Epoch: 15, Index: 231, Loss: 2.0188\n",
      "Epoch: 15, Index: 232, Loss: 1.7516\n",
      "Epoch: 15, Index: 233, Loss: 1.4052\n",
      "Epoch: 15, Index: 234, Loss: 1.1723\n",
      "Epoch: 15, Index: 235, Loss: 3.6742\n",
      "Epoch: 15, Index: 236, Loss: 0.6925\n",
      "Epoch: 15, Index: 237, Loss: 1.2215\n",
      "Epoch: 15, Index: 238, Loss: 8.1609\n",
      "Epoch: 15, Index: 239, Loss: 3.3186\n",
      "Epoch: 15, Index: 240, Loss: 2.8133\n",
      "Epoch: 15, Index: 241, Loss: 6.5784\n",
      "Epoch: 15, Index: 242, Loss: 2.1546\n",
      "Epoch: 15, Index: 243, Loss: 0.3300\n",
      "Epoch: 15, Index: 244, Loss: 0.6385\n",
      "Epoch: 15, Index: 245, Loss: 1.5866\n",
      "Epoch: 15, Index: 246, Loss: 4.3609\n",
      "Epoch: 15, Index: 247, Loss: 0.8376\n",
      "Epoch: 15, Index: 248, Loss: 2.1729\n",
      "Epoch: 15, Index: 249, Loss: 1.1959\n",
      "Epoch: 15, Index: 250, Loss: 1.6644\n",
      "Epoch: 15, Index: 251, Loss: 2.4511\n",
      "Epoch: 15, Index: 252, Loss: 0.6408\n",
      "Epoch: 15, Index: 253, Loss: 3.0575\n",
      "Epoch: 15, Index: 254, Loss: 0.6808\n",
      "Epoch: 15, Index: 255, Loss: 4.4787\n",
      "Epoch: 15, Index: 256, Loss: 2.1461\n",
      "Epoch: 15, Index: 257, Loss: 2.5836\n",
      "Epoch: 15, Index: 258, Loss: 3.8410\n",
      "Epoch: 15, Index: 259, Loss: 2.4420\n",
      "Epoch: 15, Index: 260, Loss: 1.2506\n",
      "Epoch: 15, Index: 261, Loss: 0.3314\n",
      "Epoch: 15, Index: 262, Loss: 2.2833\n",
      "Epoch: 15, Index: 263, Loss: 0.2933\n",
      "Epoch: 15, Index: 264, Loss: 0.4740\n",
      "Epoch: 15, Index: 265, Loss: 0.4063\n",
      "Epoch: 15, Index: 266, Loss: 1.5653\n",
      "Epoch: 15, Index: 267, Loss: 0.9491\n",
      "Epoch: 15, Index: 268, Loss: 0.7537\n",
      "Epoch: 15, Index: 269, Loss: 1.6847\n",
      "Epoch: 15, Index: 270, Loss: 0.7009\n",
      "Epoch: 15, Index: 271, Loss: 0.6301\n",
      "Epoch: 15, Index: 272, Loss: 1.7026\n",
      "Epoch: 15, Index: 273, Loss: 3.2500\n",
      "Epoch: 15, Index: 274, Loss: 0.5936\n",
      "Epoch: 15, Index: 275, Loss: 3.3559\n",
      "Epoch: 15, Index: 276, Loss: 4.8063\n",
      "Epoch: 15, Index: 277, Loss: 1.1253\n",
      "Epoch: 15, Index: 278, Loss: 2.0469\n",
      "Epoch: 15, Index: 279, Loss: 0.9726\n",
      "Epoch: 15, Index: 280, Loss: 0.7007\n",
      "Epoch: 15, Index: 281, Loss: 0.8533\n",
      "Epoch: 15, Index: 282, Loss: 1.0430\n",
      "Epoch: 15, Index: 283, Loss: 1.6979\n",
      "Epoch: 15, Index: 284, Loss: 3.4516\n",
      "Epoch: 15, Index: 285, Loss: 0.3036\n",
      "Epoch: 15, Index: 286, Loss: 1.7747\n",
      "Epoch: 15, Index: 287, Loss: 0.1251\n",
      "Epoch: 15, Index: 288, Loss: 1.0302\n",
      "Epoch: 15, Index: 289, Loss: 2.2086\n",
      "Epoch: 15, Index: 290, Loss: 0.9800\n",
      "Epoch: 15, Index: 291, Loss: 0.1022\n",
      "Epoch: 15, Index: 292, Loss: 3.5091\n",
      "Epoch: 15, Index: 293, Loss: 0.0170\n",
      "Epoch: 15, Index: 294, Loss: 3.5931\n",
      "Epoch: 15, Index: 295, Loss: 1.8361\n",
      "Epoch: 15, Index: 296, Loss: 0.0784\n",
      "Epoch: 15, Index: 297, Loss: 0.2209\n",
      "Epoch: 15, Index: 298, Loss: 1.7151\n",
      "Epoch: 15, Index: 299, Loss: 1.9250\n",
      "Epoch: 15, Index: 300, Loss: 0.2639\n",
      "Epoch: 15, Index: 301, Loss: 1.2217\n",
      "Epoch: 15, Index: 302, Loss: 0.0444\n",
      "Epoch: 15, Index: 303, Loss: 1.3602\n",
      "Epoch: 15, Index: 304, Loss: 0.4882\n",
      "Epoch: 15, Index: 305, Loss: 0.3775\n",
      "Epoch: 15, Index: 306, Loss: 0.5448\n",
      "Epoch: 15, Index: 307, Loss: 0.2733\n",
      "Epoch: 15, Index: 308, Loss: 1.7037\n",
      "Epoch: 15, Index: 309, Loss: 0.3477\n",
      "Epoch: 15, Index: 310, Loss: 3.2612\n",
      "Epoch: 15, Index: 311, Loss: 0.3759\n",
      "Epoch: 15, Index: 312, Loss: 3.1919\n",
      "Epoch: 15, Index: 313, Loss: 4.1271\n",
      "Epoch: 15, Index: 314, Loss: 0.0074\n",
      "Epoch: 15, Index: 315, Loss: 0.1279\n",
      "Epoch: 15, Index: 316, Loss: 0.1531\n",
      "Epoch: 15, Index: 317, Loss: 3.5214\n",
      "Epoch: 15, Index: 318, Loss: 0.3099\n",
      "Epoch: 15, Index: 319, Loss: 0.5184\n",
      "Epoch: 15, Index: 320, Loss: 1.6506\n",
      "Epoch: 15, Index: 321, Loss: 1.2002\n",
      "Epoch: 15, Index: 322, Loss: 5.8924\n",
      "Epoch: 15, Index: 323, Loss: 1.9271\n",
      "Epoch: 15, Index: 324, Loss: 1.7706\n",
      "Epoch: 15, Index: 325, Loss: 1.9728\n",
      "Epoch: 15, Index: 326, Loss: 0.8553\n",
      "Epoch: 15, Index: 327, Loss: 0.3716\n",
      "Epoch: 15, Index: 328, Loss: 0.2725\n",
      "Epoch: 15, Index: 329, Loss: 1.8576\n",
      "Epoch: 15, Index: 330, Loss: 0.2907\n",
      "Epoch: 15, Index: 331, Loss: 2.8214\n",
      "Epoch: 15, Index: 332, Loss: 0.2416\n",
      "Epoch: 15, Index: 333, Loss: 1.1318\n",
      "Epoch: 15, Index: 334, Loss: 1.5826\n",
      "Epoch: 15, Index: 335, Loss: 3.0706\n",
      "Epoch: 15, Index: 336, Loss: 0.0715\n",
      "Epoch: 15, Index: 337, Loss: 1.0992\n",
      "Epoch: 15, Index: 338, Loss: 0.0850\n",
      "Epoch: 15, Index: 339, Loss: 4.9173\n",
      "Epoch: 15, Index: 340, Loss: 1.7024\n",
      "Epoch: 15, Index: 341, Loss: 0.3317\n",
      "Epoch: 15, Index: 342, Loss: 1.3109\n",
      "Epoch: 15, Index: 343, Loss: 3.1107\n",
      "Epoch: 15, Index: 344, Loss: 1.3079\n",
      "Epoch: 15, Index: 345, Loss: 0.3295\n",
      "Epoch: 15, Index: 346, Loss: 3.3615\n",
      "Epoch: 15, Index: 347, Loss: 4.1511\n",
      "Epoch: 15, Index: 348, Loss: 1.0597\n",
      "Epoch: 15, Index: 349, Loss: 2.2318\n",
      "Epoch: 15, Index: 350, Loss: 0.6603\n",
      "Epoch: 15, Index: 351, Loss: 3.0120\n",
      "Epoch: 15, Index: 352, Loss: 2.4433\n",
      "Epoch: 15, Index: 353, Loss: 0.3690\n",
      "Epoch: 15, Index: 354, Loss: 1.5598\n",
      "Epoch: 15, Index: 355, Loss: 1.6556\n",
      "Epoch: 15, Index: 356, Loss: 0.4887\n",
      "Epoch: 15, Index: 357, Loss: 1.6114\n",
      "Epoch: 15, Index: 358, Loss: 1.5772\n",
      "Epoch: 15, Index: 359, Loss: 4.9042\n",
      "Epoch: 15, Index: 360, Loss: 1.5541\n",
      "Epoch: 15, Index: 361, Loss: 0.9518\n",
      "Epoch: 15, Index: 362, Loss: 5.6007\n",
      "Epoch: 15, Index: 363, Loss: 0.0740\n",
      "Epoch: 15, Index: 364, Loss: 0.7029\n",
      "Epoch: 15, Index: 365, Loss: 1.6176\n",
      "Epoch: 15, Index: 366, Loss: 1.2898\n",
      "Epoch: 15, Index: 367, Loss: 5.1383\n",
      "Epoch: 15, Index: 368, Loss: 1.6788\n",
      "Epoch: 15, Index: 369, Loss: 2.0586\n",
      "Epoch: 15, Index: 370, Loss: 2.4273\n",
      "Epoch: 15, Index: 371, Loss: 2.3091\n",
      "Epoch: 15, Index: 372, Loss: 0.1474\n",
      "Epoch: 15, Index: 373, Loss: 0.5616\n",
      "Epoch: 15, Index: 374, Loss: 0.6025\n",
      "Epoch: 15, Index: 375, Loss: 1.1257\n",
      "Epoch: 15, Index: 376, Loss: 0.9680\n",
      "Epoch: 15, Index: 377, Loss: 0.6388\n",
      "Epoch: 15, Index: 378, Loss: 1.2384\n",
      "Epoch: 15, Index: 379, Loss: 0.8541\n",
      "Epoch: 15, Index: 380, Loss: 4.7653\n",
      "Epoch: 15, Index: 381, Loss: 1.1521\n",
      "Epoch: 15, Index: 382, Loss: 0.2130\n",
      "Epoch: 15, Index: 383, Loss: 0.2222\n",
      "Epoch: 15, Index: 384, Loss: 6.5398\n",
      "Epoch: 15, Index: 385, Loss: 0.1694\n",
      "Epoch: 15, Index: 386, Loss: 0.6401\n",
      "Epoch: 15, Index: 387, Loss: 0.5782\n",
      "Epoch: 15, Index: 388, Loss: 0.7656\n",
      "Epoch: 15, Index: 389, Loss: 1.5887\n",
      "Epoch: 15, Index: 390, Loss: 18.1993\n",
      "Epoch: 15, Index: 391, Loss: 0.7493\n",
      "Epoch: 15, Index: 392, Loss: 1.6019\n",
      "Epoch: 15, Index: 393, Loss: 2.4506\n",
      "Epoch: 15, Index: 394, Loss: 0.8876\n",
      "Epoch: 15, Index: 395, Loss: 1.2435\n",
      "Epoch: 15, Index: 396, Loss: 0.9731\n",
      "Epoch: 15, Index: 397, Loss: 0.5172\n",
      "Epoch: 15, Index: 398, Loss: 2.2722\n",
      "Epoch: 15, Index: 399, Loss: 1.8095\n",
      "Epoch: 15, Index: 400, Loss: 5.5728\n",
      "Epoch: 15, Index: 401, Loss: 2.2612\n",
      "Epoch: 15, Index: 402, Loss: 1.5562\n",
      "Epoch: 15, Index: 403, Loss: 0.2616\n",
      "Epoch: 15, Index: 404, Loss: 1.5211\n",
      "Epoch: 15, Index: 405, Loss: 0.1749\n",
      "Epoch: 15, Index: 406, Loss: 0.0044\n",
      "Epoch: 15, Index: 407, Loss: 1.2847\n",
      "Epoch: 15, Index: 408, Loss: 1.3949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa73de228d740cdba0ec732a55d9731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Index: 0, Loss: 1.6643\n",
      "Epoch: 16, Index: 1, Loss: 1.8404\n",
      "Epoch: 16, Index: 2, Loss: 0.0050\n",
      "Epoch: 16, Index: 3, Loss: 0.1621\n",
      "Epoch: 16, Index: 4, Loss: 0.4376\n",
      "Epoch: 16, Index: 5, Loss: 2.3450\n",
      "Epoch: 16, Index: 6, Loss: 0.3048\n",
      "Epoch: 16, Index: 7, Loss: 3.1787\n",
      "Epoch: 16, Index: 8, Loss: 1.1677\n",
      "Epoch: 16, Index: 9, Loss: 0.5284\n",
      "Epoch: 16, Index: 10, Loss: 1.1314\n",
      "Epoch: 16, Index: 11, Loss: 0.2989\n",
      "Epoch: 16, Index: 12, Loss: 0.7546\n",
      "Epoch: 16, Index: 13, Loss: 0.8279\n",
      "Epoch: 16, Index: 14, Loss: 0.3698\n",
      "Epoch: 16, Index: 15, Loss: 2.1881\n",
      "Epoch: 16, Index: 16, Loss: 1.7211\n",
      "Epoch: 16, Index: 17, Loss: 0.1010\n",
      "Epoch: 16, Index: 18, Loss: 1.6006\n",
      "Epoch: 16, Index: 19, Loss: 5.7522\n",
      "Epoch: 16, Index: 20, Loss: 3.4055\n",
      "Epoch: 16, Index: 21, Loss: 0.2057\n",
      "Epoch: 16, Index: 22, Loss: 0.1095\n",
      "Epoch: 16, Index: 23, Loss: 4.6952\n",
      "Epoch: 16, Index: 24, Loss: 0.5314\n",
      "Epoch: 16, Index: 25, Loss: 1.7283\n",
      "Epoch: 16, Index: 26, Loss: 0.0867\n",
      "Epoch: 16, Index: 27, Loss: 1.0168\n",
      "Epoch: 16, Index: 28, Loss: 3.1415\n",
      "Epoch: 16, Index: 29, Loss: 0.6529\n",
      "Epoch: 16, Index: 30, Loss: 4.0713\n",
      "Epoch: 16, Index: 31, Loss: 0.0045\n",
      "Epoch: 16, Index: 32, Loss: 0.6363\n",
      "Epoch: 16, Index: 33, Loss: 1.8229\n",
      "Epoch: 16, Index: 34, Loss: 3.8548\n",
      "Epoch: 16, Index: 35, Loss: 1.1732\n",
      "Epoch: 16, Index: 36, Loss: 0.0523\n",
      "Epoch: 16, Index: 37, Loss: 0.7182\n",
      "Epoch: 16, Index: 38, Loss: 0.6703\n",
      "Epoch: 16, Index: 39, Loss: 2.9648\n",
      "Epoch: 16, Index: 40, Loss: 5.4965\n",
      "Epoch: 16, Index: 41, Loss: 0.5114\n",
      "Epoch: 16, Index: 42, Loss: 1.1603\n",
      "Epoch: 16, Index: 43, Loss: 0.5600\n",
      "Epoch: 16, Index: 44, Loss: 0.6838\n",
      "Epoch: 16, Index: 45, Loss: 0.6420\n",
      "Epoch: 16, Index: 46, Loss: 2.3767\n",
      "Epoch: 16, Index: 47, Loss: 1.6564\n",
      "Epoch: 16, Index: 48, Loss: 2.6489\n",
      "Epoch: 16, Index: 49, Loss: 0.1087\n",
      "Epoch: 16, Index: 50, Loss: 0.6285\n",
      "Epoch: 16, Index: 51, Loss: 2.0180\n",
      "Epoch: 16, Index: 52, Loss: 1.9157\n",
      "Epoch: 16, Index: 53, Loss: 2.3501\n",
      "Epoch: 16, Index: 54, Loss: 0.4689\n",
      "Epoch: 16, Index: 55, Loss: 17.9246\n",
      "Epoch: 16, Index: 56, Loss: 1.5794\n",
      "Epoch: 16, Index: 57, Loss: 0.9559\n",
      "Epoch: 16, Index: 58, Loss: 2.0881\n",
      "Epoch: 16, Index: 59, Loss: 10.0676\n",
      "Epoch: 16, Index: 60, Loss: 1.3086\n",
      "Epoch: 16, Index: 61, Loss: 1.2337\n",
      "Epoch: 16, Index: 62, Loss: 1.0109\n",
      "Epoch: 16, Index: 63, Loss: 1.4863\n",
      "Epoch: 16, Index: 64, Loss: 2.0027\n",
      "Epoch: 16, Index: 65, Loss: 0.1963\n",
      "Epoch: 16, Index: 66, Loss: 2.1770\n",
      "Epoch: 16, Index: 67, Loss: 0.6663\n",
      "Epoch: 16, Index: 68, Loss: 0.8296\n",
      "Epoch: 16, Index: 69, Loss: 0.6756\n",
      "Epoch: 16, Index: 70, Loss: 1.9356\n",
      "Epoch: 16, Index: 71, Loss: 0.2053\n",
      "Epoch: 16, Index: 72, Loss: 2.7154\n",
      "Epoch: 16, Index: 73, Loss: 0.0815\n",
      "Epoch: 16, Index: 74, Loss: 5.6502\n",
      "Epoch: 16, Index: 75, Loss: 4.3720\n",
      "Epoch: 16, Index: 76, Loss: 0.1633\n",
      "Epoch: 16, Index: 77, Loss: 5.0740\n",
      "Epoch: 16, Index: 78, Loss: 1.7830\n",
      "Epoch: 16, Index: 79, Loss: 0.1664\n",
      "Epoch: 16, Index: 80, Loss: 0.7797\n",
      "Epoch: 16, Index: 81, Loss: 3.3192\n",
      "Epoch: 16, Index: 82, Loss: 6.6077\n",
      "Epoch: 16, Index: 83, Loss: 3.4560\n",
      "Epoch: 16, Index: 84, Loss: 2.0005\n",
      "Epoch: 16, Index: 85, Loss: 1.1519\n",
      "Epoch: 16, Index: 86, Loss: 0.3513\n",
      "Epoch: 16, Index: 87, Loss: 0.8207\n",
      "Epoch: 16, Index: 88, Loss: 0.7432\n",
      "Epoch: 16, Index: 89, Loss: 2.3428\n",
      "Epoch: 16, Index: 90, Loss: 4.9103\n",
      "Epoch: 16, Index: 91, Loss: 7.2199\n",
      "Epoch: 16, Index: 92, Loss: 2.6803\n",
      "Epoch: 16, Index: 93, Loss: 0.4538\n",
      "Epoch: 16, Index: 94, Loss: 2.8542\n",
      "Epoch: 16, Index: 95, Loss: 1.8412\n",
      "Epoch: 16, Index: 96, Loss: 1.5158\n",
      "Epoch: 16, Index: 97, Loss: 1.6057\n",
      "Epoch: 16, Index: 98, Loss: 0.2197\n",
      "Epoch: 16, Index: 99, Loss: 0.3732\n",
      "Epoch: 16, Index: 100, Loss: 1.1285\n",
      "Epoch: 16, Index: 101, Loss: 0.2234\n",
      "Epoch: 16, Index: 102, Loss: 5.5742\n",
      "Epoch: 16, Index: 103, Loss: 0.4699\n",
      "Epoch: 16, Index: 104, Loss: 1.8438\n",
      "Epoch: 16, Index: 105, Loss: 0.1579\n",
      "Epoch: 16, Index: 106, Loss: 0.6248\n",
      "Epoch: 16, Index: 107, Loss: 0.5231\n",
      "Epoch: 16, Index: 108, Loss: 2.5711\n",
      "Epoch: 16, Index: 109, Loss: 4.0688\n",
      "Epoch: 16, Index: 110, Loss: 1.0418\n",
      "Epoch: 16, Index: 111, Loss: 0.3463\n",
      "Epoch: 16, Index: 112, Loss: 0.7484\n",
      "Epoch: 16, Index: 113, Loss: 13.4987\n",
      "Epoch: 16, Index: 114, Loss: 1.0290\n",
      "Epoch: 16, Index: 115, Loss: 0.0092\n",
      "Epoch: 16, Index: 116, Loss: 3.0801\n",
      "Epoch: 16, Index: 117, Loss: 2.5311\n",
      "Epoch: 16, Index: 118, Loss: 2.3510\n",
      "Epoch: 16, Index: 119, Loss: 0.9678\n",
      "Epoch: 16, Index: 120, Loss: 0.0314\n",
      "Epoch: 16, Index: 121, Loss: 2.2461\n",
      "Epoch: 16, Index: 122, Loss: 1.7973\n",
      "Epoch: 16, Index: 123, Loss: 2.9220\n",
      "Epoch: 16, Index: 124, Loss: 1.3254\n",
      "Epoch: 16, Index: 125, Loss: 1.7416\n",
      "Epoch: 16, Index: 126, Loss: 1.2068\n",
      "Epoch: 16, Index: 127, Loss: 1.9046\n",
      "Epoch: 16, Index: 128, Loss: 2.0881\n",
      "Epoch: 16, Index: 129, Loss: 0.8974\n",
      "Epoch: 16, Index: 130, Loss: 2.1665\n",
      "Epoch: 16, Index: 131, Loss: 0.1784\n",
      "Epoch: 16, Index: 132, Loss: 3.2293\n",
      "Epoch: 16, Index: 133, Loss: 1.3948\n",
      "Epoch: 16, Index: 134, Loss: 4.6380\n",
      "Epoch: 16, Index: 135, Loss: 2.9376\n",
      "Epoch: 16, Index: 136, Loss: 3.3868\n",
      "Epoch: 16, Index: 137, Loss: 0.8036\n",
      "Epoch: 16, Index: 138, Loss: 0.0505\n",
      "Epoch: 16, Index: 139, Loss: 1.6693\n",
      "Epoch: 16, Index: 140, Loss: 1.4665\n",
      "Epoch: 16, Index: 141, Loss: 0.2620\n",
      "Epoch: 16, Index: 142, Loss: 0.1389\n",
      "Epoch: 16, Index: 143, Loss: 1.2705\n",
      "Epoch: 16, Index: 144, Loss: 0.6914\n",
      "Epoch: 16, Index: 145, Loss: 1.0824\n",
      "Epoch: 16, Index: 146, Loss: 1.9438\n",
      "Epoch: 16, Index: 147, Loss: 3.1199\n",
      "Epoch: 16, Index: 148, Loss: 3.3247\n",
      "Epoch: 16, Index: 149, Loss: 0.9710\n",
      "Epoch: 16, Index: 150, Loss: 1.5309\n",
      "Epoch: 16, Index: 151, Loss: 0.0200\n",
      "Epoch: 16, Index: 152, Loss: 0.8224\n",
      "Epoch: 16, Index: 153, Loss: 0.0395\n",
      "Epoch: 16, Index: 154, Loss: 3.3842\n",
      "Epoch: 16, Index: 155, Loss: 1.2048\n",
      "Epoch: 16, Index: 156, Loss: 0.2753\n",
      "Epoch: 16, Index: 157, Loss: 0.8349\n",
      "Epoch: 16, Index: 158, Loss: 2.0586\n",
      "Epoch: 16, Index: 159, Loss: 0.2499\n",
      "Epoch: 16, Index: 160, Loss: 0.1720\n",
      "Epoch: 16, Index: 161, Loss: 3.6055\n",
      "Epoch: 16, Index: 162, Loss: 0.7404\n",
      "Epoch: 16, Index: 163, Loss: 0.8699\n",
      "Epoch: 16, Index: 164, Loss: 0.8951\n",
      "Epoch: 16, Index: 165, Loss: 2.8878\n",
      "Epoch: 16, Index: 166, Loss: 0.7174\n",
      "Epoch: 16, Index: 167, Loss: 0.9607\n",
      "Epoch: 16, Index: 168, Loss: 0.6159\n",
      "Epoch: 16, Index: 169, Loss: 0.6453\n",
      "Epoch: 16, Index: 170, Loss: 1.1037\n",
      "Epoch: 16, Index: 171, Loss: 1.1180\n",
      "Epoch: 16, Index: 172, Loss: 0.0540\n",
      "Epoch: 16, Index: 173, Loss: 1.5226\n",
      "Epoch: 16, Index: 174, Loss: 2.0446\n",
      "Epoch: 16, Index: 175, Loss: 3.9249\n",
      "Epoch: 16, Index: 176, Loss: 0.9918\n",
      "Epoch: 16, Index: 177, Loss: 7.0347\n",
      "Epoch: 16, Index: 178, Loss: 0.8538\n",
      "Epoch: 16, Index: 179, Loss: 1.1639\n",
      "Epoch: 16, Index: 180, Loss: 0.8712\n",
      "Epoch: 16, Index: 181, Loss: 0.1526\n",
      "Epoch: 16, Index: 182, Loss: 3.9788\n",
      "Epoch: 16, Index: 183, Loss: 1.1511\n",
      "Epoch: 16, Index: 184, Loss: 4.3088\n",
      "Epoch: 16, Index: 185, Loss: 8.5551\n",
      "Epoch: 16, Index: 186, Loss: 1.0839\n",
      "Epoch: 16, Index: 187, Loss: 0.4354\n",
      "Epoch: 16, Index: 188, Loss: 2.2585\n",
      "Epoch: 16, Index: 189, Loss: 0.7123\n",
      "Epoch: 16, Index: 190, Loss: 0.4728\n",
      "Epoch: 16, Index: 191, Loss: 1.4435\n",
      "Epoch: 16, Index: 192, Loss: 1.9965\n",
      "Epoch: 16, Index: 193, Loss: 0.0440\n",
      "Epoch: 16, Index: 194, Loss: 8.5281\n",
      "Epoch: 16, Index: 195, Loss: 0.2964\n",
      "Epoch: 16, Index: 196, Loss: 0.3571\n",
      "Epoch: 16, Index: 197, Loss: 1.2725\n",
      "Epoch: 16, Index: 198, Loss: 0.6909\n",
      "Epoch: 16, Index: 199, Loss: 3.2765\n",
      "Epoch: 16, Index: 200, Loss: 4.1425\n",
      "Epoch: 16, Index: 201, Loss: 0.4937\n",
      "Epoch: 16, Index: 202, Loss: 1.9206\n",
      "Epoch: 16, Index: 203, Loss: 0.2911\n",
      "Epoch: 16, Index: 204, Loss: 6.3770\n",
      "Epoch: 16, Index: 205, Loss: 2.7493\n",
      "Epoch: 16, Index: 206, Loss: 3.8806\n",
      "Epoch: 16, Index: 207, Loss: 4.0555\n",
      "Epoch: 16, Index: 208, Loss: 0.1708\n",
      "Epoch: 16, Index: 209, Loss: 0.1376\n",
      "Epoch: 16, Index: 210, Loss: 3.6865\n",
      "Epoch: 16, Index: 211, Loss: 0.6078\n",
      "Epoch: 16, Index: 212, Loss: 0.9602\n",
      "Epoch: 16, Index: 213, Loss: 2.8982\n",
      "Epoch: 16, Index: 214, Loss: 2.0490\n",
      "Epoch: 16, Index: 215, Loss: 1.4885\n",
      "Epoch: 16, Index: 216, Loss: 4.1330\n",
      "Epoch: 16, Index: 217, Loss: 0.3776\n",
      "Epoch: 16, Index: 218, Loss: 3.0821\n",
      "Epoch: 16, Index: 219, Loss: 1.1516\n",
      "Epoch: 16, Index: 220, Loss: 1.7414\n",
      "Epoch: 16, Index: 221, Loss: 0.0717\n",
      "Epoch: 16, Index: 222, Loss: 1.1469\n",
      "Epoch: 16, Index: 223, Loss: 0.4144\n",
      "Epoch: 16, Index: 224, Loss: 8.0871\n",
      "Epoch: 16, Index: 225, Loss: 0.4202\n",
      "Epoch: 16, Index: 226, Loss: 0.7511\n",
      "Epoch: 16, Index: 227, Loss: 0.8903\n",
      "Epoch: 16, Index: 228, Loss: 3.2362\n",
      "Epoch: 16, Index: 229, Loss: 0.2599\n",
      "Epoch: 16, Index: 230, Loss: 1.1871\n",
      "Epoch: 16, Index: 231, Loss: 0.1761\n",
      "Epoch: 16, Index: 232, Loss: 1.1274\n",
      "Epoch: 16, Index: 233, Loss: 0.5074\n",
      "Epoch: 16, Index: 234, Loss: 0.9513\n",
      "Epoch: 16, Index: 235, Loss: 0.3754\n",
      "Epoch: 16, Index: 236, Loss: 0.2144\n",
      "Epoch: 16, Index: 237, Loss: 1.1663\n",
      "Epoch: 16, Index: 238, Loss: 0.0198\n",
      "Epoch: 16, Index: 239, Loss: 0.7433\n",
      "Epoch: 16, Index: 240, Loss: 0.0607\n",
      "Epoch: 16, Index: 241, Loss: 3.9879\n",
      "Epoch: 16, Index: 242, Loss: 1.0714\n",
      "Epoch: 16, Index: 243, Loss: 1.7663\n",
      "Epoch: 16, Index: 244, Loss: 0.9901\n",
      "Epoch: 16, Index: 245, Loss: 1.2017\n",
      "Epoch: 16, Index: 246, Loss: 2.7596\n",
      "Epoch: 16, Index: 247, Loss: 3.8311\n",
      "Epoch: 16, Index: 248, Loss: 2.4896\n",
      "Epoch: 16, Index: 249, Loss: 1.1695\n",
      "Epoch: 16, Index: 250, Loss: 2.6874\n",
      "Epoch: 16, Index: 251, Loss: 0.0536\n",
      "Epoch: 16, Index: 252, Loss: 0.1805\n",
      "Epoch: 16, Index: 253, Loss: 2.0570\n",
      "Epoch: 16, Index: 254, Loss: 0.3106\n",
      "Epoch: 16, Index: 255, Loss: 1.3597\n",
      "Epoch: 16, Index: 256, Loss: 0.5665\n",
      "Epoch: 16, Index: 257, Loss: 2.1048\n",
      "Epoch: 16, Index: 258, Loss: 1.7673\n",
      "Epoch: 16, Index: 259, Loss: 1.1702\n",
      "Epoch: 16, Index: 260, Loss: 1.0044\n",
      "Epoch: 16, Index: 261, Loss: 1.0366\n",
      "Epoch: 16, Index: 262, Loss: 2.5743\n",
      "Epoch: 16, Index: 263, Loss: 3.5559\n",
      "Epoch: 16, Index: 264, Loss: 0.5832\n",
      "Epoch: 16, Index: 265, Loss: 0.1854\n",
      "Epoch: 16, Index: 266, Loss: 2.5080\n",
      "Epoch: 16, Index: 267, Loss: 0.4979\n",
      "Epoch: 16, Index: 268, Loss: 2.2219\n",
      "Epoch: 16, Index: 269, Loss: 0.0629\n",
      "Epoch: 16, Index: 270, Loss: 1.3726\n",
      "Epoch: 16, Index: 271, Loss: 0.5108\n",
      "Epoch: 16, Index: 272, Loss: 1.8974\n",
      "Epoch: 16, Index: 273, Loss: 0.9998\n",
      "Epoch: 16, Index: 274, Loss: 10.4305\n",
      "Epoch: 16, Index: 275, Loss: 0.5453\n",
      "Epoch: 16, Index: 276, Loss: 4.5386\n",
      "Epoch: 16, Index: 277, Loss: 0.1365\n",
      "Epoch: 16, Index: 278, Loss: 0.3554\n",
      "Epoch: 16, Index: 279, Loss: 0.4231\n",
      "Epoch: 16, Index: 280, Loss: 2.0680\n",
      "Epoch: 16, Index: 281, Loss: 2.0441\n",
      "Epoch: 16, Index: 282, Loss: 0.0372\n",
      "Epoch: 16, Index: 283, Loss: 0.7881\n",
      "Epoch: 16, Index: 284, Loss: 4.7896\n",
      "Epoch: 16, Index: 285, Loss: 0.7398\n",
      "Epoch: 16, Index: 286, Loss: 0.2297\n",
      "Epoch: 16, Index: 287, Loss: 3.4223\n",
      "Epoch: 16, Index: 288, Loss: 1.7037\n",
      "Epoch: 16, Index: 289, Loss: 1.7669\n",
      "Epoch: 16, Index: 290, Loss: 0.6300\n",
      "Epoch: 16, Index: 291, Loss: 0.0004\n",
      "Epoch: 16, Index: 292, Loss: 4.7348\n",
      "Epoch: 16, Index: 293, Loss: 1.2175\n",
      "Epoch: 16, Index: 294, Loss: 6.2609\n",
      "Epoch: 16, Index: 295, Loss: 1.0581\n",
      "Epoch: 16, Index: 296, Loss: 9.2825\n",
      "Epoch: 16, Index: 297, Loss: 2.5050\n",
      "Epoch: 16, Index: 298, Loss: 0.2205\n",
      "Epoch: 16, Index: 299, Loss: 2.7072\n",
      "Epoch: 16, Index: 300, Loss: 0.6907\n",
      "Epoch: 16, Index: 301, Loss: 0.5088\n",
      "Epoch: 16, Index: 302, Loss: 1.4541\n",
      "Epoch: 16, Index: 303, Loss: 13.9192\n",
      "Epoch: 16, Index: 304, Loss: 2.3103\n",
      "Epoch: 16, Index: 305, Loss: 9.3218\n",
      "Epoch: 16, Index: 306, Loss: 1.6338\n",
      "Epoch: 16, Index: 307, Loss: 0.3025\n",
      "Epoch: 16, Index: 308, Loss: 0.0975\n",
      "Epoch: 16, Index: 309, Loss: 2.1520\n",
      "Epoch: 16, Index: 310, Loss: 180.8008\n",
      "Epoch: 16, Index: 311, Loss: 1.7936\n",
      "Epoch: 16, Index: 312, Loss: 1.0901\n",
      "Epoch: 16, Index: 313, Loss: 0.7691\n",
      "Epoch: 16, Index: 314, Loss: 3.4289\n",
      "Epoch: 16, Index: 315, Loss: 10.3588\n",
      "Epoch: 16, Index: 316, Loss: 0.7130\n",
      "Epoch: 16, Index: 317, Loss: 4.0603\n",
      "Epoch: 16, Index: 318, Loss: 4.0825\n",
      "Epoch: 16, Index: 319, Loss: 10.4825\n",
      "Epoch: 16, Index: 320, Loss: 15.1363\n",
      "Epoch: 16, Index: 321, Loss: 2.2253\n",
      "Epoch: 16, Index: 322, Loss: 38.3155\n",
      "Epoch: 16, Index: 323, Loss: 15.5525\n",
      "Epoch: 16, Index: 324, Loss: 16.7317\n",
      "Epoch: 16, Index: 325, Loss: 9.9230\n",
      "Epoch: 16, Index: 326, Loss: 13.7170\n",
      "Epoch: 16, Index: 327, Loss: 2.8723\n",
      "Epoch: 16, Index: 328, Loss: 5.8940\n",
      "Epoch: 16, Index: 329, Loss: 0.4484\n",
      "Epoch: 16, Index: 330, Loss: 2.7414\n",
      "Epoch: 16, Index: 331, Loss: 6.1905\n",
      "Epoch: 16, Index: 332, Loss: 4.4281\n",
      "Epoch: 16, Index: 333, Loss: 1.8867\n",
      "Epoch: 16, Index: 334, Loss: 0.1680\n",
      "Epoch: 16, Index: 335, Loss: 1.7532\n",
      "Epoch: 16, Index: 336, Loss: 7.7635\n",
      "Epoch: 16, Index: 337, Loss: 1.7246\n",
      "Epoch: 16, Index: 338, Loss: 1.3963\n",
      "Epoch: 16, Index: 339, Loss: 0.3823\n",
      "Epoch: 16, Index: 340, Loss: 0.3321\n",
      "Epoch: 16, Index: 341, Loss: 2.9671\n",
      "Epoch: 16, Index: 342, Loss: 0.8741\n",
      "Epoch: 16, Index: 343, Loss: 2.6958\n",
      "Epoch: 16, Index: 344, Loss: 2.2901\n",
      "Epoch: 16, Index: 345, Loss: 4.5489\n",
      "Epoch: 16, Index: 346, Loss: 3.5420\n",
      "Epoch: 16, Index: 347, Loss: 0.5913\n",
      "Epoch: 16, Index: 348, Loss: 3.3440\n",
      "Epoch: 16, Index: 349, Loss: 1.2660\n",
      "Epoch: 16, Index: 350, Loss: 1.9324\n",
      "Epoch: 16, Index: 351, Loss: 1.0416\n",
      "Epoch: 16, Index: 352, Loss: 1.7436\n",
      "Epoch: 16, Index: 353, Loss: 1.4959\n",
      "Epoch: 16, Index: 354, Loss: 2.2819\n",
      "Epoch: 16, Index: 355, Loss: 9.6938\n",
      "Epoch: 16, Index: 356, Loss: 1.1251\n",
      "Epoch: 16, Index: 357, Loss: 1.0483\n",
      "Epoch: 16, Index: 358, Loss: 0.4241\n",
      "Epoch: 16, Index: 359, Loss: 4.5035\n",
      "Epoch: 16, Index: 360, Loss: 2.4275\n",
      "Epoch: 16, Index: 361, Loss: 2.5694\n",
      "Epoch: 16, Index: 362, Loss: 0.6542\n",
      "Epoch: 16, Index: 363, Loss: 0.1749\n",
      "Epoch: 16, Index: 364, Loss: 4.7471\n",
      "Epoch: 16, Index: 365, Loss: 5.2252\n",
      "Epoch: 16, Index: 366, Loss: 0.8645\n",
      "Epoch: 16, Index: 367, Loss: 2.4054\n",
      "Epoch: 16, Index: 368, Loss: 8.7444\n",
      "Epoch: 16, Index: 369, Loss: 1.3707\n",
      "Epoch: 16, Index: 370, Loss: 1.4899\n",
      "Epoch: 16, Index: 371, Loss: 3.4497\n",
      "Epoch: 16, Index: 372, Loss: 0.4856\n",
      "Epoch: 16, Index: 373, Loss: 3.5426\n",
      "Epoch: 16, Index: 374, Loss: 0.1459\n",
      "Epoch: 16, Index: 375, Loss: 0.6165\n",
      "Epoch: 16, Index: 376, Loss: 0.9735\n",
      "Epoch: 16, Index: 377, Loss: 0.1233\n",
      "Epoch: 16, Index: 378, Loss: 2.2492\n",
      "Epoch: 16, Index: 379, Loss: 0.3597\n",
      "Epoch: 16, Index: 380, Loss: 1.2493\n",
      "Epoch: 16, Index: 381, Loss: 1.4375\n",
      "Epoch: 16, Index: 382, Loss: 0.3905\n",
      "Epoch: 16, Index: 383, Loss: 2.5905\n",
      "Epoch: 16, Index: 384, Loss: 0.4013\n",
      "Epoch: 16, Index: 385, Loss: 2.4285\n",
      "Epoch: 16, Index: 386, Loss: 1.7081\n",
      "Epoch: 16, Index: 387, Loss: 1.4777\n",
      "Epoch: 16, Index: 388, Loss: 3.4756\n",
      "Epoch: 16, Index: 389, Loss: 0.5243\n",
      "Epoch: 16, Index: 390, Loss: 0.0220\n",
      "Epoch: 16, Index: 391, Loss: 6.2261\n",
      "Epoch: 16, Index: 392, Loss: 4.6102\n",
      "Epoch: 16, Index: 393, Loss: 3.3944\n",
      "Epoch: 16, Index: 394, Loss: 3.6521\n",
      "Epoch: 16, Index: 395, Loss: 2.1974\n",
      "Epoch: 16, Index: 396, Loss: 0.4332\n",
      "Epoch: 16, Index: 397, Loss: 1.7563\n",
      "Epoch: 16, Index: 398, Loss: 3.7124\n",
      "Epoch: 16, Index: 399, Loss: 0.2708\n",
      "Epoch: 16, Index: 400, Loss: 0.7854\n",
      "Epoch: 16, Index: 401, Loss: 4.6841\n",
      "Epoch: 16, Index: 402, Loss: 0.7628\n",
      "Epoch: 16, Index: 403, Loss: 0.6304\n",
      "Epoch: 16, Index: 404, Loss: 2.4805\n",
      "Epoch: 16, Index: 405, Loss: 1.7037\n",
      "Epoch: 16, Index: 406, Loss: 1.8917\n",
      "Epoch: 16, Index: 407, Loss: 0.6510\n",
      "Epoch: 16, Index: 408, Loss: 1.9788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b327dbc226af47b79d939464e38746c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Index: 0, Loss: 0.1701\n",
      "Epoch: 17, Index: 1, Loss: 2.8803\n",
      "Epoch: 17, Index: 2, Loss: 6.9910\n",
      "Epoch: 17, Index: 3, Loss: 0.4804\n",
      "Epoch: 17, Index: 4, Loss: 5.0961\n",
      "Epoch: 17, Index: 5, Loss: 0.1532\n",
      "Epoch: 17, Index: 6, Loss: 2.6277\n",
      "Epoch: 17, Index: 7, Loss: 4.6166\n",
      "Epoch: 17, Index: 8, Loss: 3.9775\n",
      "Epoch: 17, Index: 9, Loss: 6.8010\n",
      "Epoch: 17, Index: 10, Loss: 9.6688\n",
      "Epoch: 17, Index: 11, Loss: 2.9278\n",
      "Epoch: 17, Index: 12, Loss: 1.0352\n",
      "Epoch: 17, Index: 13, Loss: 2.7640\n",
      "Epoch: 17, Index: 14, Loss: 0.9844\n",
      "Epoch: 17, Index: 15, Loss: 4.5845\n",
      "Epoch: 17, Index: 16, Loss: 0.0242\n",
      "Epoch: 17, Index: 17, Loss: 0.3444\n",
      "Epoch: 17, Index: 18, Loss: 2.6191\n",
      "Epoch: 17, Index: 19, Loss: 0.2424\n",
      "Epoch: 17, Index: 20, Loss: 11.4512\n",
      "Epoch: 17, Index: 21, Loss: 3.9825\n",
      "Epoch: 17, Index: 22, Loss: 2.4493\n",
      "Epoch: 17, Index: 23, Loss: 4.1878\n",
      "Epoch: 17, Index: 24, Loss: 0.3815\n",
      "Epoch: 17, Index: 25, Loss: 6.0942\n",
      "Epoch: 17, Index: 26, Loss: 6.6422\n",
      "Epoch: 17, Index: 27, Loss: 1.6877\n",
      "Epoch: 17, Index: 28, Loss: 1.8170\n",
      "Epoch: 17, Index: 29, Loss: 1.7344\n",
      "Epoch: 17, Index: 30, Loss: 4.6049\n",
      "Epoch: 17, Index: 31, Loss: 2.3388\n",
      "Epoch: 17, Index: 32, Loss: 3.1992\n",
      "Epoch: 17, Index: 33, Loss: 0.4289\n",
      "Epoch: 17, Index: 34, Loss: 0.0153\n",
      "Epoch: 17, Index: 35, Loss: 1.0697\n",
      "Epoch: 17, Index: 36, Loss: 1.8886\n",
      "Epoch: 17, Index: 37, Loss: 0.2472\n",
      "Epoch: 17, Index: 38, Loss: 0.5050\n",
      "Epoch: 17, Index: 39, Loss: 1.1260\n",
      "Epoch: 17, Index: 40, Loss: 4.8352\n",
      "Epoch: 17, Index: 41, Loss: 0.0065\n",
      "Epoch: 17, Index: 42, Loss: 1.2966\n",
      "Epoch: 17, Index: 43, Loss: 0.8548\n",
      "Epoch: 17, Index: 44, Loss: 0.8300\n",
      "Epoch: 17, Index: 45, Loss: 0.5021\n",
      "Epoch: 17, Index: 46, Loss: 0.4673\n",
      "Epoch: 17, Index: 47, Loss: 3.6342\n",
      "Epoch: 17, Index: 48, Loss: 0.2880\n",
      "Epoch: 17, Index: 49, Loss: 1.2423\n",
      "Epoch: 17, Index: 50, Loss: 1.8411\n",
      "Epoch: 17, Index: 51, Loss: 1.8760\n",
      "Epoch: 17, Index: 52, Loss: 4.3031\n",
      "Epoch: 17, Index: 53, Loss: 4.6587\n",
      "Epoch: 17, Index: 54, Loss: 1.8375\n",
      "Epoch: 17, Index: 55, Loss: 2.5936\n",
      "Epoch: 17, Index: 56, Loss: 1.0688\n",
      "Epoch: 17, Index: 57, Loss: 2.1153\n",
      "Epoch: 17, Index: 58, Loss: 1.3413\n",
      "Epoch: 17, Index: 59, Loss: 8.8143\n",
      "Epoch: 17, Index: 60, Loss: 1.6595\n",
      "Epoch: 17, Index: 61, Loss: 4.6598\n",
      "Epoch: 17, Index: 62, Loss: 2.2361\n",
      "Epoch: 17, Index: 63, Loss: 0.8580\n",
      "Epoch: 17, Index: 64, Loss: 1.3776\n",
      "Epoch: 17, Index: 65, Loss: 0.3936\n",
      "Epoch: 17, Index: 66, Loss: 5.0996\n",
      "Epoch: 17, Index: 67, Loss: 0.5031\n",
      "Epoch: 17, Index: 68, Loss: 1.0688\n",
      "Epoch: 17, Index: 69, Loss: 0.0114\n",
      "Epoch: 17, Index: 70, Loss: 0.7663\n",
      "Epoch: 17, Index: 71, Loss: 3.8265\n",
      "Epoch: 17, Index: 72, Loss: 3.8340\n",
      "Epoch: 17, Index: 73, Loss: 0.8649\n",
      "Epoch: 17, Index: 74, Loss: 0.7986\n",
      "Epoch: 17, Index: 75, Loss: 0.7105\n",
      "Epoch: 17, Index: 76, Loss: 1.2983\n",
      "Epoch: 17, Index: 77, Loss: 0.6642\n",
      "Epoch: 17, Index: 78, Loss: 1.2032\n",
      "Epoch: 17, Index: 79, Loss: 0.2250\n",
      "Epoch: 17, Index: 80, Loss: 1.3992\n",
      "Epoch: 17, Index: 81, Loss: 0.1748\n",
      "Epoch: 17, Index: 82, Loss: 0.8640\n",
      "Epoch: 17, Index: 83, Loss: 5.1437\n",
      "Epoch: 17, Index: 84, Loss: 0.5262\n",
      "Epoch: 17, Index: 85, Loss: 6.5491\n",
      "Epoch: 17, Index: 86, Loss: 2.2529\n",
      "Epoch: 17, Index: 87, Loss: 3.5406\n",
      "Epoch: 17, Index: 88, Loss: 0.5099\n",
      "Epoch: 17, Index: 89, Loss: 0.6730\n",
      "Epoch: 17, Index: 90, Loss: 0.2848\n",
      "Epoch: 17, Index: 91, Loss: 0.4541\n",
      "Epoch: 17, Index: 92, Loss: 2.6291\n",
      "Epoch: 17, Index: 93, Loss: 0.6658\n",
      "Epoch: 17, Index: 94, Loss: 5.0461\n",
      "Epoch: 17, Index: 95, Loss: 0.5988\n",
      "Epoch: 17, Index: 96, Loss: 0.3153\n",
      "Epoch: 17, Index: 97, Loss: 3.2292\n",
      "Epoch: 17, Index: 98, Loss: 2.7477\n",
      "Epoch: 17, Index: 99, Loss: 2.2664\n",
      "Epoch: 17, Index: 100, Loss: 9.8302\n",
      "Epoch: 17, Index: 101, Loss: 7.1167\n",
      "Epoch: 17, Index: 102, Loss: 1.2155\n",
      "Epoch: 17, Index: 103, Loss: 2.3073\n",
      "Epoch: 17, Index: 104, Loss: 2.3815\n",
      "Epoch: 17, Index: 105, Loss: 4.0348\n",
      "Epoch: 17, Index: 106, Loss: 0.8741\n",
      "Epoch: 17, Index: 107, Loss: 3.5500\n",
      "Epoch: 17, Index: 108, Loss: 4.2334\n",
      "Epoch: 17, Index: 109, Loss: 1.5998\n",
      "Epoch: 17, Index: 110, Loss: 1.2638\n",
      "Epoch: 17, Index: 111, Loss: 3.0004\n",
      "Epoch: 17, Index: 112, Loss: 0.4139\n",
      "Epoch: 17, Index: 113, Loss: 0.0175\n",
      "Epoch: 17, Index: 114, Loss: 1.5001\n",
      "Epoch: 17, Index: 115, Loss: 1.9595\n",
      "Epoch: 17, Index: 116, Loss: 4.1468\n",
      "Epoch: 17, Index: 117, Loss: 1.5351\n",
      "Epoch: 17, Index: 118, Loss: 2.1230\n",
      "Epoch: 17, Index: 119, Loss: 0.8776\n",
      "Epoch: 17, Index: 120, Loss: 0.0444\n",
      "Epoch: 17, Index: 121, Loss: 3.8690\n",
      "Epoch: 17, Index: 122, Loss: 0.3468\n",
      "Epoch: 17, Index: 123, Loss: 2.3987\n",
      "Epoch: 17, Index: 124, Loss: 0.6818\n",
      "Epoch: 17, Index: 125, Loss: 0.0704\n",
      "Epoch: 17, Index: 126, Loss: 0.7629\n",
      "Epoch: 17, Index: 127, Loss: 1.3028\n",
      "Epoch: 17, Index: 128, Loss: 4.7532\n",
      "Epoch: 17, Index: 129, Loss: 2.9926\n",
      "Epoch: 17, Index: 130, Loss: 1.1491\n",
      "Epoch: 17, Index: 131, Loss: 0.1805\n",
      "Epoch: 17, Index: 132, Loss: 0.6812\n",
      "Epoch: 17, Index: 133, Loss: 0.5478\n",
      "Epoch: 17, Index: 134, Loss: 4.5252\n",
      "Epoch: 17, Index: 135, Loss: 3.9143\n",
      "Epoch: 17, Index: 136, Loss: 0.6676\n",
      "Epoch: 17, Index: 137, Loss: 1.8458\n",
      "Epoch: 17, Index: 138, Loss: 5.1850\n",
      "Epoch: 17, Index: 139, Loss: 0.3470\n",
      "Epoch: 17, Index: 140, Loss: 3.6171\n",
      "Epoch: 17, Index: 141, Loss: 0.7996\n",
      "Epoch: 17, Index: 142, Loss: 0.3486\n",
      "Epoch: 17, Index: 143, Loss: 0.8400\n",
      "Epoch: 17, Index: 144, Loss: 0.0720\n",
      "Epoch: 17, Index: 145, Loss: 2.0523\n",
      "Epoch: 17, Index: 146, Loss: 5.1684\n",
      "Epoch: 17, Index: 147, Loss: 1.0783\n",
      "Epoch: 17, Index: 148, Loss: 3.9236\n",
      "Epoch: 17, Index: 149, Loss: 0.1586\n",
      "Epoch: 17, Index: 150, Loss: 1.2876\n",
      "Epoch: 17, Index: 151, Loss: 2.7077\n",
      "Epoch: 17, Index: 152, Loss: 3.7900\n",
      "Epoch: 17, Index: 153, Loss: 0.7290\n",
      "Epoch: 17, Index: 154, Loss: 0.0764\n",
      "Epoch: 17, Index: 155, Loss: 1.3017\n",
      "Epoch: 17, Index: 156, Loss: 0.9517\n",
      "Epoch: 17, Index: 157, Loss: 1.8953\n",
      "Epoch: 17, Index: 158, Loss: 2.8412\n",
      "Epoch: 17, Index: 159, Loss: 1.6370\n",
      "Epoch: 17, Index: 160, Loss: 1.7288\n",
      "Epoch: 17, Index: 161, Loss: 0.4869\n",
      "Epoch: 17, Index: 162, Loss: 0.4033\n",
      "Epoch: 17, Index: 163, Loss: 0.1563\n",
      "Epoch: 17, Index: 164, Loss: 0.1503\n",
      "Epoch: 17, Index: 165, Loss: 3.2229\n",
      "Epoch: 17, Index: 166, Loss: 5.3663\n",
      "Epoch: 17, Index: 167, Loss: 2.0675\n",
      "Epoch: 17, Index: 168, Loss: 2.2993\n",
      "Epoch: 17, Index: 169, Loss: 1.4863\n",
      "Epoch: 17, Index: 170, Loss: 0.6495\n",
      "Epoch: 17, Index: 171, Loss: 0.0783\n",
      "Epoch: 17, Index: 172, Loss: 0.8193\n",
      "Epoch: 17, Index: 173, Loss: 19.3378\n",
      "Epoch: 17, Index: 174, Loss: 3.3474\n",
      "Epoch: 17, Index: 175, Loss: 3.4767\n",
      "Epoch: 17, Index: 176, Loss: 1.4482\n",
      "Epoch: 17, Index: 177, Loss: 1.2810\n",
      "Epoch: 17, Index: 178, Loss: 2.7223\n",
      "Epoch: 17, Index: 179, Loss: 1.9366\n",
      "Epoch: 17, Index: 180, Loss: 0.7511\n",
      "Epoch: 17, Index: 181, Loss: 1.0341\n",
      "Epoch: 17, Index: 182, Loss: 6.6274\n",
      "Epoch: 17, Index: 183, Loss: 3.7672\n",
      "Epoch: 17, Index: 184, Loss: 0.5160\n",
      "Epoch: 17, Index: 185, Loss: 2.3672\n",
      "Epoch: 17, Index: 186, Loss: 5.6753\n",
      "Epoch: 17, Index: 187, Loss: 6.1735\n",
      "Epoch: 17, Index: 188, Loss: 0.1495\n",
      "Epoch: 17, Index: 189, Loss: 4.6221\n",
      "Epoch: 17, Index: 190, Loss: 4.2202\n",
      "Epoch: 17, Index: 191, Loss: 0.8159\n",
      "Epoch: 17, Index: 192, Loss: 2.5480\n",
      "Epoch: 17, Index: 193, Loss: 1.7316\n",
      "Epoch: 17, Index: 194, Loss: 0.0079\n",
      "Epoch: 17, Index: 195, Loss: 3.6318\n",
      "Epoch: 17, Index: 196, Loss: 0.3936\n",
      "Epoch: 17, Index: 197, Loss: 0.7245\n",
      "Epoch: 17, Index: 198, Loss: 1.6388\n",
      "Epoch: 17, Index: 199, Loss: 0.1599\n",
      "Epoch: 17, Index: 200, Loss: 1.1741\n",
      "Epoch: 17, Index: 201, Loss: 0.9874\n",
      "Epoch: 17, Index: 202, Loss: 4.8970\n",
      "Epoch: 17, Index: 203, Loss: 3.2173\n",
      "Epoch: 17, Index: 204, Loss: 1.6004\n",
      "Epoch: 17, Index: 205, Loss: 0.6455\n",
      "Epoch: 17, Index: 206, Loss: 6.9349\n",
      "Epoch: 17, Index: 207, Loss: 0.3403\n",
      "Epoch: 17, Index: 208, Loss: 0.2129\n",
      "Epoch: 17, Index: 209, Loss: 0.9819\n",
      "Epoch: 17, Index: 210, Loss: 0.3342\n",
      "Epoch: 17, Index: 211, Loss: 2.1151\n",
      "Epoch: 17, Index: 212, Loss: 0.6690\n",
      "Epoch: 17, Index: 213, Loss: 0.1267\n",
      "Epoch: 17, Index: 214, Loss: 0.0090\n",
      "Epoch: 17, Index: 215, Loss: 0.1374\n",
      "Epoch: 17, Index: 216, Loss: 0.7543\n",
      "Epoch: 17, Index: 217, Loss: 0.8081\n",
      "Epoch: 17, Index: 218, Loss: 3.8238\n",
      "Epoch: 17, Index: 219, Loss: 2.8335\n",
      "Epoch: 17, Index: 220, Loss: 1.7452\n",
      "Epoch: 17, Index: 221, Loss: 0.6824\n",
      "Epoch: 17, Index: 222, Loss: 0.1968\n",
      "Epoch: 17, Index: 223, Loss: 4.3046\n",
      "Epoch: 17, Index: 224, Loss: 0.5617\n",
      "Epoch: 17, Index: 225, Loss: 0.0705\n",
      "Epoch: 17, Index: 226, Loss: 0.1531\n",
      "Epoch: 17, Index: 227, Loss: 1.6016\n",
      "Epoch: 17, Index: 228, Loss: 0.5956\n",
      "Epoch: 17, Index: 229, Loss: 1.7868\n",
      "Epoch: 17, Index: 230, Loss: 0.1007\n",
      "Epoch: 17, Index: 231, Loss: 0.9678\n",
      "Epoch: 17, Index: 232, Loss: 4.4625\n",
      "Epoch: 17, Index: 233, Loss: 1.8986\n",
      "Epoch: 17, Index: 234, Loss: 2.0877\n",
      "Epoch: 17, Index: 235, Loss: 2.0785\n",
      "Epoch: 17, Index: 236, Loss: 0.9686\n",
      "Epoch: 17, Index: 237, Loss: 0.1841\n",
      "Epoch: 17, Index: 238, Loss: 1.1097\n",
      "Epoch: 17, Index: 239, Loss: 0.3312\n",
      "Epoch: 17, Index: 240, Loss: 9.5713\n",
      "Epoch: 17, Index: 241, Loss: 0.8275\n",
      "Epoch: 17, Index: 242, Loss: 0.1389\n",
      "Epoch: 17, Index: 243, Loss: 6.8511\n",
      "Epoch: 17, Index: 244, Loss: 0.8759\n",
      "Epoch: 17, Index: 245, Loss: 8.1626\n",
      "Epoch: 17, Index: 246, Loss: 1.2874\n",
      "Epoch: 17, Index: 247, Loss: 5.3225\n",
      "Epoch: 17, Index: 248, Loss: 3.7203\n",
      "Epoch: 17, Index: 249, Loss: 1.9030\n",
      "Epoch: 17, Index: 250, Loss: 0.7806\n",
      "Epoch: 17, Index: 251, Loss: 0.7633\n",
      "Epoch: 17, Index: 252, Loss: 4.0132\n",
      "Epoch: 17, Index: 253, Loss: 6.1110\n",
      "Epoch: 17, Index: 254, Loss: 4.2190\n",
      "Epoch: 17, Index: 255, Loss: 0.7843\n",
      "Epoch: 17, Index: 256, Loss: 4.2776\n",
      "Epoch: 17, Index: 257, Loss: 2.7924\n",
      "Epoch: 17, Index: 258, Loss: 2.4072\n",
      "Epoch: 17, Index: 259, Loss: 0.6447\n",
      "Epoch: 17, Index: 260, Loss: 4.7514\n",
      "Epoch: 17, Index: 261, Loss: 1.6339\n",
      "Epoch: 17, Index: 262, Loss: 1.4609\n",
      "Epoch: 17, Index: 263, Loss: 2.4586\n",
      "Epoch: 17, Index: 264, Loss: 1.9445\n",
      "Epoch: 17, Index: 265, Loss: 4.9747\n",
      "Epoch: 17, Index: 266, Loss: 0.4850\n",
      "Epoch: 17, Index: 267, Loss: 3.3902\n",
      "Epoch: 17, Index: 268, Loss: 1.0745\n",
      "Epoch: 17, Index: 269, Loss: 3.9938\n",
      "Epoch: 17, Index: 270, Loss: 2.2041\n",
      "Epoch: 17, Index: 271, Loss: 0.3151\n",
      "Epoch: 17, Index: 272, Loss: 0.2978\n",
      "Epoch: 17, Index: 273, Loss: 0.2510\n",
      "Epoch: 17, Index: 274, Loss: 1.3999\n",
      "Epoch: 17, Index: 275, Loss: 0.2129\n",
      "Epoch: 17, Index: 276, Loss: 0.1093\n",
      "Epoch: 17, Index: 277, Loss: 2.6486\n",
      "Epoch: 17, Index: 278, Loss: 1.6209\n",
      "Epoch: 17, Index: 279, Loss: 0.8445\n",
      "Epoch: 17, Index: 280, Loss: 1.7670\n",
      "Epoch: 17, Index: 281, Loss: 6.7590\n",
      "Epoch: 17, Index: 282, Loss: 0.4948\n",
      "Epoch: 17, Index: 283, Loss: 6.4988\n",
      "Epoch: 17, Index: 284, Loss: 1.0945\n",
      "Epoch: 17, Index: 285, Loss: 2.1131\n",
      "Epoch: 17, Index: 286, Loss: 1.3355\n",
      "Epoch: 17, Index: 287, Loss: 0.2309\n",
      "Epoch: 17, Index: 288, Loss: 0.1179\n",
      "Epoch: 17, Index: 289, Loss: 0.0629\n",
      "Epoch: 17, Index: 290, Loss: 3.3488\n",
      "Epoch: 17, Index: 291, Loss: 0.1546\n",
      "Epoch: 17, Index: 292, Loss: 1.5180\n",
      "Epoch: 17, Index: 293, Loss: 1.4562\n",
      "Epoch: 17, Index: 294, Loss: 4.0639\n",
      "Epoch: 17, Index: 295, Loss: 0.9531\n",
      "Epoch: 17, Index: 296, Loss: 3.1560\n",
      "Epoch: 17, Index: 297, Loss: 1.9380\n",
      "Epoch: 17, Index: 298, Loss: 0.1474\n",
      "Epoch: 17, Index: 299, Loss: 0.0525\n",
      "Epoch: 17, Index: 300, Loss: 0.3379\n",
      "Epoch: 17, Index: 301, Loss: 3.9618\n",
      "Epoch: 17, Index: 302, Loss: 1.3088\n",
      "Epoch: 17, Index: 303, Loss: 0.8357\n",
      "Epoch: 17, Index: 304, Loss: 1.6877\n",
      "Epoch: 17, Index: 305, Loss: 1.6188\n",
      "Epoch: 17, Index: 306, Loss: 1.3988\n",
      "Epoch: 17, Index: 307, Loss: 1.7545\n",
      "Epoch: 17, Index: 308, Loss: 0.5287\n",
      "Epoch: 17, Index: 309, Loss: 2.3926\n",
      "Epoch: 17, Index: 310, Loss: 0.9503\n",
      "Epoch: 17, Index: 311, Loss: 0.2737\n",
      "Epoch: 17, Index: 312, Loss: 0.9107\n",
      "Epoch: 17, Index: 313, Loss: 1.2827\n",
      "Epoch: 17, Index: 314, Loss: 0.1934\n",
      "Epoch: 17, Index: 315, Loss: 0.9943\n",
      "Epoch: 17, Index: 316, Loss: 2.4032\n",
      "Epoch: 17, Index: 317, Loss: 0.2667\n",
      "Epoch: 17, Index: 318, Loss: 1.5205\n",
      "Epoch: 17, Index: 319, Loss: 3.9386\n",
      "Epoch: 17, Index: 320, Loss: 2.8081\n",
      "Epoch: 17, Index: 321, Loss: 0.7120\n",
      "Epoch: 17, Index: 322, Loss: 2.6875\n",
      "Epoch: 17, Index: 323, Loss: 0.7247\n",
      "Epoch: 17, Index: 324, Loss: 1.0826\n",
      "Epoch: 17, Index: 325, Loss: 3.1632\n",
      "Epoch: 17, Index: 326, Loss: 0.1720\n",
      "Epoch: 17, Index: 327, Loss: 0.5968\n",
      "Epoch: 17, Index: 328, Loss: 1.0077\n",
      "Epoch: 17, Index: 329, Loss: 2.0162\n",
      "Epoch: 17, Index: 330, Loss: 4.2130\n",
      "Epoch: 17, Index: 331, Loss: 1.6147\n",
      "Epoch: 17, Index: 332, Loss: 2.7903\n",
      "Epoch: 17, Index: 333, Loss: 4.9545\n",
      "Epoch: 17, Index: 334, Loss: 1.0578\n",
      "Epoch: 17, Index: 335, Loss: 0.1650\n",
      "Epoch: 17, Index: 336, Loss: 2.0935\n",
      "Epoch: 17, Index: 337, Loss: 0.8020\n",
      "Epoch: 17, Index: 338, Loss: 0.0806\n",
      "Epoch: 17, Index: 339, Loss: 0.0329\n",
      "Epoch: 17, Index: 340, Loss: 1.0436\n",
      "Epoch: 17, Index: 341, Loss: 4.5749\n",
      "Epoch: 17, Index: 342, Loss: 0.0150\n",
      "Epoch: 17, Index: 343, Loss: 0.5745\n",
      "Epoch: 17, Index: 344, Loss: 1.9293\n",
      "Epoch: 17, Index: 345, Loss: 0.2039\n",
      "Epoch: 17, Index: 346, Loss: 0.6484\n",
      "Epoch: 17, Index: 347, Loss: 0.4308\n",
      "Epoch: 17, Index: 348, Loss: 2.1088\n",
      "Epoch: 17, Index: 349, Loss: 0.1658\n",
      "Epoch: 17, Index: 350, Loss: 0.2383\n",
      "Epoch: 17, Index: 351, Loss: 0.8421\n",
      "Epoch: 17, Index: 352, Loss: 1.4576\n",
      "Epoch: 17, Index: 353, Loss: 2.4758\n",
      "Epoch: 17, Index: 354, Loss: 0.5194\n",
      "Epoch: 17, Index: 355, Loss: 1.7975\n",
      "Epoch: 17, Index: 356, Loss: 2.0528\n",
      "Epoch: 17, Index: 357, Loss: 1.7583\n",
      "Epoch: 17, Index: 358, Loss: 2.2838\n",
      "Epoch: 17, Index: 359, Loss: 0.7114\n",
      "Epoch: 17, Index: 360, Loss: 1.0602\n",
      "Epoch: 17, Index: 361, Loss: 0.2624\n",
      "Epoch: 17, Index: 362, Loss: 20.3479\n",
      "Epoch: 17, Index: 363, Loss: 0.7281\n",
      "Epoch: 17, Index: 364, Loss: 1.1081\n",
      "Epoch: 17, Index: 365, Loss: 1.6811\n",
      "Epoch: 17, Index: 366, Loss: 1.3367\n",
      "Epoch: 17, Index: 367, Loss: 1.3162\n",
      "Epoch: 17, Index: 368, Loss: 0.8777\n",
      "Epoch: 17, Index: 369, Loss: 2.4253\n",
      "Epoch: 17, Index: 370, Loss: 1.7353\n",
      "Epoch: 17, Index: 371, Loss: 0.8858\n",
      "Epoch: 17, Index: 372, Loss: 0.0714\n",
      "Epoch: 17, Index: 373, Loss: 0.1086\n",
      "Epoch: 17, Index: 374, Loss: 3.5620\n",
      "Epoch: 17, Index: 375, Loss: 0.8949\n",
      "Epoch: 17, Index: 376, Loss: 5.7722\n",
      "Epoch: 17, Index: 377, Loss: 0.5168\n",
      "Epoch: 17, Index: 378, Loss: 0.6841\n",
      "Epoch: 17, Index: 379, Loss: 0.0878\n",
      "Epoch: 17, Index: 380, Loss: 0.6528\n",
      "Epoch: 17, Index: 381, Loss: 2.4728\n",
      "Epoch: 17, Index: 382, Loss: 1.2950\n",
      "Epoch: 17, Index: 383, Loss: 0.6438\n",
      "Epoch: 17, Index: 384, Loss: 0.0406\n",
      "Epoch: 17, Index: 385, Loss: 1.4247\n",
      "Epoch: 17, Index: 386, Loss: 0.7323\n",
      "Epoch: 17, Index: 387, Loss: 1.0927\n",
      "Epoch: 17, Index: 388, Loss: 1.3700\n",
      "Epoch: 17, Index: 389, Loss: 0.0981\n",
      "Epoch: 17, Index: 390, Loss: 0.5460\n",
      "Epoch: 17, Index: 391, Loss: 2.4402\n",
      "Epoch: 17, Index: 392, Loss: 0.9403\n",
      "Epoch: 17, Index: 393, Loss: 0.0505\n",
      "Epoch: 17, Index: 394, Loss: 1.9532\n",
      "Epoch: 17, Index: 395, Loss: 1.2620\n",
      "Epoch: 17, Index: 396, Loss: 0.0472\n",
      "Epoch: 17, Index: 397, Loss: 0.3390\n",
      "Epoch: 17, Index: 398, Loss: 1.2189\n",
      "Epoch: 17, Index: 399, Loss: 3.8354\n",
      "Epoch: 17, Index: 400, Loss: 1.4137\n",
      "Epoch: 17, Index: 401, Loss: 1.4710\n",
      "Epoch: 17, Index: 402, Loss: 0.3453\n",
      "Epoch: 17, Index: 403, Loss: 0.9123\n",
      "Epoch: 17, Index: 404, Loss: 0.4223\n",
      "Epoch: 17, Index: 405, Loss: 1.8449\n",
      "Epoch: 17, Index: 406, Loss: 1.0913\n",
      "Epoch: 17, Index: 407, Loss: 1.6487\n",
      "Epoch: 17, Index: 408, Loss: 1.1315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c509f4a23f8c4ad4a8ba117f82bc3356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Index: 0, Loss: 1.4427\n",
      "Epoch: 18, Index: 1, Loss: 1.5234\n",
      "Epoch: 18, Index: 2, Loss: 0.4463\n",
      "Epoch: 18, Index: 3, Loss: 4.3438\n",
      "Epoch: 18, Index: 4, Loss: 2.7718\n",
      "Epoch: 18, Index: 5, Loss: 5.3944\n",
      "Epoch: 18, Index: 6, Loss: 3.3262\n",
      "Epoch: 18, Index: 7, Loss: 0.2506\n",
      "Epoch: 18, Index: 8, Loss: 0.4253\n",
      "Epoch: 18, Index: 9, Loss: 2.1175\n",
      "Epoch: 18, Index: 10, Loss: 3.0831\n",
      "Epoch: 18, Index: 11, Loss: 6.5627\n",
      "Epoch: 18, Index: 12, Loss: 0.2493\n",
      "Epoch: 18, Index: 13, Loss: 0.0431\n",
      "Epoch: 18, Index: 14, Loss: 11.5381\n",
      "Epoch: 18, Index: 15, Loss: 0.7895\n",
      "Epoch: 18, Index: 16, Loss: 0.1971\n",
      "Epoch: 18, Index: 17, Loss: 2.3320\n",
      "Epoch: 18, Index: 18, Loss: 1.5902\n",
      "Epoch: 18, Index: 19, Loss: 2.4058\n",
      "Epoch: 18, Index: 20, Loss: 1.4205\n",
      "Epoch: 18, Index: 21, Loss: 1.5824\n",
      "Epoch: 18, Index: 22, Loss: 0.3101\n",
      "Epoch: 18, Index: 23, Loss: 3.1818\n",
      "Epoch: 18, Index: 24, Loss: 3.4520\n",
      "Epoch: 18, Index: 25, Loss: 0.1357\n",
      "Epoch: 18, Index: 26, Loss: 0.6810\n",
      "Epoch: 18, Index: 27, Loss: 2.5735\n",
      "Epoch: 18, Index: 28, Loss: 5.3110\n",
      "Epoch: 18, Index: 29, Loss: 0.9230\n",
      "Epoch: 18, Index: 30, Loss: 0.2370\n",
      "Epoch: 18, Index: 31, Loss: 1.9747\n",
      "Epoch: 18, Index: 32, Loss: 4.6839\n",
      "Epoch: 18, Index: 33, Loss: 0.8003\n",
      "Epoch: 18, Index: 34, Loss: 0.7383\n",
      "Epoch: 18, Index: 35, Loss: 2.1730\n",
      "Epoch: 18, Index: 36, Loss: 0.3699\n",
      "Epoch: 18, Index: 37, Loss: 1.2257\n",
      "Epoch: 18, Index: 38, Loss: 3.5305\n",
      "Epoch: 18, Index: 39, Loss: 0.4389\n",
      "Epoch: 18, Index: 40, Loss: 4.0738\n",
      "Epoch: 18, Index: 41, Loss: 0.0524\n",
      "Epoch: 18, Index: 42, Loss: 1.5104\n",
      "Epoch: 18, Index: 43, Loss: 0.3063\n",
      "Epoch: 18, Index: 44, Loss: 5.6089\n",
      "Epoch: 18, Index: 45, Loss: 0.5624\n",
      "Epoch: 18, Index: 46, Loss: 2.5084\n",
      "Epoch: 18, Index: 47, Loss: 1.8381\n",
      "Epoch: 18, Index: 48, Loss: 1.4778\n",
      "Epoch: 18, Index: 49, Loss: 0.9474\n",
      "Epoch: 18, Index: 50, Loss: 3.1149\n",
      "Epoch: 18, Index: 51, Loss: 2.6581\n",
      "Epoch: 18, Index: 52, Loss: 4.4360\n",
      "Epoch: 18, Index: 53, Loss: 1.6105\n",
      "Epoch: 18, Index: 54, Loss: 0.4625\n",
      "Epoch: 18, Index: 55, Loss: 2.6886\n",
      "Epoch: 18, Index: 56, Loss: 1.2678\n",
      "Epoch: 18, Index: 57, Loss: 0.8678\n",
      "Epoch: 18, Index: 58, Loss: 0.2929\n",
      "Epoch: 18, Index: 59, Loss: 0.8115\n",
      "Epoch: 18, Index: 60, Loss: 0.1823\n",
      "Epoch: 18, Index: 61, Loss: 1.2853\n",
      "Epoch: 18, Index: 62, Loss: 0.8324\n",
      "Epoch: 18, Index: 63, Loss: 0.8596\n",
      "Epoch: 18, Index: 64, Loss: 0.2232\n",
      "Epoch: 18, Index: 65, Loss: 0.0561\n",
      "Epoch: 18, Index: 66, Loss: 1.0165\n",
      "Epoch: 18, Index: 67, Loss: 0.7366\n",
      "Epoch: 18, Index: 68, Loss: 1.1104\n",
      "Epoch: 18, Index: 69, Loss: 0.6735\n",
      "Epoch: 18, Index: 70, Loss: 1.1975\n",
      "Epoch: 18, Index: 71, Loss: 1.2709\n",
      "Epoch: 18, Index: 72, Loss: 0.0212\n",
      "Epoch: 18, Index: 73, Loss: 0.1751\n",
      "Epoch: 18, Index: 74, Loss: 1.9694\n",
      "Epoch: 18, Index: 75, Loss: 1.2672\n",
      "Epoch: 18, Index: 76, Loss: 4.7230\n",
      "Epoch: 18, Index: 77, Loss: 3.2961\n",
      "Epoch: 18, Index: 78, Loss: 0.7391\n",
      "Epoch: 18, Index: 79, Loss: 1.2272\n",
      "Epoch: 18, Index: 80, Loss: 1.2885\n",
      "Epoch: 18, Index: 81, Loss: 2.3106\n",
      "Epoch: 18, Index: 82, Loss: 0.4404\n",
      "Epoch: 18, Index: 83, Loss: 3.4987\n",
      "Epoch: 18, Index: 84, Loss: 3.0403\n",
      "Epoch: 18, Index: 85, Loss: 1.4572\n",
      "Epoch: 18, Index: 86, Loss: 1.2903\n",
      "Epoch: 18, Index: 87, Loss: 0.2431\n",
      "Epoch: 18, Index: 88, Loss: 1.0131\n",
      "Epoch: 18, Index: 89, Loss: 1.5903\n",
      "Epoch: 18, Index: 90, Loss: 2.2640\n",
      "Epoch: 18, Index: 91, Loss: 0.7515\n",
      "Epoch: 18, Index: 92, Loss: 2.3206\n",
      "Epoch: 18, Index: 93, Loss: 0.2731\n",
      "Epoch: 18, Index: 94, Loss: 3.2714\n",
      "Epoch: 18, Index: 95, Loss: 1.1662\n",
      "Epoch: 18, Index: 96, Loss: 1.3324\n",
      "Epoch: 18, Index: 97, Loss: 0.6776\n",
      "Epoch: 18, Index: 98, Loss: 5.6586\n",
      "Epoch: 18, Index: 99, Loss: 1.7819\n",
      "Epoch: 18, Index: 100, Loss: 1.2836\n",
      "Epoch: 18, Index: 101, Loss: 2.8310\n",
      "Epoch: 18, Index: 102, Loss: 1.5047\n",
      "Epoch: 18, Index: 103, Loss: 0.0247\n",
      "Epoch: 18, Index: 104, Loss: 0.7931\n",
      "Epoch: 18, Index: 105, Loss: 1.2995\n",
      "Epoch: 18, Index: 106, Loss: 1.0193\n",
      "Epoch: 18, Index: 107, Loss: 2.7552\n",
      "Epoch: 18, Index: 108, Loss: 0.6122\n",
      "Epoch: 18, Index: 109, Loss: 1.5408\n",
      "Epoch: 18, Index: 110, Loss: 0.6071\n",
      "Epoch: 18, Index: 111, Loss: 2.3224\n",
      "Epoch: 18, Index: 112, Loss: 2.0916\n",
      "Epoch: 18, Index: 113, Loss: 0.3741\n",
      "Epoch: 18, Index: 114, Loss: 1.1202\n",
      "Epoch: 18, Index: 115, Loss: 12.6546\n",
      "Epoch: 18, Index: 116, Loss: 0.9284\n",
      "Epoch: 18, Index: 117, Loss: 0.0256\n",
      "Epoch: 18, Index: 118, Loss: 1.0800\n",
      "Epoch: 18, Index: 119, Loss: 0.3339\n",
      "Epoch: 18, Index: 120, Loss: 4.3705\n",
      "Epoch: 18, Index: 121, Loss: 1.9522\n",
      "Epoch: 18, Index: 122, Loss: 1.6914\n",
      "Epoch: 18, Index: 123, Loss: 1.2869\n",
      "Epoch: 18, Index: 124, Loss: 0.0777\n",
      "Epoch: 18, Index: 125, Loss: 1.0741\n",
      "Epoch: 18, Index: 126, Loss: 1.3906\n",
      "Epoch: 18, Index: 127, Loss: 0.1183\n",
      "Epoch: 18, Index: 128, Loss: 0.4401\n",
      "Epoch: 18, Index: 129, Loss: 1.4187\n",
      "Epoch: 18, Index: 130, Loss: 0.5404\n",
      "Epoch: 18, Index: 131, Loss: 0.8489\n",
      "Epoch: 18, Index: 132, Loss: 0.1351\n",
      "Epoch: 18, Index: 133, Loss: 0.4106\n",
      "Epoch: 18, Index: 134, Loss: 0.2635\n",
      "Epoch: 18, Index: 135, Loss: 0.1008\n",
      "Epoch: 18, Index: 136, Loss: 0.9488\n",
      "Epoch: 18, Index: 137, Loss: 0.2897\n",
      "Epoch: 18, Index: 138, Loss: 1.0147\n",
      "Epoch: 18, Index: 139, Loss: 0.5060\n",
      "Epoch: 18, Index: 140, Loss: 2.8045\n",
      "Epoch: 18, Index: 141, Loss: 0.2467\n",
      "Epoch: 18, Index: 142, Loss: 0.8998\n",
      "Epoch: 18, Index: 143, Loss: 1.0701\n",
      "Epoch: 18, Index: 144, Loss: 0.0730\n",
      "Epoch: 18, Index: 145, Loss: 1.8414\n",
      "Epoch: 18, Index: 146, Loss: 0.5980\n",
      "Epoch: 18, Index: 147, Loss: 0.1334\n",
      "Epoch: 18, Index: 148, Loss: 0.2647\n",
      "Epoch: 18, Index: 149, Loss: 0.6125\n",
      "Epoch: 18, Index: 150, Loss: 0.5179\n",
      "Epoch: 18, Index: 151, Loss: 0.1370\n",
      "Epoch: 18, Index: 152, Loss: 0.0784\n",
      "Epoch: 18, Index: 153, Loss: 3.1528\n",
      "Epoch: 18, Index: 154, Loss: 1.0715\n",
      "Epoch: 18, Index: 155, Loss: 0.5897\n",
      "Epoch: 18, Index: 156, Loss: 3.9506\n",
      "Epoch: 18, Index: 157, Loss: 1.6696\n",
      "Epoch: 18, Index: 158, Loss: 0.1599\n",
      "Epoch: 18, Index: 159, Loss: 1.8642\n",
      "Epoch: 18, Index: 160, Loss: 0.9166\n",
      "Epoch: 18, Index: 161, Loss: 2.9248\n",
      "Epoch: 18, Index: 162, Loss: 0.0548\n",
      "Epoch: 18, Index: 163, Loss: 13.9951\n",
      "Epoch: 18, Index: 164, Loss: 0.1228\n",
      "Epoch: 18, Index: 165, Loss: 1.6800\n",
      "Epoch: 18, Index: 166, Loss: 1.1650\n",
      "Epoch: 18, Index: 167, Loss: 0.0230\n",
      "Epoch: 18, Index: 168, Loss: 2.5898\n",
      "Epoch: 18, Index: 169, Loss: 3.4869\n",
      "Epoch: 18, Index: 170, Loss: 0.3177\n",
      "Epoch: 18, Index: 171, Loss: 1.7068\n",
      "Epoch: 18, Index: 172, Loss: 2.9999\n",
      "Epoch: 18, Index: 173, Loss: 0.0806\n",
      "Epoch: 18, Index: 174, Loss: 1.0199\n",
      "Epoch: 18, Index: 175, Loss: 2.5723\n",
      "Epoch: 18, Index: 176, Loss: 0.4308\n",
      "Epoch: 18, Index: 177, Loss: 0.1451\n",
      "Epoch: 18, Index: 178, Loss: 0.2094\n",
      "Epoch: 18, Index: 179, Loss: 0.7405\n",
      "Epoch: 18, Index: 180, Loss: 0.8313\n",
      "Epoch: 18, Index: 181, Loss: 0.4945\n",
      "Epoch: 18, Index: 182, Loss: 0.3759\n",
      "Epoch: 18, Index: 183, Loss: 1.6125\n",
      "Epoch: 18, Index: 184, Loss: 0.2683\n",
      "Epoch: 18, Index: 185, Loss: 3.5973\n",
      "Epoch: 18, Index: 186, Loss: 0.2063\n",
      "Epoch: 18, Index: 187, Loss: 1.9859\n",
      "Epoch: 18, Index: 188, Loss: 1.8254\n",
      "Epoch: 18, Index: 189, Loss: 0.6816\n",
      "Epoch: 18, Index: 190, Loss: 0.8290\n",
      "Epoch: 18, Index: 191, Loss: 1.0044\n",
      "Epoch: 18, Index: 192, Loss: 0.3490\n",
      "Epoch: 18, Index: 193, Loss: 0.2288\n",
      "Epoch: 18, Index: 194, Loss: 1.8754\n",
      "Epoch: 18, Index: 195, Loss: 4.5318\n",
      "Epoch: 18, Index: 196, Loss: 0.7965\n",
      "Epoch: 18, Index: 197, Loss: 2.4649\n",
      "Epoch: 18, Index: 198, Loss: 0.2653\n",
      "Epoch: 18, Index: 199, Loss: 0.5324\n",
      "Epoch: 18, Index: 200, Loss: 3.4275\n",
      "Epoch: 18, Index: 201, Loss: 2.7932\n",
      "Epoch: 18, Index: 202, Loss: 0.9968\n",
      "Epoch: 18, Index: 203, Loss: 3.0734\n",
      "Epoch: 18, Index: 204, Loss: 0.9484\n",
      "Epoch: 18, Index: 205, Loss: 0.9580\n",
      "Epoch: 18, Index: 206, Loss: 0.4661\n",
      "Epoch: 18, Index: 207, Loss: 0.2051\n",
      "Epoch: 18, Index: 208, Loss: 0.6043\n",
      "Epoch: 18, Index: 209, Loss: 0.0741\n",
      "Epoch: 18, Index: 210, Loss: 1.5553\n",
      "Epoch: 18, Index: 211, Loss: 4.1266\n",
      "Epoch: 18, Index: 212, Loss: 2.6850\n",
      "Epoch: 18, Index: 213, Loss: 0.6750\n",
      "Epoch: 18, Index: 214, Loss: 1.5636\n",
      "Epoch: 18, Index: 215, Loss: 2.6578\n",
      "Epoch: 18, Index: 216, Loss: 1.0206\n",
      "Epoch: 18, Index: 217, Loss: 0.0066\n",
      "Epoch: 18, Index: 218, Loss: 1.1511\n",
      "Epoch: 18, Index: 219, Loss: 3.1294\n",
      "Epoch: 18, Index: 220, Loss: 0.8959\n",
      "Epoch: 18, Index: 221, Loss: 2.2696\n",
      "Epoch: 18, Index: 222, Loss: 1.7344\n",
      "Epoch: 18, Index: 223, Loss: 0.0229\n",
      "Epoch: 18, Index: 224, Loss: 6.3625\n",
      "Epoch: 18, Index: 225, Loss: 3.8459\n",
      "Epoch: 18, Index: 226, Loss: 0.5623\n",
      "Epoch: 18, Index: 227, Loss: 4.5244\n",
      "Epoch: 18, Index: 228, Loss: 2.1092\n",
      "Epoch: 18, Index: 229, Loss: 0.3597\n",
      "Epoch: 18, Index: 230, Loss: 1.6270\n",
      "Epoch: 18, Index: 231, Loss: 2.1314\n",
      "Epoch: 18, Index: 232, Loss: 1.3662\n",
      "Epoch: 18, Index: 233, Loss: 1.6320\n",
      "Epoch: 18, Index: 234, Loss: 0.1344\n",
      "Epoch: 18, Index: 235, Loss: 0.2703\n",
      "Epoch: 18, Index: 236, Loss: 0.7306\n",
      "Epoch: 18, Index: 237, Loss: 1.0577\n",
      "Epoch: 18, Index: 238, Loss: 1.7620\n",
      "Epoch: 18, Index: 239, Loss: 3.6308\n",
      "Epoch: 18, Index: 240, Loss: 6.8516\n",
      "Epoch: 18, Index: 241, Loss: 2.0915\n",
      "Epoch: 18, Index: 242, Loss: 1.4874\n",
      "Epoch: 18, Index: 243, Loss: 4.5297\n",
      "Epoch: 18, Index: 244, Loss: 0.6767\n",
      "Epoch: 18, Index: 245, Loss: 1.2745\n",
      "Epoch: 18, Index: 246, Loss: 0.3253\n",
      "Epoch: 18, Index: 247, Loss: 0.7234\n",
      "Epoch: 18, Index: 248, Loss: 1.8238\n",
      "Epoch: 18, Index: 249, Loss: 1.0641\n",
      "Epoch: 18, Index: 250, Loss: 1.5870\n",
      "Epoch: 18, Index: 251, Loss: 0.2855\n",
      "Epoch: 18, Index: 252, Loss: 0.2663\n",
      "Epoch: 18, Index: 253, Loss: 0.1806\n",
      "Epoch: 18, Index: 254, Loss: 1.5930\n",
      "Epoch: 18, Index: 255, Loss: 8.8816\n",
      "Epoch: 18, Index: 256, Loss: 0.3782\n",
      "Epoch: 18, Index: 257, Loss: 4.0469\n",
      "Epoch: 18, Index: 258, Loss: 0.9668\n",
      "Epoch: 18, Index: 259, Loss: 2.0304\n",
      "Epoch: 18, Index: 260, Loss: 0.5759\n",
      "Epoch: 18, Index: 261, Loss: 2.2375\n",
      "Epoch: 18, Index: 262, Loss: 0.3198\n",
      "Epoch: 18, Index: 263, Loss: 0.0850\n",
      "Epoch: 18, Index: 264, Loss: 1.2316\n",
      "Epoch: 18, Index: 265, Loss: 0.0551\n",
      "Epoch: 18, Index: 266, Loss: 0.8942\n",
      "Epoch: 18, Index: 267, Loss: 2.1721\n",
      "Epoch: 18, Index: 268, Loss: 7.8960\n",
      "Epoch: 18, Index: 269, Loss: 0.9541\n",
      "Epoch: 18, Index: 270, Loss: 1.7478\n",
      "Epoch: 18, Index: 271, Loss: 1.8523\n",
      "Epoch: 18, Index: 272, Loss: 3.8209\n",
      "Epoch: 18, Index: 273, Loss: 1.2341\n",
      "Epoch: 18, Index: 274, Loss: 0.5245\n",
      "Epoch: 18, Index: 275, Loss: 1.1512\n",
      "Epoch: 18, Index: 276, Loss: 1.6035\n",
      "Epoch: 18, Index: 277, Loss: 2.8645\n",
      "Epoch: 18, Index: 278, Loss: 0.0384\n",
      "Epoch: 18, Index: 279, Loss: 3.8762\n",
      "Epoch: 18, Index: 280, Loss: 3.9282\n",
      "Epoch: 18, Index: 281, Loss: 1.8362\n",
      "Epoch: 18, Index: 282, Loss: 1.3528\n",
      "Epoch: 18, Index: 283, Loss: 1.7104\n",
      "Epoch: 18, Index: 284, Loss: 2.3861\n",
      "Epoch: 18, Index: 285, Loss: 1.0452\n",
      "Epoch: 18, Index: 286, Loss: 1.8868\n",
      "Epoch: 18, Index: 287, Loss: 0.4585\n",
      "Epoch: 18, Index: 288, Loss: 0.6750\n",
      "Epoch: 18, Index: 289, Loss: 1.0030\n",
      "Epoch: 18, Index: 290, Loss: 0.1108\n",
      "Epoch: 18, Index: 291, Loss: 5.7837\n",
      "Epoch: 18, Index: 292, Loss: 0.5065\n",
      "Epoch: 18, Index: 293, Loss: 1.4559\n",
      "Epoch: 18, Index: 294, Loss: 0.1688\n",
      "Epoch: 18, Index: 295, Loss: 0.0787\n",
      "Epoch: 18, Index: 296, Loss: 0.5309\n",
      "Epoch: 18, Index: 297, Loss: 1.1403\n",
      "Epoch: 18, Index: 298, Loss: 0.5607\n",
      "Epoch: 18, Index: 299, Loss: 4.0286\n",
      "Epoch: 18, Index: 300, Loss: 1.4896\n",
      "Epoch: 18, Index: 301, Loss: 0.8493\n",
      "Epoch: 18, Index: 302, Loss: 12.0610\n",
      "Epoch: 18, Index: 303, Loss: 3.8766\n",
      "Epoch: 18, Index: 304, Loss: 1.3707\n",
      "Epoch: 18, Index: 305, Loss: 1.3802\n",
      "Epoch: 18, Index: 306, Loss: 0.3535\n",
      "Epoch: 18, Index: 307, Loss: 1.0966\n",
      "Epoch: 18, Index: 308, Loss: 2.2203\n",
      "Epoch: 18, Index: 309, Loss: 0.1125\n",
      "Epoch: 18, Index: 310, Loss: 3.6073\n",
      "Epoch: 18, Index: 311, Loss: 8.1817\n",
      "Epoch: 18, Index: 312, Loss: 0.8998\n",
      "Epoch: 18, Index: 313, Loss: 3.4899\n",
      "Epoch: 18, Index: 314, Loss: 1.7737\n",
      "Epoch: 18, Index: 315, Loss: 5.5095\n",
      "Epoch: 18, Index: 316, Loss: 1.0746\n",
      "Epoch: 18, Index: 317, Loss: 1.3230\n",
      "Epoch: 18, Index: 318, Loss: 2.7098\n",
      "Epoch: 18, Index: 319, Loss: 0.3339\n",
      "Epoch: 18, Index: 320, Loss: 1.2765\n",
      "Epoch: 18, Index: 321, Loss: 1.1962\n",
      "Epoch: 18, Index: 322, Loss: 0.0092\n",
      "Epoch: 18, Index: 323, Loss: 3.1957\n",
      "Epoch: 18, Index: 324, Loss: 3.1305\n",
      "Epoch: 18, Index: 325, Loss: 2.2792\n",
      "Epoch: 18, Index: 326, Loss: 2.1967\n",
      "Epoch: 18, Index: 327, Loss: 4.0147\n",
      "Epoch: 18, Index: 328, Loss: 2.1035\n",
      "Epoch: 18, Index: 329, Loss: 0.5422\n",
      "Epoch: 18, Index: 330, Loss: 0.0481\n",
      "Epoch: 18, Index: 331, Loss: 0.9004\n",
      "Epoch: 18, Index: 332, Loss: 2.1904\n",
      "Epoch: 18, Index: 333, Loss: 6.8528\n",
      "Epoch: 18, Index: 334, Loss: 1.9680\n",
      "Epoch: 18, Index: 335, Loss: 1.8719\n",
      "Epoch: 18, Index: 336, Loss: 0.1329\n",
      "Epoch: 18, Index: 337, Loss: 2.8798\n",
      "Epoch: 18, Index: 338, Loss: 0.4556\n",
      "Epoch: 18, Index: 339, Loss: 0.8893\n",
      "Epoch: 18, Index: 340, Loss: 2.1183\n",
      "Epoch: 18, Index: 341, Loss: 1.1681\n",
      "Epoch: 18, Index: 342, Loss: 0.6887\n",
      "Epoch: 18, Index: 343, Loss: 1.9873\n",
      "Epoch: 18, Index: 344, Loss: 0.5409\n",
      "Epoch: 18, Index: 345, Loss: 5.9968\n",
      "Epoch: 18, Index: 346, Loss: 0.0538\n",
      "Epoch: 18, Index: 347, Loss: 1.2985\n",
      "Epoch: 18, Index: 348, Loss: 0.3652\n",
      "Epoch: 18, Index: 349, Loss: 9.6404\n",
      "Epoch: 18, Index: 350, Loss: 1.3257\n",
      "Epoch: 18, Index: 351, Loss: 4.8540\n",
      "Epoch: 18, Index: 352, Loss: 2.1252\n",
      "Epoch: 18, Index: 353, Loss: 1.4217\n",
      "Epoch: 18, Index: 354, Loss: 7.7766\n",
      "Epoch: 18, Index: 355, Loss: 1.5833\n",
      "Epoch: 18, Index: 356, Loss: 5.7762\n",
      "Epoch: 18, Index: 357, Loss: 1.0399\n",
      "Epoch: 18, Index: 358, Loss: 2.1280\n",
      "Epoch: 18, Index: 359, Loss: 4.3502\n",
      "Epoch: 18, Index: 360, Loss: 1.8011\n",
      "Epoch: 18, Index: 361, Loss: 1.7562\n",
      "Epoch: 18, Index: 362, Loss: 6.9576\n",
      "Epoch: 18, Index: 363, Loss: 0.5773\n",
      "Epoch: 18, Index: 364, Loss: 2.6531\n",
      "Epoch: 18, Index: 365, Loss: 1.3078\n",
      "Epoch: 18, Index: 366, Loss: 1.9443\n",
      "Epoch: 18, Index: 367, Loss: 1.8118\n",
      "Epoch: 18, Index: 368, Loss: 1.5640\n",
      "Epoch: 18, Index: 369, Loss: 1.3430\n",
      "Epoch: 18, Index: 370, Loss: 0.5617\n",
      "Epoch: 18, Index: 371, Loss: 1.7713\n",
      "Epoch: 18, Index: 372, Loss: 0.2514\n",
      "Epoch: 18, Index: 373, Loss: 3.3693\n",
      "Epoch: 18, Index: 374, Loss: 0.0268\n",
      "Epoch: 18, Index: 375, Loss: 2.8211\n",
      "Epoch: 18, Index: 376, Loss: 1.0845\n",
      "Epoch: 18, Index: 377, Loss: 0.3853\n",
      "Epoch: 18, Index: 378, Loss: 1.3552\n",
      "Epoch: 18, Index: 379, Loss: 5.4655\n",
      "Epoch: 18, Index: 380, Loss: 0.4187\n",
      "Epoch: 18, Index: 381, Loss: 14.5847\n",
      "Epoch: 18, Index: 382, Loss: 17.1304\n",
      "Epoch: 18, Index: 383, Loss: 0.6121\n",
      "Epoch: 18, Index: 384, Loss: 0.1458\n",
      "Epoch: 18, Index: 385, Loss: 0.2053\n",
      "Epoch: 18, Index: 386, Loss: 0.3521\n",
      "Epoch: 18, Index: 387, Loss: 1.5380\n",
      "Epoch: 18, Index: 388, Loss: 0.3759\n",
      "Epoch: 18, Index: 389, Loss: 1.3992\n",
      "Epoch: 18, Index: 390, Loss: 5.2280\n",
      "Epoch: 18, Index: 391, Loss: 0.5716\n",
      "Epoch: 18, Index: 392, Loss: 3.9881\n",
      "Epoch: 18, Index: 393, Loss: 1.6134\n",
      "Epoch: 18, Index: 394, Loss: 0.8447\n",
      "Epoch: 18, Index: 395, Loss: 1.8747\n",
      "Epoch: 18, Index: 396, Loss: 1.4854\n",
      "Epoch: 18, Index: 397, Loss: 3.5305\n",
      "Epoch: 18, Index: 398, Loss: 0.8133\n",
      "Epoch: 18, Index: 399, Loss: 1.4248\n",
      "Epoch: 18, Index: 400, Loss: 1.3329\n",
      "Epoch: 18, Index: 401, Loss: 0.5021\n",
      "Epoch: 18, Index: 402, Loss: 0.8305\n",
      "Epoch: 18, Index: 403, Loss: 0.5089\n",
      "Epoch: 18, Index: 404, Loss: 5.3321\n",
      "Epoch: 18, Index: 405, Loss: 1.9023\n",
      "Epoch: 18, Index: 406, Loss: 0.0383\n",
      "Epoch: 18, Index: 407, Loss: 6.5409\n",
      "Epoch: 18, Index: 408, Loss: 2.3064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f201220bc8b44af9af2ed0c895f9475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Index: 0, Loss: 0.1413\n",
      "Epoch: 19, Index: 1, Loss: 1.1870\n",
      "Epoch: 19, Index: 2, Loss: 1.5264\n",
      "Epoch: 19, Index: 3, Loss: 0.8387\n",
      "Epoch: 19, Index: 4, Loss: 0.4318\n",
      "Epoch: 19, Index: 5, Loss: 2.4067\n",
      "Epoch: 19, Index: 6, Loss: 1.9479\n",
      "Epoch: 19, Index: 7, Loss: 3.7847\n",
      "Epoch: 19, Index: 8, Loss: 1.2863\n",
      "Epoch: 19, Index: 9, Loss: 0.4836\n",
      "Epoch: 19, Index: 10, Loss: 0.2676\n",
      "Epoch: 19, Index: 11, Loss: 2.1474\n",
      "Epoch: 19, Index: 12, Loss: 0.0385\n",
      "Epoch: 19, Index: 13, Loss: 0.3804\n",
      "Epoch: 19, Index: 14, Loss: 5.0298\n",
      "Epoch: 19, Index: 15, Loss: 0.9455\n",
      "Epoch: 19, Index: 16, Loss: 0.3145\n",
      "Epoch: 19, Index: 17, Loss: 0.8521\n",
      "Epoch: 19, Index: 18, Loss: 3.0628\n",
      "Epoch: 19, Index: 19, Loss: 1.8009\n",
      "Epoch: 19, Index: 20, Loss: 0.8698\n",
      "Epoch: 19, Index: 21, Loss: 0.9914\n",
      "Epoch: 19, Index: 22, Loss: 0.7004\n",
      "Epoch: 19, Index: 23, Loss: 1.7142\n",
      "Epoch: 19, Index: 24, Loss: 0.4309\n",
      "Epoch: 19, Index: 25, Loss: 0.9268\n",
      "Epoch: 19, Index: 26, Loss: 0.1435\n",
      "Epoch: 19, Index: 27, Loss: 0.9234\n",
      "Epoch: 19, Index: 28, Loss: 0.7746\n",
      "Epoch: 19, Index: 29, Loss: 2.7475\n",
      "Epoch: 19, Index: 30, Loss: 1.0260\n",
      "Epoch: 19, Index: 31, Loss: 0.8804\n",
      "Epoch: 19, Index: 32, Loss: 0.7048\n",
      "Epoch: 19, Index: 33, Loss: 0.9445\n",
      "Epoch: 19, Index: 34, Loss: 7.0071\n",
      "Epoch: 19, Index: 35, Loss: 0.6268\n",
      "Epoch: 19, Index: 36, Loss: 1.1246\n",
      "Epoch: 19, Index: 37, Loss: 2.1940\n",
      "Epoch: 19, Index: 38, Loss: 1.6239\n",
      "Epoch: 19, Index: 39, Loss: 1.5625\n",
      "Epoch: 19, Index: 40, Loss: 10.1922\n",
      "Epoch: 19, Index: 41, Loss: 0.7999\n",
      "Epoch: 19, Index: 42, Loss: 0.6672\n",
      "Epoch: 19, Index: 43, Loss: 3.3478\n",
      "Epoch: 19, Index: 44, Loss: 4.4968\n",
      "Epoch: 19, Index: 45, Loss: 0.6799\n",
      "Epoch: 19, Index: 46, Loss: 1.6919\n",
      "Epoch: 19, Index: 47, Loss: 0.9242\n",
      "Epoch: 19, Index: 48, Loss: 0.3506\n",
      "Epoch: 19, Index: 49, Loss: 8.6124\n",
      "Epoch: 19, Index: 50, Loss: 0.7871\n",
      "Epoch: 19, Index: 51, Loss: 0.6487\n",
      "Epoch: 19, Index: 52, Loss: 3.2332\n",
      "Epoch: 19, Index: 53, Loss: 0.5106\n",
      "Epoch: 19, Index: 54, Loss: 0.6813\n",
      "Epoch: 19, Index: 55, Loss: 0.8418\n",
      "Epoch: 19, Index: 56, Loss: 3.7202\n",
      "Epoch: 19, Index: 57, Loss: 0.8928\n",
      "Epoch: 19, Index: 58, Loss: 5.1257\n",
      "Epoch: 19, Index: 59, Loss: 0.9399\n",
      "Epoch: 19, Index: 60, Loss: 1.2708\n",
      "Epoch: 19, Index: 61, Loss: 0.8762\n",
      "Epoch: 19, Index: 62, Loss: 5.0699\n",
      "Epoch: 19, Index: 63, Loss: 1.4681\n",
      "Epoch: 19, Index: 64, Loss: 1.8575\n",
      "Epoch: 19, Index: 65, Loss: 0.3352\n",
      "Epoch: 19, Index: 66, Loss: 1.5627\n",
      "Epoch: 19, Index: 67, Loss: 5.7895\n",
      "Epoch: 19, Index: 68, Loss: 1.3353\n",
      "Epoch: 19, Index: 69, Loss: 0.4836\n",
      "Epoch: 19, Index: 70, Loss: 2.7988\n",
      "Epoch: 19, Index: 71, Loss: 0.7511\n",
      "Epoch: 19, Index: 72, Loss: 5.6234\n",
      "Epoch: 19, Index: 73, Loss: 0.5078\n",
      "Epoch: 19, Index: 74, Loss: 1.9913\n",
      "Epoch: 19, Index: 75, Loss: 0.0680\n",
      "Epoch: 19, Index: 76, Loss: 0.1168\n",
      "Epoch: 19, Index: 77, Loss: 0.9995\n",
      "Epoch: 19, Index: 78, Loss: 0.8922\n",
      "Epoch: 19, Index: 79, Loss: 0.3586\n",
      "Epoch: 19, Index: 80, Loss: 1.6693\n",
      "Epoch: 19, Index: 81, Loss: 2.5961\n",
      "Epoch: 19, Index: 82, Loss: 0.2392\n",
      "Epoch: 19, Index: 83, Loss: 1.3097\n",
      "Epoch: 19, Index: 84, Loss: 0.8241\n",
      "Epoch: 19, Index: 85, Loss: 3.5994\n",
      "Epoch: 19, Index: 86, Loss: 1.9137\n",
      "Epoch: 19, Index: 87, Loss: 3.3763\n",
      "Epoch: 19, Index: 88, Loss: 1.7818\n",
      "Epoch: 19, Index: 89, Loss: 0.1731\n",
      "Epoch: 19, Index: 90, Loss: 0.0220\n",
      "Epoch: 19, Index: 91, Loss: 0.0080\n",
      "Epoch: 19, Index: 92, Loss: 2.2473\n",
      "Epoch: 19, Index: 93, Loss: 1.7132\n",
      "Epoch: 19, Index: 94, Loss: 2.0060\n",
      "Epoch: 19, Index: 95, Loss: 0.0542\n",
      "Epoch: 19, Index: 96, Loss: 0.4669\n",
      "Epoch: 19, Index: 97, Loss: 3.6511\n",
      "Epoch: 19, Index: 98, Loss: 0.7883\n",
      "Epoch: 19, Index: 99, Loss: 3.0841\n",
      "Epoch: 19, Index: 100, Loss: 1.9944\n",
      "Epoch: 19, Index: 101, Loss: 0.3293\n",
      "Epoch: 19, Index: 102, Loss: 0.3243\n",
      "Epoch: 19, Index: 103, Loss: 1.1835\n",
      "Epoch: 19, Index: 104, Loss: 4.3309\n",
      "Epoch: 19, Index: 105, Loss: 0.7080\n",
      "Epoch: 19, Index: 106, Loss: 2.2466\n",
      "Epoch: 19, Index: 107, Loss: 0.0643\n",
      "Epoch: 19, Index: 108, Loss: 0.3937\n",
      "Epoch: 19, Index: 109, Loss: 2.2718\n",
      "Epoch: 19, Index: 110, Loss: 3.1825\n",
      "Epoch: 19, Index: 111, Loss: 3.5498\n",
      "Epoch: 19, Index: 112, Loss: 4.4876\n",
      "Epoch: 19, Index: 113, Loss: 1.8875\n",
      "Epoch: 19, Index: 114, Loss: 0.2019\n",
      "Epoch: 19, Index: 115, Loss: 1.7708\n",
      "Epoch: 19, Index: 116, Loss: 0.4250\n",
      "Epoch: 19, Index: 117, Loss: 1.1943\n",
      "Epoch: 19, Index: 118, Loss: 0.9477\n",
      "Epoch: 19, Index: 119, Loss: 2.7708\n",
      "Epoch: 19, Index: 120, Loss: 2.2857\n",
      "Epoch: 19, Index: 121, Loss: 0.1256\n",
      "Epoch: 19, Index: 122, Loss: 1.3334\n",
      "Epoch: 19, Index: 123, Loss: 0.8719\n",
      "Epoch: 19, Index: 124, Loss: 4.8707\n",
      "Epoch: 19, Index: 125, Loss: 0.6846\n",
      "Epoch: 19, Index: 126, Loss: 1.7187\n",
      "Epoch: 19, Index: 127, Loss: 0.1135\n",
      "Epoch: 19, Index: 128, Loss: 0.1451\n",
      "Epoch: 19, Index: 129, Loss: 1.3077\n",
      "Epoch: 19, Index: 130, Loss: 0.2274\n",
      "Epoch: 19, Index: 131, Loss: 0.0820\n",
      "Epoch: 19, Index: 132, Loss: 1.8160\n",
      "Epoch: 19, Index: 133, Loss: 0.3813\n",
      "Epoch: 19, Index: 134, Loss: 3.7444\n",
      "Epoch: 19, Index: 135, Loss: 1.0008\n",
      "Epoch: 19, Index: 136, Loss: 5.0382\n",
      "Epoch: 19, Index: 137, Loss: 0.6372\n",
      "Epoch: 19, Index: 138, Loss: 4.1008\n",
      "Epoch: 19, Index: 139, Loss: 2.4627\n",
      "Epoch: 19, Index: 140, Loss: 0.2203\n",
      "Epoch: 19, Index: 141, Loss: 0.3253\n",
      "Epoch: 19, Index: 142, Loss: 7.4435\n",
      "Epoch: 19, Index: 143, Loss: 0.7541\n",
      "Epoch: 19, Index: 144, Loss: 0.0012\n",
      "Epoch: 19, Index: 145, Loss: 0.6343\n",
      "Epoch: 19, Index: 146, Loss: 1.6813\n",
      "Epoch: 19, Index: 147, Loss: 1.1852\n",
      "Epoch: 19, Index: 148, Loss: 1.5178\n",
      "Epoch: 19, Index: 149, Loss: 0.0488\n",
      "Epoch: 19, Index: 150, Loss: 3.8113\n",
      "Epoch: 19, Index: 151, Loss: 3.5290\n",
      "Epoch: 19, Index: 152, Loss: 1.0201\n",
      "Epoch: 19, Index: 153, Loss: 3.3124\n",
      "Epoch: 19, Index: 154, Loss: 2.4664\n",
      "Epoch: 19, Index: 155, Loss: 1.4528\n",
      "Epoch: 19, Index: 156, Loss: 0.1450\n",
      "Epoch: 19, Index: 157, Loss: 2.3853\n",
      "Epoch: 19, Index: 158, Loss: 1.6480\n",
      "Epoch: 19, Index: 159, Loss: 1.8099\n",
      "Epoch: 19, Index: 160, Loss: 1.8538\n",
      "Epoch: 19, Index: 161, Loss: 0.8130\n",
      "Epoch: 19, Index: 162, Loss: 3.2669\n",
      "Epoch: 19, Index: 163, Loss: 1.0636\n",
      "Epoch: 19, Index: 164, Loss: 1.8878\n",
      "Epoch: 19, Index: 165, Loss: 1.1692\n",
      "Epoch: 19, Index: 166, Loss: 0.3127\n",
      "Epoch: 19, Index: 167, Loss: 0.0389\n",
      "Epoch: 19, Index: 168, Loss: 2.5376\n",
      "Epoch: 19, Index: 169, Loss: 1.3926\n",
      "Epoch: 19, Index: 170, Loss: 0.5780\n",
      "Epoch: 19, Index: 171, Loss: 3.1501\n",
      "Epoch: 19, Index: 172, Loss: 3.7385\n",
      "Epoch: 19, Index: 173, Loss: 0.1743\n",
      "Epoch: 19, Index: 174, Loss: 2.7287\n",
      "Epoch: 19, Index: 175, Loss: 0.0068\n",
      "Epoch: 19, Index: 176, Loss: 0.7701\n",
      "Epoch: 19, Index: 177, Loss: 2.7985\n",
      "Epoch: 19, Index: 178, Loss: 2.5219\n",
      "Epoch: 19, Index: 179, Loss: 3.5740\n",
      "Epoch: 19, Index: 180, Loss: 1.3965\n",
      "Epoch: 19, Index: 181, Loss: 4.7456\n",
      "Epoch: 19, Index: 182, Loss: 2.5788\n",
      "Epoch: 19, Index: 183, Loss: 1.1781\n",
      "Epoch: 19, Index: 184, Loss: 3.4469\n",
      "Epoch: 19, Index: 185, Loss: 3.1964\n",
      "Epoch: 19, Index: 186, Loss: 0.3411\n",
      "Epoch: 19, Index: 187, Loss: 0.1075\n",
      "Epoch: 19, Index: 188, Loss: 0.8431\n",
      "Epoch: 19, Index: 189, Loss: 1.1661\n",
      "Epoch: 19, Index: 190, Loss: 0.5097\n",
      "Epoch: 19, Index: 191, Loss: 0.2756\n",
      "Epoch: 19, Index: 192, Loss: 0.1291\n",
      "Epoch: 19, Index: 193, Loss: 0.3206\n",
      "Epoch: 19, Index: 194, Loss: 1.3644\n",
      "Epoch: 19, Index: 195, Loss: 0.2530\n",
      "Epoch: 19, Index: 196, Loss: 0.5352\n",
      "Epoch: 19, Index: 197, Loss: 0.4329\n",
      "Epoch: 19, Index: 198, Loss: 0.0174\n",
      "Epoch: 19, Index: 199, Loss: 4.0470\n",
      "Epoch: 19, Index: 200, Loss: 4.6015\n",
      "Epoch: 19, Index: 201, Loss: 1.9048\n",
      "Epoch: 19, Index: 202, Loss: 1.2372\n",
      "Epoch: 19, Index: 203, Loss: 4.8636\n",
      "Epoch: 19, Index: 204, Loss: 0.4945\n",
      "Epoch: 19, Index: 205, Loss: 0.8901\n",
      "Epoch: 19, Index: 206, Loss: 2.4700\n",
      "Epoch: 19, Index: 207, Loss: 5.4042\n",
      "Epoch: 19, Index: 208, Loss: 1.8800\n",
      "Epoch: 19, Index: 209, Loss: 0.2722\n",
      "Epoch: 19, Index: 210, Loss: 1.5602\n",
      "Epoch: 19, Index: 211, Loss: 0.0977\n",
      "Epoch: 19, Index: 212, Loss: 0.5423\n",
      "Epoch: 19, Index: 213, Loss: 1.1219\n",
      "Epoch: 19, Index: 214, Loss: 1.0815\n",
      "Epoch: 19, Index: 215, Loss: 7.6136\n",
      "Epoch: 19, Index: 216, Loss: 0.0778\n",
      "Epoch: 19, Index: 217, Loss: 1.0220\n",
      "Epoch: 19, Index: 218, Loss: 5.2901\n",
      "Epoch: 19, Index: 219, Loss: 0.1161\n",
      "Epoch: 19, Index: 220, Loss: 4.9627\n",
      "Epoch: 19, Index: 221, Loss: 0.4172\n",
      "Epoch: 19, Index: 222, Loss: 0.3696\n",
      "Epoch: 19, Index: 223, Loss: 0.2365\n",
      "Epoch: 19, Index: 224, Loss: 2.2178\n",
      "Epoch: 19, Index: 225, Loss: 0.4181\n",
      "Epoch: 19, Index: 226, Loss: 1.8693\n",
      "Epoch: 19, Index: 227, Loss: 0.4948\n",
      "Epoch: 19, Index: 228, Loss: 0.1200\n",
      "Epoch: 19, Index: 229, Loss: 0.6685\n",
      "Epoch: 19, Index: 230, Loss: 1.3624\n",
      "Epoch: 19, Index: 231, Loss: 2.4460\n",
      "Epoch: 19, Index: 232, Loss: 4.3803\n",
      "Epoch: 19, Index: 233, Loss: 0.7427\n",
      "Epoch: 19, Index: 234, Loss: 0.3103\n",
      "Epoch: 19, Index: 235, Loss: 1.3587\n",
      "Epoch: 19, Index: 236, Loss: 4.8750\n",
      "Epoch: 19, Index: 237, Loss: 2.4703\n",
      "Epoch: 19, Index: 238, Loss: 0.2782\n",
      "Epoch: 19, Index: 239, Loss: 2.4761\n",
      "Epoch: 19, Index: 240, Loss: 1.4637\n",
      "Epoch: 19, Index: 241, Loss: 0.6624\n",
      "Epoch: 19, Index: 242, Loss: 0.5207\n",
      "Epoch: 19, Index: 243, Loss: 1.1035\n",
      "Epoch: 19, Index: 244, Loss: 2.8976\n",
      "Epoch: 19, Index: 245, Loss: 0.7163\n",
      "Epoch: 19, Index: 246, Loss: 2.4857\n",
      "Epoch: 19, Index: 247, Loss: 3.1178\n",
      "Epoch: 19, Index: 248, Loss: 1.6646\n",
      "Epoch: 19, Index: 249, Loss: 6.4348\n",
      "Epoch: 19, Index: 250, Loss: 1.7984\n",
      "Epoch: 19, Index: 251, Loss: 0.2540\n",
      "Epoch: 19, Index: 252, Loss: 1.1541\n",
      "Epoch: 19, Index: 253, Loss: 0.3779\n",
      "Epoch: 19, Index: 254, Loss: 1.3241\n",
      "Epoch: 19, Index: 255, Loss: 1.8671\n",
      "Epoch: 19, Index: 256, Loss: 1.8575\n",
      "Epoch: 19, Index: 257, Loss: 0.8714\n",
      "Epoch: 19, Index: 258, Loss: 1.5708\n",
      "Epoch: 19, Index: 259, Loss: 16.7915\n",
      "Epoch: 19, Index: 260, Loss: 1.5568\n",
      "Epoch: 19, Index: 261, Loss: 2.0503\n",
      "Epoch: 19, Index: 262, Loss: 0.8847\n",
      "Epoch: 19, Index: 263, Loss: 1.2822\n",
      "Epoch: 19, Index: 264, Loss: 2.3531\n",
      "Epoch: 19, Index: 265, Loss: 0.0395\n",
      "Epoch: 19, Index: 266, Loss: 0.8859\n",
      "Epoch: 19, Index: 267, Loss: 5.1007\n",
      "Epoch: 19, Index: 268, Loss: 0.3305\n",
      "Epoch: 19, Index: 269, Loss: 0.0896\n",
      "Epoch: 19, Index: 270, Loss: 0.5143\n",
      "Epoch: 19, Index: 271, Loss: 2.6928\n",
      "Epoch: 19, Index: 272, Loss: 1.6948\n",
      "Epoch: 19, Index: 273, Loss: 1.7064\n",
      "Epoch: 19, Index: 274, Loss: 2.1143\n",
      "Epoch: 19, Index: 275, Loss: 0.1064\n",
      "Epoch: 19, Index: 276, Loss: 2.8465\n",
      "Epoch: 19, Index: 277, Loss: 0.6389\n",
      "Epoch: 19, Index: 278, Loss: 5.4163\n",
      "Epoch: 19, Index: 279, Loss: 0.3139\n",
      "Epoch: 19, Index: 280, Loss: 1.2373\n",
      "Epoch: 19, Index: 281, Loss: 2.1071\n",
      "Epoch: 19, Index: 282, Loss: 2.1010\n",
      "Epoch: 19, Index: 283, Loss: 1.1101\n",
      "Epoch: 19, Index: 284, Loss: 2.3606\n",
      "Epoch: 19, Index: 285, Loss: 0.5508\n",
      "Epoch: 19, Index: 286, Loss: 2.3500\n",
      "Epoch: 19, Index: 287, Loss: 0.4652\n",
      "Epoch: 19, Index: 288, Loss: 1.9749\n",
      "Epoch: 19, Index: 289, Loss: 0.9445\n",
      "Epoch: 19, Index: 290, Loss: 1.7129\n",
      "Epoch: 19, Index: 291, Loss: 0.4736\n",
      "Epoch: 19, Index: 292, Loss: 3.4974\n",
      "Epoch: 19, Index: 293, Loss: 1.4622\n",
      "Epoch: 19, Index: 294, Loss: 0.3264\n",
      "Epoch: 19, Index: 295, Loss: 0.1575\n",
      "Epoch: 19, Index: 296, Loss: 3.9093\n",
      "Epoch: 19, Index: 297, Loss: 0.1806\n",
      "Epoch: 19, Index: 298, Loss: 6.5271\n",
      "Epoch: 19, Index: 299, Loss: 0.5098\n",
      "Epoch: 19, Index: 300, Loss: 0.7276\n",
      "Epoch: 19, Index: 301, Loss: 2.6107\n",
      "Epoch: 19, Index: 302, Loss: 0.0545\n",
      "Epoch: 19, Index: 303, Loss: 0.4769\n",
      "Epoch: 19, Index: 304, Loss: 0.9512\n",
      "Epoch: 19, Index: 305, Loss: 1.7052\n",
      "Epoch: 19, Index: 306, Loss: 1.1190\n",
      "Epoch: 19, Index: 307, Loss: 0.2259\n",
      "Epoch: 19, Index: 308, Loss: 0.6764\n",
      "Epoch: 19, Index: 309, Loss: 2.4187\n",
      "Epoch: 19, Index: 310, Loss: 4.3845\n",
      "Epoch: 19, Index: 311, Loss: 0.8292\n",
      "Epoch: 19, Index: 312, Loss: 0.3991\n",
      "Epoch: 19, Index: 313, Loss: 2.3938\n",
      "Epoch: 19, Index: 314, Loss: 2.7230\n",
      "Epoch: 19, Index: 315, Loss: 3.2682\n",
      "Epoch: 19, Index: 316, Loss: 1.4107\n",
      "Epoch: 19, Index: 317, Loss: 0.4877\n",
      "Epoch: 19, Index: 318, Loss: 0.4437\n",
      "Epoch: 19, Index: 319, Loss: 0.2985\n",
      "Epoch: 19, Index: 320, Loss: 1.3605\n",
      "Epoch: 19, Index: 321, Loss: 0.7935\n",
      "Epoch: 19, Index: 322, Loss: 0.1998\n",
      "Epoch: 19, Index: 323, Loss: 1.3317\n",
      "Epoch: 19, Index: 324, Loss: 0.8990\n",
      "Epoch: 19, Index: 325, Loss: 1.0055\n",
      "Epoch: 19, Index: 326, Loss: 0.8606\n",
      "Epoch: 19, Index: 327, Loss: 0.9920\n",
      "Epoch: 19, Index: 328, Loss: 0.8221\n",
      "Epoch: 19, Index: 329, Loss: 0.1780\n",
      "Epoch: 19, Index: 330, Loss: 2.4460\n",
      "Epoch: 19, Index: 331, Loss: 2.1186\n",
      "Epoch: 19, Index: 332, Loss: 4.5728\n",
      "Epoch: 19, Index: 333, Loss: 1.7150\n",
      "Epoch: 19, Index: 334, Loss: 0.6956\n",
      "Epoch: 19, Index: 335, Loss: 0.5030\n",
      "Epoch: 19, Index: 336, Loss: 1.7784\n",
      "Epoch: 19, Index: 337, Loss: 2.0297\n",
      "Epoch: 19, Index: 338, Loss: 0.0031\n",
      "Epoch: 19, Index: 339, Loss: 1.6872\n",
      "Epoch: 19, Index: 340, Loss: 1.6641\n",
      "Epoch: 19, Index: 341, Loss: 1.2921\n",
      "Epoch: 19, Index: 342, Loss: 0.4953\n",
      "Epoch: 19, Index: 343, Loss: 1.1975\n",
      "Epoch: 19, Index: 344, Loss: 12.8992\n",
      "Epoch: 19, Index: 345, Loss: 4.4957\n",
      "Epoch: 19, Index: 346, Loss: 2.4657\n",
      "Epoch: 19, Index: 347, Loss: 1.3522\n",
      "Epoch: 19, Index: 348, Loss: 2.6821\n",
      "Epoch: 19, Index: 349, Loss: 1.5127\n",
      "Epoch: 19, Index: 350, Loss: 17.5139\n",
      "Epoch: 19, Index: 351, Loss: 1.7633\n",
      "Epoch: 19, Index: 352, Loss: 0.9813\n",
      "Epoch: 19, Index: 353, Loss: 2.1371\n",
      "Epoch: 19, Index: 354, Loss: 2.9399\n",
      "Epoch: 19, Index: 355, Loss: 4.1363\n",
      "Epoch: 19, Index: 356, Loss: 2.1528\n",
      "Epoch: 19, Index: 357, Loss: 1.0166\n",
      "Epoch: 19, Index: 358, Loss: 0.4583\n",
      "Epoch: 19, Index: 359, Loss: 0.8949\n",
      "Epoch: 19, Index: 360, Loss: 0.2880\n",
      "Epoch: 19, Index: 361, Loss: 0.9407\n",
      "Epoch: 19, Index: 362, Loss: 1.6204\n",
      "Epoch: 19, Index: 363, Loss: 3.9854\n",
      "Epoch: 19, Index: 364, Loss: 3.6480\n",
      "Epoch: 19, Index: 365, Loss: 0.4460\n",
      "Epoch: 19, Index: 366, Loss: 1.1581\n",
      "Epoch: 19, Index: 367, Loss: 1.4889\n",
      "Epoch: 19, Index: 368, Loss: 0.0996\n",
      "Epoch: 19, Index: 369, Loss: 3.5433\n",
      "Epoch: 19, Index: 370, Loss: 2.1339\n",
      "Epoch: 19, Index: 371, Loss: 0.3693\n",
      "Epoch: 19, Index: 372, Loss: 0.1703\n",
      "Epoch: 19, Index: 373, Loss: 0.2410\n",
      "Epoch: 19, Index: 374, Loss: 0.1798\n",
      "Epoch: 19, Index: 375, Loss: 4.0848\n",
      "Epoch: 19, Index: 376, Loss: 3.4932\n",
      "Epoch: 19, Index: 377, Loss: 0.0580\n",
      "Epoch: 19, Index: 378, Loss: 1.8239\n",
      "Epoch: 19, Index: 379, Loss: 0.2095\n",
      "Epoch: 19, Index: 380, Loss: 0.7700\n",
      "Epoch: 19, Index: 381, Loss: 1.0484\n",
      "Epoch: 19, Index: 382, Loss: 0.1723\n",
      "Epoch: 19, Index: 383, Loss: 0.9741\n",
      "Epoch: 19, Index: 384, Loss: 3.4791\n",
      "Epoch: 19, Index: 385, Loss: 5.5618\n",
      "Epoch: 19, Index: 386, Loss: 1.1139\n",
      "Epoch: 19, Index: 387, Loss: 1.7452\n",
      "Epoch: 19, Index: 388, Loss: 0.2014\n",
      "Epoch: 19, Index: 389, Loss: 3.2289\n",
      "Epoch: 19, Index: 390, Loss: 0.3907\n",
      "Epoch: 19, Index: 391, Loss: 0.1444\n",
      "Epoch: 19, Index: 392, Loss: 0.4952\n",
      "Epoch: 19, Index: 393, Loss: 1.5313\n",
      "Epoch: 19, Index: 394, Loss: 1.8987\n",
      "Epoch: 19, Index: 395, Loss: 1.7236\n",
      "Epoch: 19, Index: 396, Loss: 0.2197\n",
      "Epoch: 19, Index: 397, Loss: 3.6065\n",
      "Epoch: 19, Index: 398, Loss: 0.0057\n",
      "Epoch: 19, Index: 399, Loss: 0.3205\n",
      "Epoch: 19, Index: 400, Loss: 2.7123\n",
      "Epoch: 19, Index: 401, Loss: 1.0289\n",
      "Epoch: 19, Index: 402, Loss: 2.3564\n",
      "Epoch: 19, Index: 403, Loss: 0.6799\n",
      "Epoch: 19, Index: 404, Loss: 3.7775\n",
      "Epoch: 19, Index: 405, Loss: 1.9822\n",
      "Epoch: 19, Index: 406, Loss: 0.7220\n",
      "Epoch: 19, Index: 407, Loss: 0.8289\n",
      "Epoch: 19, Index: 408, Loss: 1.6670\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "460469a6367e4691a0ebdc5f7394d655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Index: 0, Loss: 2.9702\n",
      "Epoch: 20, Index: 1, Loss: 1.7365\n",
      "Epoch: 20, Index: 2, Loss: 0.3610\n",
      "Epoch: 20, Index: 3, Loss: 2.8344\n",
      "Epoch: 20, Index: 4, Loss: 2.3469\n",
      "Epoch: 20, Index: 5, Loss: 0.8604\n",
      "Epoch: 20, Index: 6, Loss: 0.1887\n",
      "Epoch: 20, Index: 7, Loss: 0.1692\n",
      "Epoch: 20, Index: 8, Loss: 0.6570\n",
      "Epoch: 20, Index: 9, Loss: 4.4283\n",
      "Epoch: 20, Index: 10, Loss: 2.8306\n",
      "Epoch: 20, Index: 11, Loss: 1.3955\n",
      "Epoch: 20, Index: 12, Loss: 0.7125\n",
      "Epoch: 20, Index: 13, Loss: 1.0607\n",
      "Epoch: 20, Index: 14, Loss: 1.0787\n",
      "Epoch: 20, Index: 15, Loss: 2.4993\n",
      "Epoch: 20, Index: 16, Loss: 1.4304\n",
      "Epoch: 20, Index: 17, Loss: 2.1737\n",
      "Epoch: 20, Index: 18, Loss: 1.0163\n",
      "Epoch: 20, Index: 19, Loss: 1.3183\n",
      "Epoch: 20, Index: 20, Loss: 3.1131\n",
      "Epoch: 20, Index: 21, Loss: 1.1079\n",
      "Epoch: 20, Index: 22, Loss: 0.8334\n",
      "Epoch: 20, Index: 23, Loss: 1.0648\n",
      "Epoch: 20, Index: 24, Loss: 4.7622\n",
      "Epoch: 20, Index: 25, Loss: 0.3865\n",
      "Epoch: 20, Index: 26, Loss: 4.2295\n",
      "Epoch: 20, Index: 27, Loss: 0.6213\n",
      "Epoch: 20, Index: 28, Loss: 0.3956\n",
      "Epoch: 20, Index: 29, Loss: 1.5702\n",
      "Epoch: 20, Index: 30, Loss: 0.9500\n",
      "Epoch: 20, Index: 31, Loss: 0.0820\n",
      "Epoch: 20, Index: 32, Loss: 0.4169\n",
      "Epoch: 20, Index: 33, Loss: 5.0576\n",
      "Epoch: 20, Index: 34, Loss: 0.4696\n",
      "Epoch: 20, Index: 35, Loss: 0.5235\n",
      "Epoch: 20, Index: 36, Loss: 0.8171\n",
      "Epoch: 20, Index: 37, Loss: 0.6616\n",
      "Epoch: 20, Index: 38, Loss: 0.5248\n",
      "Epoch: 20, Index: 39, Loss: 0.6902\n",
      "Epoch: 20, Index: 40, Loss: 3.3096\n",
      "Epoch: 20, Index: 41, Loss: 1.3145\n",
      "Epoch: 20, Index: 42, Loss: 2.4195\n",
      "Epoch: 20, Index: 43, Loss: 1.7876\n",
      "Epoch: 20, Index: 44, Loss: 0.1772\n",
      "Epoch: 20, Index: 45, Loss: 1.7552\n",
      "Epoch: 20, Index: 46, Loss: 1.3978\n",
      "Epoch: 20, Index: 47, Loss: 0.2403\n",
      "Epoch: 20, Index: 48, Loss: 0.1896\n",
      "Epoch: 20, Index: 49, Loss: 0.3770\n",
      "Epoch: 20, Index: 50, Loss: 6.8065\n",
      "Epoch: 20, Index: 51, Loss: 2.5203\n",
      "Epoch: 20, Index: 52, Loss: 0.1441\n",
      "Epoch: 20, Index: 53, Loss: 0.1859\n",
      "Epoch: 20, Index: 54, Loss: 2.4579\n",
      "Epoch: 20, Index: 55, Loss: 3.2426\n",
      "Epoch: 20, Index: 56, Loss: 2.8926\n",
      "Epoch: 20, Index: 57, Loss: 2.2991\n",
      "Epoch: 20, Index: 58, Loss: 1.2926\n",
      "Epoch: 20, Index: 59, Loss: 0.0449\n",
      "Epoch: 20, Index: 60, Loss: 0.9593\n",
      "Epoch: 20, Index: 61, Loss: 2.4254\n",
      "Epoch: 20, Index: 62, Loss: 0.5103\n",
      "Epoch: 20, Index: 63, Loss: 1.4534\n",
      "Epoch: 20, Index: 64, Loss: 1.4046\n",
      "Epoch: 20, Index: 65, Loss: 1.3530\n",
      "Epoch: 20, Index: 66, Loss: 2.5439\n",
      "Epoch: 20, Index: 67, Loss: 0.5615\n",
      "Epoch: 20, Index: 68, Loss: 0.9879\n",
      "Epoch: 20, Index: 69, Loss: 3.3733\n",
      "Epoch: 20, Index: 70, Loss: 0.1246\n",
      "Epoch: 20, Index: 71, Loss: 1.6823\n",
      "Epoch: 20, Index: 72, Loss: 0.0197\n",
      "Epoch: 20, Index: 73, Loss: 5.4400\n",
      "Epoch: 20, Index: 74, Loss: 0.4223\n",
      "Epoch: 20, Index: 75, Loss: 1.1952\n",
      "Epoch: 20, Index: 76, Loss: 0.4009\n",
      "Epoch: 20, Index: 77, Loss: 1.2296\n",
      "Epoch: 20, Index: 78, Loss: 0.2285\n",
      "Epoch: 20, Index: 79, Loss: 0.7292\n",
      "Epoch: 20, Index: 80, Loss: 3.2167\n",
      "Epoch: 20, Index: 81, Loss: 0.8863\n",
      "Epoch: 20, Index: 82, Loss: 0.2094\n",
      "Epoch: 20, Index: 83, Loss: 0.3675\n",
      "Epoch: 20, Index: 84, Loss: 3.4887\n",
      "Epoch: 20, Index: 85, Loss: 3.4766\n",
      "Epoch: 20, Index: 86, Loss: 3.9147\n",
      "Epoch: 20, Index: 87, Loss: 0.5895\n",
      "Epoch: 20, Index: 88, Loss: 2.2422\n",
      "Epoch: 20, Index: 89, Loss: 1.4868\n",
      "Epoch: 20, Index: 90, Loss: 7.0118\n",
      "Epoch: 20, Index: 91, Loss: 1.1566\n",
      "Epoch: 20, Index: 92, Loss: 0.0947\n",
      "Epoch: 20, Index: 93, Loss: 2.2649\n",
      "Epoch: 20, Index: 94, Loss: 1.8897\n",
      "Epoch: 20, Index: 95, Loss: 2.0919\n",
      "Epoch: 20, Index: 96, Loss: 0.7401\n",
      "Epoch: 20, Index: 97, Loss: 0.5893\n",
      "Epoch: 20, Index: 98, Loss: 0.7860\n",
      "Epoch: 20, Index: 99, Loss: 1.6373\n",
      "Epoch: 20, Index: 100, Loss: 16.3658\n",
      "Epoch: 20, Index: 101, Loss: 0.2225\n",
      "Epoch: 20, Index: 102, Loss: 0.1283\n",
      "Epoch: 20, Index: 103, Loss: 1.4754\n",
      "Epoch: 20, Index: 104, Loss: 8.6643\n",
      "Epoch: 20, Index: 105, Loss: 1.8165\n",
      "Epoch: 20, Index: 106, Loss: 2.2203\n",
      "Epoch: 20, Index: 107, Loss: 1.4401\n",
      "Epoch: 20, Index: 108, Loss: 1.3745\n",
      "Epoch: 20, Index: 109, Loss: 1.1076\n",
      "Epoch: 20, Index: 110, Loss: 3.1988\n",
      "Epoch: 20, Index: 111, Loss: 1.0835\n",
      "Epoch: 20, Index: 112, Loss: 1.5934\n",
      "Epoch: 20, Index: 113, Loss: 0.9946\n",
      "Epoch: 20, Index: 114, Loss: 3.0020\n",
      "Epoch: 20, Index: 115, Loss: 4.4094\n",
      "Epoch: 20, Index: 116, Loss: 0.4574\n",
      "Epoch: 20, Index: 117, Loss: 3.8534\n",
      "Epoch: 20, Index: 118, Loss: 0.4946\n",
      "Epoch: 20, Index: 119, Loss: 2.3369\n",
      "Epoch: 20, Index: 120, Loss: 1.0729\n",
      "Epoch: 20, Index: 121, Loss: 3.8369\n",
      "Epoch: 20, Index: 122, Loss: 5.3766\n",
      "Epoch: 20, Index: 123, Loss: 1.8125\n",
      "Epoch: 20, Index: 124, Loss: 0.4408\n",
      "Epoch: 20, Index: 125, Loss: 0.2974\n",
      "Epoch: 20, Index: 126, Loss: 5.4131\n",
      "Epoch: 20, Index: 127, Loss: 0.5784\n",
      "Epoch: 20, Index: 128, Loss: 0.7483\n",
      "Epoch: 20, Index: 129, Loss: 2.4478\n",
      "Epoch: 20, Index: 130, Loss: 4.2169\n",
      "Epoch: 20, Index: 131, Loss: 0.6400\n",
      "Epoch: 20, Index: 132, Loss: 1.1204\n",
      "Epoch: 20, Index: 133, Loss: 0.4647\n",
      "Epoch: 20, Index: 134, Loss: 1.9467\n",
      "Epoch: 20, Index: 135, Loss: 1.6786\n",
      "Epoch: 20, Index: 136, Loss: 1.5501\n",
      "Epoch: 20, Index: 137, Loss: 4.2023\n",
      "Epoch: 20, Index: 138, Loss: 0.6123\n",
      "Epoch: 20, Index: 139, Loss: 5.0549\n",
      "Epoch: 20, Index: 140, Loss: 0.6272\n",
      "Epoch: 20, Index: 141, Loss: 0.3823\n",
      "Epoch: 20, Index: 142, Loss: 1.4252\n",
      "Epoch: 20, Index: 143, Loss: 0.2641\n",
      "Epoch: 20, Index: 144, Loss: 2.3835\n",
      "Epoch: 20, Index: 145, Loss: 1.4046\n",
      "Epoch: 20, Index: 146, Loss: 1.8851\n",
      "Epoch: 20, Index: 147, Loss: 3.6340\n",
      "Epoch: 20, Index: 148, Loss: 1.1698\n",
      "Epoch: 20, Index: 149, Loss: 4.1571\n",
      "Epoch: 20, Index: 150, Loss: 1.6438\n",
      "Epoch: 20, Index: 151, Loss: 1.3369\n",
      "Epoch: 20, Index: 152, Loss: 3.8938\n",
      "Epoch: 20, Index: 153, Loss: 1.2453\n",
      "Epoch: 20, Index: 154, Loss: 1.6565\n",
      "Epoch: 20, Index: 155, Loss: 0.9363\n",
      "Epoch: 20, Index: 156, Loss: 2.2203\n",
      "Epoch: 20, Index: 157, Loss: 1.5559\n",
      "Epoch: 20, Index: 158, Loss: 4.8958\n",
      "Epoch: 20, Index: 159, Loss: 1.8281\n",
      "Epoch: 20, Index: 160, Loss: 0.0682\n",
      "Epoch: 20, Index: 161, Loss: 0.2653\n",
      "Epoch: 20, Index: 162, Loss: 0.2653\n",
      "Epoch: 20, Index: 163, Loss: 0.4899\n",
      "Epoch: 20, Index: 164, Loss: 2.6378\n",
      "Epoch: 20, Index: 165, Loss: 5.6603\n",
      "Epoch: 20, Index: 166, Loss: 1.7452\n",
      "Epoch: 20, Index: 167, Loss: 4.3607\n",
      "Epoch: 20, Index: 168, Loss: 3.6976\n",
      "Epoch: 20, Index: 169, Loss: 1.4138\n",
      "Epoch: 20, Index: 170, Loss: 0.4169\n",
      "Epoch: 20, Index: 171, Loss: 1.2183\n",
      "Epoch: 20, Index: 172, Loss: 1.9639\n",
      "Epoch: 20, Index: 173, Loss: 1.7613\n",
      "Epoch: 20, Index: 174, Loss: 0.0730\n",
      "Epoch: 20, Index: 175, Loss: 2.4464\n",
      "Epoch: 20, Index: 176, Loss: 0.2740\n",
      "Epoch: 20, Index: 177, Loss: 2.1076\n",
      "Epoch: 20, Index: 178, Loss: 3.9385\n",
      "Epoch: 20, Index: 179, Loss: 5.5519\n",
      "Epoch: 20, Index: 180, Loss: 1.7402\n",
      "Epoch: 20, Index: 181, Loss: 3.0806\n",
      "Epoch: 20, Index: 182, Loss: 1.0183\n",
      "Epoch: 20, Index: 183, Loss: 0.3027\n",
      "Epoch: 20, Index: 184, Loss: 0.5416\n",
      "Epoch: 20, Index: 185, Loss: 0.2781\n",
      "Epoch: 20, Index: 186, Loss: 2.7383\n",
      "Epoch: 20, Index: 187, Loss: 7.2057\n",
      "Epoch: 20, Index: 188, Loss: 0.6965\n",
      "Epoch: 20, Index: 189, Loss: 0.6238\n",
      "Epoch: 20, Index: 190, Loss: 2.4188\n",
      "Epoch: 20, Index: 191, Loss: 0.1053\n",
      "Epoch: 20, Index: 192, Loss: 1.4529\n",
      "Epoch: 20, Index: 193, Loss: 2.2778\n",
      "Epoch: 20, Index: 194, Loss: 2.2298\n",
      "Epoch: 20, Index: 195, Loss: 1.0299\n",
      "Epoch: 20, Index: 196, Loss: 4.8972\n",
      "Epoch: 20, Index: 197, Loss: 3.0674\n",
      "Epoch: 20, Index: 198, Loss: 1.6968\n",
      "Epoch: 20, Index: 199, Loss: 2.1889\n",
      "Epoch: 20, Index: 200, Loss: 0.6082\n",
      "Epoch: 20, Index: 201, Loss: 1.0696\n",
      "Epoch: 20, Index: 202, Loss: 0.6919\n",
      "Epoch: 20, Index: 203, Loss: 0.3523\n",
      "Epoch: 20, Index: 204, Loss: 0.3118\n",
      "Epoch: 20, Index: 205, Loss: 2.6946\n",
      "Epoch: 20, Index: 206, Loss: 1.4691\n",
      "Epoch: 20, Index: 207, Loss: 0.0384\n",
      "Epoch: 20, Index: 208, Loss: 0.0413\n",
      "Epoch: 20, Index: 209, Loss: 0.6298\n",
      "Epoch: 20, Index: 210, Loss: 0.1145\n",
      "Epoch: 20, Index: 211, Loss: 2.3974\n",
      "Epoch: 20, Index: 212, Loss: 3.1980\n",
      "Epoch: 20, Index: 213, Loss: 2.3021\n",
      "Epoch: 20, Index: 214, Loss: 1.1871\n",
      "Epoch: 20, Index: 215, Loss: 1.2520\n",
      "Epoch: 20, Index: 216, Loss: 0.4411\n",
      "Epoch: 20, Index: 217, Loss: 0.3735\n",
      "Epoch: 20, Index: 218, Loss: 2.1400\n",
      "Epoch: 20, Index: 219, Loss: 0.1890\n",
      "Epoch: 20, Index: 220, Loss: 1.8025\n",
      "Epoch: 20, Index: 221, Loss: 2.2937\n",
      "Epoch: 20, Index: 222, Loss: 3.2591\n",
      "Epoch: 20, Index: 223, Loss: 3.5050\n",
      "Epoch: 20, Index: 224, Loss: 2.9567\n",
      "Epoch: 20, Index: 225, Loss: 2.3451\n",
      "Epoch: 20, Index: 226, Loss: 1.3994\n",
      "Epoch: 20, Index: 227, Loss: 8.9658\n",
      "Epoch: 20, Index: 228, Loss: 1.7136\n",
      "Epoch: 20, Index: 229, Loss: 1.5869\n",
      "Epoch: 20, Index: 230, Loss: 1.5580\n",
      "Epoch: 20, Index: 231, Loss: 0.3233\n",
      "Epoch: 20, Index: 232, Loss: 2.7949\n",
      "Epoch: 20, Index: 233, Loss: 0.5653\n",
      "Epoch: 20, Index: 234, Loss: 0.6397\n",
      "Epoch: 20, Index: 235, Loss: 0.2961\n",
      "Epoch: 20, Index: 236, Loss: 0.3844\n",
      "Epoch: 20, Index: 237, Loss: 1.2626\n",
      "Epoch: 20, Index: 238, Loss: 2.6692\n",
      "Epoch: 20, Index: 239, Loss: 0.7764\n",
      "Epoch: 20, Index: 240, Loss: 0.8936\n",
      "Epoch: 20, Index: 241, Loss: 2.0865\n",
      "Epoch: 20, Index: 242, Loss: 4.9535\n",
      "Epoch: 20, Index: 243, Loss: 0.3669\n",
      "Epoch: 20, Index: 244, Loss: 4.8222\n",
      "Epoch: 20, Index: 245, Loss: 1.0685\n",
      "Epoch: 20, Index: 246, Loss: 0.8630\n",
      "Epoch: 20, Index: 247, Loss: 0.1901\n",
      "Epoch: 20, Index: 248, Loss: 0.1182\n",
      "Epoch: 20, Index: 249, Loss: 0.0604\n",
      "Epoch: 20, Index: 250, Loss: 1.2987\n",
      "Epoch: 20, Index: 251, Loss: 0.9899\n",
      "Epoch: 20, Index: 252, Loss: 1.2378\n",
      "Epoch: 20, Index: 253, Loss: 0.1852\n",
      "Epoch: 20, Index: 254, Loss: 1.1973\n",
      "Epoch: 20, Index: 255, Loss: 1.5784\n",
      "Epoch: 20, Index: 256, Loss: 0.5500\n",
      "Epoch: 20, Index: 257, Loss: 1.0184\n",
      "Epoch: 20, Index: 258, Loss: 0.2330\n",
      "Epoch: 20, Index: 259, Loss: 1.2817\n",
      "Epoch: 20, Index: 260, Loss: 0.5393\n",
      "Epoch: 20, Index: 261, Loss: 0.5324\n",
      "Epoch: 20, Index: 262, Loss: 0.4646\n",
      "Epoch: 20, Index: 263, Loss: 0.6594\n",
      "Epoch: 20, Index: 264, Loss: 2.7795\n",
      "Epoch: 20, Index: 265, Loss: 0.3760\n",
      "Epoch: 20, Index: 266, Loss: 6.7051\n",
      "Epoch: 20, Index: 267, Loss: 3.9178\n",
      "Epoch: 20, Index: 268, Loss: 0.2477\n",
      "Epoch: 20, Index: 269, Loss: 0.5670\n",
      "Epoch: 20, Index: 270, Loss: 0.8753\n",
      "Epoch: 20, Index: 271, Loss: 0.1189\n",
      "Epoch: 20, Index: 272, Loss: 5.3866\n",
      "Epoch: 20, Index: 273, Loss: 0.2894\n",
      "Epoch: 20, Index: 274, Loss: 1.7171\n",
      "Epoch: 20, Index: 275, Loss: 0.3601\n",
      "Epoch: 20, Index: 276, Loss: 2.4453\n",
      "Epoch: 20, Index: 277, Loss: 0.2866\n",
      "Epoch: 20, Index: 278, Loss: 2.7764\n",
      "Epoch: 20, Index: 279, Loss: 1.3288\n",
      "Epoch: 20, Index: 280, Loss: 0.1835\n",
      "Epoch: 20, Index: 281, Loss: 1.4550\n",
      "Epoch: 20, Index: 282, Loss: 1.4697\n",
      "Epoch: 20, Index: 283, Loss: 0.0688\n",
      "Epoch: 20, Index: 284, Loss: 0.8607\n",
      "Epoch: 20, Index: 285, Loss: 6.1242\n",
      "Epoch: 20, Index: 286, Loss: 0.9458\n",
      "Epoch: 20, Index: 287, Loss: 2.6402\n",
      "Epoch: 20, Index: 288, Loss: 0.0513\n",
      "Epoch: 20, Index: 289, Loss: 3.4748\n",
      "Epoch: 20, Index: 290, Loss: 0.9672\n",
      "Epoch: 20, Index: 291, Loss: 3.3380\n",
      "Epoch: 20, Index: 292, Loss: 0.0578\n",
      "Epoch: 20, Index: 293, Loss: 0.6706\n",
      "Epoch: 20, Index: 294, Loss: 0.7208\n",
      "Epoch: 20, Index: 295, Loss: 3.0861\n",
      "Epoch: 20, Index: 296, Loss: 1.4346\n",
      "Epoch: 20, Index: 297, Loss: 0.8638\n",
      "Epoch: 20, Index: 298, Loss: 2.6606\n",
      "Epoch: 20, Index: 299, Loss: 1.3628\n",
      "Epoch: 20, Index: 300, Loss: 1.0213\n",
      "Epoch: 20, Index: 301, Loss: 1.6320\n",
      "Epoch: 20, Index: 302, Loss: 1.5439\n",
      "Epoch: 20, Index: 303, Loss: 0.0124\n",
      "Epoch: 20, Index: 304, Loss: 0.1650\n",
      "Epoch: 20, Index: 305, Loss: 1.5929\n",
      "Epoch: 20, Index: 306, Loss: 0.9246\n",
      "Epoch: 20, Index: 307, Loss: 0.0828\n",
      "Epoch: 20, Index: 308, Loss: 5.9352\n",
      "Epoch: 20, Index: 309, Loss: 1.8823\n",
      "Epoch: 20, Index: 310, Loss: 1.2836\n",
      "Epoch: 20, Index: 311, Loss: 0.5577\n",
      "Epoch: 20, Index: 312, Loss: 0.3710\n",
      "Epoch: 20, Index: 313, Loss: 0.3159\n",
      "Epoch: 20, Index: 314, Loss: 2.4967\n",
      "Epoch: 20, Index: 315, Loss: 0.3471\n",
      "Epoch: 20, Index: 316, Loss: 1.2355\n",
      "Epoch: 20, Index: 317, Loss: 2.8860\n",
      "Epoch: 20, Index: 318, Loss: 0.6905\n",
      "Epoch: 20, Index: 319, Loss: 0.1704\n",
      "Epoch: 20, Index: 320, Loss: 0.9407\n",
      "Epoch: 20, Index: 321, Loss: 1.2853\n",
      "Epoch: 20, Index: 322, Loss: 0.8500\n",
      "Epoch: 20, Index: 323, Loss: 0.9325\n",
      "Epoch: 20, Index: 324, Loss: 1.9523\n",
      "Epoch: 20, Index: 325, Loss: 1.2039\n",
      "Epoch: 20, Index: 326, Loss: 0.2747\n",
      "Epoch: 20, Index: 327, Loss: 1.6107\n",
      "Epoch: 20, Index: 328, Loss: 0.8620\n",
      "Epoch: 20, Index: 329, Loss: 0.7488\n",
      "Epoch: 20, Index: 330, Loss: 0.8200\n",
      "Epoch: 20, Index: 331, Loss: 0.8781\n",
      "Epoch: 20, Index: 332, Loss: 2.0928\n",
      "Epoch: 20, Index: 333, Loss: 0.3789\n",
      "Epoch: 20, Index: 334, Loss: 0.8697\n",
      "Epoch: 20, Index: 335, Loss: 2.4865\n",
      "Epoch: 20, Index: 336, Loss: 1.3161\n",
      "Epoch: 20, Index: 337, Loss: 0.6075\n",
      "Epoch: 20, Index: 338, Loss: 2.5436\n",
      "Epoch: 20, Index: 339, Loss: 1.2562\n",
      "Epoch: 20, Index: 340, Loss: 0.0738\n",
      "Epoch: 20, Index: 341, Loss: 3.7403\n",
      "Epoch: 20, Index: 342, Loss: 3.1766\n",
      "Epoch: 20, Index: 343, Loss: 1.0776\n",
      "Epoch: 20, Index: 344, Loss: 0.0868\n",
      "Epoch: 20, Index: 345, Loss: 4.1581\n",
      "Epoch: 20, Index: 346, Loss: 0.5012\n",
      "Epoch: 20, Index: 347, Loss: 1.3309\n",
      "Epoch: 20, Index: 348, Loss: 1.0237\n",
      "Epoch: 20, Index: 349, Loss: 0.4876\n",
      "Epoch: 20, Index: 350, Loss: 0.5215\n",
      "Epoch: 20, Index: 351, Loss: 0.4235\n",
      "Epoch: 20, Index: 352, Loss: 1.8243\n",
      "Epoch: 20, Index: 353, Loss: 19.0260\n",
      "Epoch: 20, Index: 354, Loss: 1.9814\n",
      "Epoch: 20, Index: 355, Loss: 0.9614\n",
      "Epoch: 20, Index: 356, Loss: 0.7729\n",
      "Epoch: 20, Index: 357, Loss: 0.8278\n",
      "Epoch: 20, Index: 358, Loss: 0.4868\n",
      "Epoch: 20, Index: 359, Loss: 2.4118\n",
      "Epoch: 20, Index: 360, Loss: 4.2927\n",
      "Epoch: 20, Index: 361, Loss: 0.1402\n",
      "Epoch: 20, Index: 362, Loss: 4.4611\n",
      "Epoch: 20, Index: 363, Loss: 4.6913\n",
      "Epoch: 20, Index: 364, Loss: 2.3499\n",
      "Epoch: 20, Index: 365, Loss: 0.5217\n",
      "Epoch: 20, Index: 366, Loss: 1.7445\n",
      "Epoch: 20, Index: 367, Loss: 6.8168\n",
      "Epoch: 20, Index: 368, Loss: 4.1511\n",
      "Epoch: 20, Index: 369, Loss: 0.9926\n",
      "Epoch: 20, Index: 370, Loss: 3.5183\n",
      "Epoch: 20, Index: 371, Loss: 0.5790\n",
      "Epoch: 20, Index: 372, Loss: 1.1481\n",
      "Epoch: 20, Index: 373, Loss: 3.8713\n",
      "Epoch: 20, Index: 374, Loss: 0.0948\n",
      "Epoch: 20, Index: 375, Loss: 0.7769\n",
      "Epoch: 20, Index: 376, Loss: 0.9696\n",
      "Epoch: 20, Index: 377, Loss: 3.6721\n",
      "Epoch: 20, Index: 378, Loss: 0.4980\n",
      "Epoch: 20, Index: 379, Loss: 3.0937\n",
      "Epoch: 20, Index: 380, Loss: 2.1171\n",
      "Epoch: 20, Index: 381, Loss: 1.4285\n",
      "Epoch: 20, Index: 382, Loss: 0.2374\n",
      "Epoch: 20, Index: 383, Loss: 0.3903\n",
      "Epoch: 20, Index: 384, Loss: 3.1547\n",
      "Epoch: 20, Index: 385, Loss: 0.8271\n",
      "Epoch: 20, Index: 386, Loss: 0.1364\n",
      "Epoch: 20, Index: 387, Loss: 2.3146\n",
      "Epoch: 20, Index: 388, Loss: 1.1835\n",
      "Epoch: 20, Index: 389, Loss: 6.9318\n",
      "Epoch: 20, Index: 390, Loss: 11.7778\n",
      "Epoch: 20, Index: 391, Loss: 0.3411\n",
      "Epoch: 20, Index: 392, Loss: 0.7264\n",
      "Epoch: 20, Index: 393, Loss: 1.4068\n",
      "Epoch: 20, Index: 394, Loss: 1.0339\n",
      "Epoch: 20, Index: 395, Loss: 0.0189\n",
      "Epoch: 20, Index: 396, Loss: 0.0527\n",
      "Epoch: 20, Index: 397, Loss: 0.0449\n",
      "Epoch: 20, Index: 398, Loss: 0.8938\n",
      "Epoch: 20, Index: 399, Loss: 0.9482\n",
      "Epoch: 20, Index: 400, Loss: 2.7959\n",
      "Epoch: 20, Index: 401, Loss: 1.8700\n",
      "Epoch: 20, Index: 402, Loss: 0.4018\n",
      "Epoch: 20, Index: 403, Loss: 1.7440\n",
      "Epoch: 20, Index: 404, Loss: 2.1417\n",
      "Epoch: 20, Index: 405, Loss: 2.9579\n",
      "Epoch: 20, Index: 406, Loss: 0.0768\n",
      "Epoch: 20, Index: 407, Loss: 1.0145\n",
      "Epoch: 20, Index: 408, Loss: 0.6053\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training the model\n",
    "n_total_steps = len(trainloader)\n",
    "avg_loss_over_epochs = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_losses = []\n",
    "    \n",
    "    for i, (images, labels) in tqdm(enumerate(trainloader), desc=\"Training Progress\", total=len(trainloader)):\n",
    "        # Move images and labels to device\n",
    "        images = torch.stack(images).float()\n",
    "        images = images.permute(1, 0, 2, 3, 4)  # Change shape to [5, 10, 1, 224, 224]\n",
    "        labels = labels.float()\n",
    "\n",
    "        # Forward pass with autograd\n",
    "        outputs = model(images).squeeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        tqdm.write(f\"Epoch: {epoch+1}, Index: {i}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        fabric.backward(loss)\n",
    "        optimizer.step()\n",
    "        # Store the loss\n",
    "        train_losses.append(loss.item())\n",
    "    # Store the loss for this epoch\n",
    "    avg_loss_over_epochs.append(sum(train_losses)/len(train_losses))\n",
    "# Plot loss over epochs\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs + 1), avg_loss_over_epochs, label='Average Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ee529196f049829cf85758e1618990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Progress:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: 2.1534\n",
      "RMSE: 1.4674\n",
      "MSE: 2.1626\n",
      "MAE: 1.0374\n",
      "R: -0.1873\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset, batch_size=batch_size, shuffle=False, num_workers=10)\n",
    "testloader = fabric.setup_dataloaders(testloader)\n",
    "test_losses = []\n",
    "all_labels = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(testloader, desc=\"Testing Progress\"):\n",
    "        images = torch.stack(images).float()\n",
    "        images = images.permute(1, 0, 2, 3, 4)\n",
    "        labels = labels.float()\n",
    "        outputs = model(images).squeeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_losses.append(loss.item())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_outputs.extend(outputs.cpu().numpy())\n",
    "\n",
    "avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "rmse = math.sqrt(avg_test_loss)\n",
    "mse = mean_squared_error(all_labels, all_outputs)\n",
    "mae = mean_absolute_error(all_labels, all_outputs)\n",
    "r2 = r2_score(all_labels, all_outputs)\n",
    "\n",
    "print(f'Average test loss: {avg_test_loss:.4f}')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'MSE: {mse:.4f}')\n",
    "print(f'MAE: {mae:.4f}')\n",
    "print(f'R: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(all_labels, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo-\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Labels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(all_outputs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx-\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Labels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(all_labels, 'o-', label='Actual Labels')\n",
    "plt.plot(all_outputs, 'x-', label='Predicted Labels')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Label Value')\n",
    "plt.title('Overlay of Predicted and Actual Labels')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(all_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
